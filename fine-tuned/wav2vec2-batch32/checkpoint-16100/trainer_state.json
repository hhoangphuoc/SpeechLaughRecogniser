{
  "best_metric": 0.4115952253341675,
  "best_model_checkpoint": "../fine-tuned/wav2vec2-batch32/checkpoint-16100",
  "epoch": 5.55747324818778,
  "eval_steps": 100,
  "global_step": 16100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01725923369002416,
      "grad_norm": 50.78611373901367,
      "learning_rate": 3.1066620642043493e-07,
      "loss": 35.3631,
      "step": 50
    },
    {
      "epoch": 0.03451846738004832,
      "grad_norm": 52.73244857788086,
      "learning_rate": 6.489471867449085e-07,
      "loss": 37.8916,
      "step": 100
    },
    {
      "epoch": 0.03451846738004832,
      "eval_loss": 37.11933135986328,
      "eval_runtime": 1023.9524,
      "eval_samples_per_second": 20.119,
      "eval_steps_per_second": 2.516,
      "eval_wer": 1.0016972061375888,
      "step": 100
    },
    {
      "epoch": 0.05177770107007249,
      "grad_norm": 59.13275909423828,
      "learning_rate": 9.941318605453917e-07,
      "loss": 37.5256,
      "step": 150
    },
    {
      "epoch": 0.06903693476009665,
      "grad_norm": 67.70394134521484,
      "learning_rate": 1.339316534345875e-06,
      "loss": 35.988,
      "step": 200
    },
    {
      "epoch": 0.06903693476009665,
      "eval_loss": 36.76264953613281,
      "eval_runtime": 985.7472,
      "eval_samples_per_second": 20.899,
      "eval_steps_per_second": 2.613,
      "eval_wer": 1.0029720306572258,
      "step": 200
    },
    {
      "epoch": 0.08629616845012081,
      "grad_norm": 55.54794692993164,
      "learning_rate": 1.6845012081463583e-06,
      "loss": 35.2662,
      "step": 250
    },
    {
      "epoch": 0.10355540214014498,
      "grad_norm": 66.96751403808594,
      "learning_rate": 2.0296858819468415e-06,
      "loss": 33.6852,
      "step": 300
    },
    {
      "epoch": 0.10355540214014498,
      "eval_loss": 36.260440826416016,
      "eval_runtime": 984.735,
      "eval_samples_per_second": 20.92,
      "eval_steps_per_second": 2.616,
      "eval_wer": 1.007652786950712,
      "step": 300
    },
    {
      "epoch": 0.12081463583016915,
      "grad_norm": 83.4151840209961,
      "learning_rate": 2.374870555747325e-06,
      "loss": 35.8623,
      "step": 350
    },
    {
      "epoch": 0.1380738695201933,
      "grad_norm": 81.82300567626953,
      "learning_rate": 2.7200552295478085e-06,
      "loss": 37.1507,
      "step": 400
    },
    {
      "epoch": 0.1380738695201933,
      "eval_loss": 35.57019805908203,
      "eval_runtime": 985.9441,
      "eval_samples_per_second": 20.895,
      "eval_steps_per_second": 2.613,
      "eval_wer": 1.290348964013086,
      "step": 400
    },
    {
      "epoch": 0.15533310321021745,
      "grad_norm": 52.729854583740234,
      "learning_rate": 3.065239903348292e-06,
      "loss": 35.2303,
      "step": 450
    },
    {
      "epoch": 0.17259233690024162,
      "grad_norm": 57.00068664550781,
      "learning_rate": 3.4104245771487747e-06,
      "loss": 31.1974,
      "step": 500
    },
    {
      "epoch": 0.17259233690024162,
      "eval_loss": 29.80358123779297,
      "eval_runtime": 984.7885,
      "eval_samples_per_second": 20.919,
      "eval_steps_per_second": 2.616,
      "eval_wer": 1.1124456663645998,
      "step": 500
    },
    {
      "epoch": 0.1898515705902658,
      "grad_norm": 69.40511322021484,
      "learning_rate": 3.755609250949258e-06,
      "loss": 26.6198,
      "step": 550
    },
    {
      "epoch": 0.20711080428028997,
      "grad_norm": 74.96147155761719,
      "learning_rate": 4.100793924749741e-06,
      "loss": 24.7157,
      "step": 600
    },
    {
      "epoch": 0.20711080428028997,
      "eval_loss": 22.050580978393555,
      "eval_runtime": 986.8443,
      "eval_samples_per_second": 20.876,
      "eval_steps_per_second": 2.61,
      "eval_wer": 1.0054218440413474,
      "step": 600
    },
    {
      "epoch": 0.22437003797031413,
      "grad_norm": 80.8115234375,
      "learning_rate": 4.445978598550225e-06,
      "loss": 21.4301,
      "step": 650
    },
    {
      "epoch": 0.2416292716603383,
      "grad_norm": 92.70976257324219,
      "learning_rate": 4.791163272350708e-06,
      "loss": 20.0542,
      "step": 700
    },
    {
      "epoch": 0.2416292716603383,
      "eval_loss": 17.28763198852539,
      "eval_runtime": 968.8377,
      "eval_samples_per_second": 21.264,
      "eval_steps_per_second": 2.659,
      "eval_wer": 1.000422381617952,
      "step": 700
    },
    {
      "epoch": 0.25888850535036245,
      "grad_norm": 96.99342346191406,
      "learning_rate": 5.1363479461511915e-06,
      "loss": 16.7274,
      "step": 750
    },
    {
      "epoch": 0.2761477390403866,
      "grad_norm": 114.44609069824219,
      "learning_rate": 5.481532619951674e-06,
      "loss": 15.3303,
      "step": 800
    },
    {
      "epoch": 0.2761477390403866,
      "eval_loss": 13.952067375183105,
      "eval_runtime": 988.9089,
      "eval_samples_per_second": 20.832,
      "eval_steps_per_second": 2.605,
      "eval_wer": 1.0,
      "step": 800
    },
    {
      "epoch": 0.2934069727304108,
      "grad_norm": 97.6893081665039,
      "learning_rate": 5.826717293752157e-06,
      "loss": 14.8966,
      "step": 850
    },
    {
      "epoch": 0.3106662064204349,
      "grad_norm": 94.09905242919922,
      "learning_rate": 6.171901967552641e-06,
      "loss": 14.14,
      "step": 900
    },
    {
      "epoch": 0.3106662064204349,
      "eval_loss": 11.609041213989258,
      "eval_runtime": 986.0393,
      "eval_samples_per_second": 20.893,
      "eval_steps_per_second": 2.612,
      "eval_wer": 1.0,
      "step": 900
    },
    {
      "epoch": 0.3279254401104591,
      "grad_norm": 85.82572937011719,
      "learning_rate": 6.517086641353125e-06,
      "loss": 12.5105,
      "step": 950
    },
    {
      "epoch": 0.34518467380048323,
      "grad_norm": 91.4456558227539,
      "learning_rate": 6.862271315153608e-06,
      "loss": 11.7516,
      "step": 1000
    },
    {
      "epoch": 0.34518467380048323,
      "eval_loss": 9.924674987792969,
      "eval_runtime": 984.2089,
      "eval_samples_per_second": 20.932,
      "eval_steps_per_second": 2.617,
      "eval_wer": 1.0,
      "step": 1000
    },
    {
      "epoch": 0.3624439074905074,
      "grad_norm": 90.55353546142578,
      "learning_rate": 7.207455988954091e-06,
      "loss": 11.2057,
      "step": 1050
    },
    {
      "epoch": 0.3797031411805316,
      "grad_norm": 71.05589294433594,
      "learning_rate": 7.552640662754575e-06,
      "loss": 9.9869,
      "step": 1100
    },
    {
      "epoch": 0.3797031411805316,
      "eval_loss": 8.61476993560791,
      "eval_runtime": 981.5773,
      "eval_samples_per_second": 20.988,
      "eval_steps_per_second": 2.624,
      "eval_wer": 1.0,
      "step": 1100
    },
    {
      "epoch": 0.39696237487055575,
      "grad_norm": 73.52696990966797,
      "learning_rate": 7.897825336555058e-06,
      "loss": 9.2973,
      "step": 1150
    },
    {
      "epoch": 0.41422160856057993,
      "grad_norm": 60.117496490478516,
      "learning_rate": 8.243010010355541e-06,
      "loss": 8.4557,
      "step": 1200
    },
    {
      "epoch": 0.41422160856057993,
      "eval_loss": 7.535671234130859,
      "eval_runtime": 976.1655,
      "eval_samples_per_second": 21.104,
      "eval_steps_per_second": 2.639,
      "eval_wer": 1.0,
      "step": 1200
    },
    {
      "epoch": 0.43148084225060407,
      "grad_norm": 72.49068450927734,
      "learning_rate": 8.588194684156023e-06,
      "loss": 7.9249,
      "step": 1250
    },
    {
      "epoch": 0.44874007594062826,
      "grad_norm": 66.552734375,
      "learning_rate": 8.933379357956507e-06,
      "loss": 7.4402,
      "step": 1300
    },
    {
      "epoch": 0.44874007594062826,
      "eval_loss": 6.613423824310303,
      "eval_runtime": 983.2522,
      "eval_samples_per_second": 20.952,
      "eval_steps_per_second": 2.62,
      "eval_wer": 1.0,
      "step": 1300
    },
    {
      "epoch": 0.4659993096306524,
      "grad_norm": 58.207763671875,
      "learning_rate": 9.278564031756991e-06,
      "loss": 6.7469,
      "step": 1350
    },
    {
      "epoch": 0.4832585433206766,
      "grad_norm": 61.82878494262695,
      "learning_rate": 9.623748705557475e-06,
      "loss": 6.8114,
      "step": 1400
    },
    {
      "epoch": 0.4832585433206766,
      "eval_loss": 5.843001842498779,
      "eval_runtime": 980.2244,
      "eval_samples_per_second": 21.017,
      "eval_steps_per_second": 2.628,
      "eval_wer": 1.0,
      "step": 1400
    },
    {
      "epoch": 0.5005177770107008,
      "grad_norm": 48.08763885498047,
      "learning_rate": 9.968933379357957e-06,
      "loss": 5.992,
      "step": 1450
    },
    {
      "epoch": 0.5177770107007249,
      "grad_norm": 39.31853485107422,
      "learning_rate": 1.031411805315844e-05,
      "loss": 5.8476,
      "step": 1500
    },
    {
      "epoch": 0.5177770107007249,
      "eval_loss": 5.233859539031982,
      "eval_runtime": 980.8444,
      "eval_samples_per_second": 21.003,
      "eval_steps_per_second": 2.626,
      "eval_wer": 1.0,
      "step": 1500
    },
    {
      "epoch": 0.535036244390749,
      "grad_norm": 37.96500778198242,
      "learning_rate": 1.0659302726958924e-05,
      "loss": 5.3173,
      "step": 1550
    },
    {
      "epoch": 0.5522954780807732,
      "grad_norm": 35.98183822631836,
      "learning_rate": 1.1004487400759408e-05,
      "loss": 5.3784,
      "step": 1600
    },
    {
      "epoch": 0.5522954780807732,
      "eval_loss": 4.818850040435791,
      "eval_runtime": 985.4447,
      "eval_samples_per_second": 20.905,
      "eval_steps_per_second": 2.614,
      "eval_wer": 1.0,
      "step": 1600
    },
    {
      "epoch": 0.5695547117707974,
      "grad_norm": 30.533004760742188,
      "learning_rate": 1.134967207455989e-05,
      "loss": 5.1603,
      "step": 1650
    },
    {
      "epoch": 0.5868139454608216,
      "grad_norm": 31.853649139404297,
      "learning_rate": 1.1694856748360373e-05,
      "loss": 4.7892,
      "step": 1700
    },
    {
      "epoch": 0.5868139454608216,
      "eval_loss": 4.521322727203369,
      "eval_runtime": 987.014,
      "eval_samples_per_second": 20.872,
      "eval_steps_per_second": 2.61,
      "eval_wer": 1.0,
      "step": 1700
    },
    {
      "epoch": 0.6040731791508457,
      "grad_norm": 28.00809669494629,
      "learning_rate": 1.2040041422160857e-05,
      "loss": 4.7381,
      "step": 1750
    },
    {
      "epoch": 0.6213324128408698,
      "grad_norm": 19.26862907409668,
      "learning_rate": 1.238522609596134e-05,
      "loss": 4.5199,
      "step": 1800
    },
    {
      "epoch": 0.6213324128408698,
      "eval_loss": 4.195621013641357,
      "eval_runtime": 989.8206,
      "eval_samples_per_second": 20.813,
      "eval_steps_per_second": 2.602,
      "eval_wer": 1.0,
      "step": 1800
    },
    {
      "epoch": 0.6385916465308941,
      "grad_norm": 21.82164192199707,
      "learning_rate": 1.2730410769761821e-05,
      "loss": 4.4116,
      "step": 1850
    },
    {
      "epoch": 0.6558508802209182,
      "grad_norm": 17.261730194091797,
      "learning_rate": 1.3075595443562305e-05,
      "loss": 4.1689,
      "step": 1900
    },
    {
      "epoch": 0.6558508802209182,
      "eval_loss": 3.9157276153564453,
      "eval_runtime": 990.4901,
      "eval_samples_per_second": 20.799,
      "eval_steps_per_second": 2.601,
      "eval_wer": 1.0,
      "step": 1900
    },
    {
      "epoch": 0.6731101139109423,
      "grad_norm": 14.0667085647583,
      "learning_rate": 1.3420780117362789e-05,
      "loss": 4.0001,
      "step": 1950
    },
    {
      "epoch": 0.6903693476009665,
      "grad_norm": 15.688777923583984,
      "learning_rate": 1.3765964791163272e-05,
      "loss": 3.8183,
      "step": 2000
    },
    {
      "epoch": 0.6903693476009665,
      "eval_loss": 3.6995773315429688,
      "eval_runtime": 971.461,
      "eval_samples_per_second": 21.206,
      "eval_steps_per_second": 2.652,
      "eval_wer": 1.0,
      "step": 2000
    },
    {
      "epoch": 0.7076285812909907,
      "grad_norm": 11.197284698486328,
      "learning_rate": 1.4111149464963758e-05,
      "loss": 3.7092,
      "step": 2050
    },
    {
      "epoch": 0.7248878149810148,
      "grad_norm": 6.864049434661865,
      "learning_rate": 1.4456334138764241e-05,
      "loss": 3.6123,
      "step": 2100
    },
    {
      "epoch": 0.7248878149810148,
      "eval_loss": 3.5737812519073486,
      "eval_runtime": 986.4147,
      "eval_samples_per_second": 20.885,
      "eval_steps_per_second": 2.611,
      "eval_wer": 1.0,
      "step": 2100
    },
    {
      "epoch": 0.742147048671039,
      "grad_norm": 9.054518699645996,
      "learning_rate": 1.4801518812564723e-05,
      "loss": 3.519,
      "step": 2150
    },
    {
      "epoch": 0.7594062823610632,
      "grad_norm": 7.2437262535095215,
      "learning_rate": 1.5146703486365207e-05,
      "loss": 3.5194,
      "step": 2200
    },
    {
      "epoch": 0.7594062823610632,
      "eval_loss": 3.528677225112915,
      "eval_runtime": 959.5668,
      "eval_samples_per_second": 21.469,
      "eval_steps_per_second": 2.685,
      "eval_wer": 1.0,
      "step": 2200
    },
    {
      "epoch": 0.7766655160510874,
      "grad_norm": 2.878000020980835,
      "learning_rate": 1.549188816016569e-05,
      "loss": 3.4483,
      "step": 2250
    },
    {
      "epoch": 0.7939247497411115,
      "grad_norm": 3.1249382495880127,
      "learning_rate": 1.5837072833966174e-05,
      "loss": 3.4058,
      "step": 2300
    },
    {
      "epoch": 0.7939247497411115,
      "eval_loss": 3.430966377258301,
      "eval_runtime": 982.9721,
      "eval_samples_per_second": 20.958,
      "eval_steps_per_second": 2.621,
      "eval_wer": 1.0,
      "step": 2300
    },
    {
      "epoch": 0.8111839834311356,
      "grad_norm": 3.178724527359009,
      "learning_rate": 1.6182257507766658e-05,
      "loss": 3.2948,
      "step": 2350
    },
    {
      "epoch": 0.8284432171211599,
      "grad_norm": 3.2591803073883057,
      "learning_rate": 1.6527442181567142e-05,
      "loss": 3.2771,
      "step": 2400
    },
    {
      "epoch": 0.8284432171211599,
      "eval_loss": 3.276263952255249,
      "eval_runtime": 987.0478,
      "eval_samples_per_second": 20.871,
      "eval_steps_per_second": 2.61,
      "eval_wer": 1.0,
      "step": 2400
    },
    {
      "epoch": 0.845702450811184,
      "grad_norm": 2.746955633163452,
      "learning_rate": 1.6872626855367622e-05,
      "loss": 3.3619,
      "step": 2450
    },
    {
      "epoch": 0.8629616845012081,
      "grad_norm": 2.9280598163604736,
      "learning_rate": 1.7217811529168106e-05,
      "loss": 3.256,
      "step": 2500
    },
    {
      "epoch": 0.8629616845012081,
      "eval_loss": 3.2282321453094482,
      "eval_runtime": 979.3496,
      "eval_samples_per_second": 21.035,
      "eval_steps_per_second": 2.63,
      "eval_wer": 1.0,
      "step": 2500
    },
    {
      "epoch": 0.8802209181912323,
      "grad_norm": 6.364762306213379,
      "learning_rate": 1.756299620296859e-05,
      "loss": 3.2307,
      "step": 2550
    },
    {
      "epoch": 0.8974801518812565,
      "grad_norm": 3.3601160049438477,
      "learning_rate": 1.7908180876769073e-05,
      "loss": 3.2465,
      "step": 2600
    },
    {
      "epoch": 0.8974801518812565,
      "eval_loss": 3.18996262550354,
      "eval_runtime": 980.3474,
      "eval_samples_per_second": 21.014,
      "eval_steps_per_second": 2.628,
      "eval_wer": 1.0,
      "step": 2600
    },
    {
      "epoch": 0.9147393855712806,
      "grad_norm": 4.195175647735596,
      "learning_rate": 1.8253365550569557e-05,
      "loss": 3.1579,
      "step": 2650
    },
    {
      "epoch": 0.9319986192613048,
      "grad_norm": 4.406469821929932,
      "learning_rate": 1.859855022437004e-05,
      "loss": 3.2107,
      "step": 2700
    },
    {
      "epoch": 0.9319986192613048,
      "eval_loss": 3.2171268463134766,
      "eval_runtime": 961.1156,
      "eval_samples_per_second": 21.434,
      "eval_steps_per_second": 2.68,
      "eval_wer": 1.0,
      "step": 2700
    },
    {
      "epoch": 0.9492578529513289,
      "grad_norm": 4.986827850341797,
      "learning_rate": 1.8943734898170524e-05,
      "loss": 3.1576,
      "step": 2750
    },
    {
      "epoch": 0.9665170866413532,
      "grad_norm": 5.558589935302734,
      "learning_rate": 1.9288919571971005e-05,
      "loss": 3.0942,
      "step": 2800
    },
    {
      "epoch": 0.9665170866413532,
      "eval_loss": 3.139652967453003,
      "eval_runtime": 1008.2743,
      "eval_samples_per_second": 20.432,
      "eval_steps_per_second": 2.555,
      "eval_wer": 1.0,
      "step": 2800
    },
    {
      "epoch": 0.9837763203313773,
      "grad_norm": 3.283506393432617,
      "learning_rate": 1.963410424577149e-05,
      "loss": 3.1508,
      "step": 2850
    },
    {
      "epoch": 1.0010355540214015,
      "grad_norm": 0.9832563996315002,
      "learning_rate": 1.9979288919571972e-05,
      "loss": 3.0463,
      "step": 2900
    },
    {
      "epoch": 1.0010355540214015,
      "eval_loss": 3.1136651039123535,
      "eval_runtime": 1007.7001,
      "eval_samples_per_second": 20.444,
      "eval_steps_per_second": 2.556,
      "eval_wer": 1.0,
      "step": 2900
    },
    {
      "epoch": 1.0182947877114257,
      "grad_norm": 0.44945359230041504,
      "learning_rate": 2.0324473593372456e-05,
      "loss": 3.0884,
      "step": 2950
    },
    {
      "epoch": 1.0355540214014498,
      "grad_norm": 0.2480493187904358,
      "learning_rate": 2.066965826717294e-05,
      "loss": 3.0608,
      "step": 3000
    },
    {
      "epoch": 1.0355540214014498,
      "eval_loss": 3.1199371814727783,
      "eval_runtime": 1031.1993,
      "eval_samples_per_second": 19.978,
      "eval_steps_per_second": 2.498,
      "eval_wer": 1.0,
      "step": 3000
    },
    {
      "epoch": 1.052813255091474,
      "grad_norm": 0.9047137498855591,
      "learning_rate": 2.1014842940973423e-05,
      "loss": 3.0281,
      "step": 3050
    },
    {
      "epoch": 1.070072488781498,
      "grad_norm": 0.40400388836860657,
      "learning_rate": 2.1360027614773907e-05,
      "loss": 3.0678,
      "step": 3100
    },
    {
      "epoch": 1.070072488781498,
      "eval_loss": 3.091989278793335,
      "eval_runtime": 1028.1114,
      "eval_samples_per_second": 20.038,
      "eval_steps_per_second": 2.506,
      "eval_wer": 1.0,
      "step": 3100
    },
    {
      "epoch": 1.0873317224715222,
      "grad_norm": 2.8298094272613525,
      "learning_rate": 2.170521228857439e-05,
      "loss": 3.0496,
      "step": 3150
    },
    {
      "epoch": 1.1045909561615463,
      "grad_norm": 0.45390230417251587,
      "learning_rate": 2.205039696237487e-05,
      "loss": 3.0751,
      "step": 3200
    },
    {
      "epoch": 1.1045909561615463,
      "eval_loss": 3.0380449295043945,
      "eval_runtime": 1017.903,
      "eval_samples_per_second": 20.239,
      "eval_steps_per_second": 2.531,
      "eval_wer": 1.0,
      "step": 3200
    },
    {
      "epoch": 1.1218501898515707,
      "grad_norm": 2.8445208072662354,
      "learning_rate": 2.2395581636175355e-05,
      "loss": 3.0456,
      "step": 3250
    },
    {
      "epoch": 1.1391094235415948,
      "grad_norm": 8.69057559967041,
      "learning_rate": 2.274076630997584e-05,
      "loss": 3.0724,
      "step": 3300
    },
    {
      "epoch": 1.1391094235415948,
      "eval_loss": 3.0572667121887207,
      "eval_runtime": 982.4091,
      "eval_samples_per_second": 20.97,
      "eval_steps_per_second": 2.622,
      "eval_wer": 1.0,
      "step": 3300
    },
    {
      "epoch": 1.156368657231619,
      "grad_norm": 1.5522992610931396,
      "learning_rate": 2.3085950983776322e-05,
      "loss": 3.0041,
      "step": 3350
    },
    {
      "epoch": 1.173627890921643,
      "grad_norm": 0.39234861731529236,
      "learning_rate": 2.3431135657576806e-05,
      "loss": 2.9585,
      "step": 3400
    },
    {
      "epoch": 1.173627890921643,
      "eval_loss": 3.0009348392486572,
      "eval_runtime": 1024.7594,
      "eval_samples_per_second": 20.103,
      "eval_steps_per_second": 2.514,
      "eval_wer": 1.0,
      "step": 3400
    },
    {
      "epoch": 1.1908871246116672,
      "grad_norm": 1.0751056671142578,
      "learning_rate": 2.377632033137729e-05,
      "loss": 2.9542,
      "step": 3450
    },
    {
      "epoch": 1.2081463583016914,
      "grad_norm": 0.71683269739151,
      "learning_rate": 2.4121505005177773e-05,
      "loss": 2.9621,
      "step": 3500
    },
    {
      "epoch": 1.2081463583016914,
      "eval_loss": 2.958608388900757,
      "eval_runtime": 1022.3394,
      "eval_samples_per_second": 20.151,
      "eval_steps_per_second": 2.52,
      "eval_wer": 1.0,
      "step": 3500
    },
    {
      "epoch": 1.2254055919917155,
      "grad_norm": 0.331440269947052,
      "learning_rate": 2.4466689678978254e-05,
      "loss": 2.9118,
      "step": 3550
    },
    {
      "epoch": 1.2426648256817396,
      "grad_norm": 0.3005501627922058,
      "learning_rate": 2.4811874352778737e-05,
      "loss": 2.9171,
      "step": 3600
    },
    {
      "epoch": 1.2426648256817396,
      "eval_loss": 2.9733996391296387,
      "eval_runtime": 1023.1056,
      "eval_samples_per_second": 20.136,
      "eval_steps_per_second": 2.518,
      "eval_wer": 1.0,
      "step": 3600
    },
    {
      "epoch": 1.2599240593717638,
      "grad_norm": 0.2681855857372284,
      "learning_rate": 2.515705902657922e-05,
      "loss": 2.8795,
      "step": 3650
    },
    {
      "epoch": 1.2771832930617881,
      "grad_norm": 0.6174575090408325,
      "learning_rate": 2.55022437003797e-05,
      "loss": 2.8891,
      "step": 3700
    },
    {
      "epoch": 1.2771832930617881,
      "eval_loss": 2.978745698928833,
      "eval_runtime": 991.9155,
      "eval_samples_per_second": 20.769,
      "eval_steps_per_second": 2.597,
      "eval_wer": 1.0,
      "step": 3700
    },
    {
      "epoch": 1.2944425267518123,
      "grad_norm": 1.9137359857559204,
      "learning_rate": 2.584742837418019e-05,
      "loss": 2.8734,
      "step": 3750
    },
    {
      "epoch": 1.3117017604418364,
      "grad_norm": 0.2369469702243805,
      "learning_rate": 2.618570935450466e-05,
      "loss": 2.9044,
      "step": 3800
    },
    {
      "epoch": 1.3117017604418364,
      "eval_loss": 2.9651331901550293,
      "eval_runtime": 976.9736,
      "eval_samples_per_second": 21.087,
      "eval_steps_per_second": 2.637,
      "eval_wer": 1.0,
      "step": 3800
    },
    {
      "epoch": 1.3289609941318605,
      "grad_norm": 0.7353858351707458,
      "learning_rate": 2.653089402830514e-05,
      "loss": 2.8811,
      "step": 3850
    },
    {
      "epoch": 1.3462202278218847,
      "grad_norm": 0.26435554027557373,
      "learning_rate": 2.687607870210563e-05,
      "loss": 2.866,
      "step": 3900
    },
    {
      "epoch": 1.3462202278218847,
      "eval_loss": 2.9398365020751953,
      "eval_runtime": 992.4726,
      "eval_samples_per_second": 20.757,
      "eval_steps_per_second": 2.596,
      "eval_wer": 1.0,
      "step": 3900
    },
    {
      "epoch": 1.3634794615119088,
      "grad_norm": 0.3826865255832672,
      "learning_rate": 2.722126337590611e-05,
      "loss": 2.8474,
      "step": 3950
    },
    {
      "epoch": 1.380738695201933,
      "grad_norm": 2.8167519569396973,
      "learning_rate": 2.7566448049706596e-05,
      "loss": 2.8435,
      "step": 4000
    },
    {
      "epoch": 1.380738695201933,
      "eval_loss": 2.8486289978027344,
      "eval_runtime": 1002.4922,
      "eval_samples_per_second": 20.55,
      "eval_steps_per_second": 2.57,
      "eval_wer": 1.0,
      "step": 4000
    },
    {
      "epoch": 1.3979979288919573,
      "grad_norm": 2.4925410747528076,
      "learning_rate": 2.7911632723507076e-05,
      "loss": 2.8465,
      "step": 4050
    },
    {
      "epoch": 1.4152571625819814,
      "grad_norm": 1.7813434600830078,
      "learning_rate": 2.825681739730756e-05,
      "loss": 2.8318,
      "step": 4100
    },
    {
      "epoch": 1.4152571625819814,
      "eval_loss": 2.8543167114257812,
      "eval_runtime": 1009.158,
      "eval_samples_per_second": 20.414,
      "eval_steps_per_second": 2.553,
      "eval_wer": 1.0,
      "step": 4100
    },
    {
      "epoch": 1.4325163962720056,
      "grad_norm": 1.3165812492370605,
      "learning_rate": 2.860200207110804e-05,
      "loss": 2.8305,
      "step": 4150
    },
    {
      "epoch": 1.4497756299620297,
      "grad_norm": 0.7072382569313049,
      "learning_rate": 2.8947186744908527e-05,
      "loss": 2.8376,
      "step": 4200
    },
    {
      "epoch": 1.4497756299620297,
      "eval_loss": 2.8780903816223145,
      "eval_runtime": 1017.6679,
      "eval_samples_per_second": 20.243,
      "eval_steps_per_second": 2.531,
      "eval_wer": 1.0,
      "step": 4200
    },
    {
      "epoch": 1.4670348636520538,
      "grad_norm": 0.8518475294113159,
      "learning_rate": 2.9292371418709008e-05,
      "loss": 2.7926,
      "step": 4250
    },
    {
      "epoch": 1.484294097342078,
      "grad_norm": 1.7973687648773193,
      "learning_rate": 2.9637556092509495e-05,
      "loss": 2.792,
      "step": 4300
    },
    {
      "epoch": 1.484294097342078,
      "eval_loss": 2.7845892906188965,
      "eval_runtime": 1022.9646,
      "eval_samples_per_second": 20.139,
      "eval_steps_per_second": 2.518,
      "eval_wer": 1.0,
      "step": 4300
    },
    {
      "epoch": 1.501553331032102,
      "grad_norm": 0.17206625640392303,
      "learning_rate": 2.9982740766309975e-05,
      "loss": 2.7527,
      "step": 4350
    },
    {
      "epoch": 1.5188125647221264,
      "grad_norm": 0.3113628625869751,
      "learning_rate": 3.0327925440110462e-05,
      "loss": 2.7533,
      "step": 4400
    },
    {
      "epoch": 1.5188125647221264,
      "eval_loss": 2.828322172164917,
      "eval_runtime": 1042.0926,
      "eval_samples_per_second": 19.769,
      "eval_steps_per_second": 2.472,
      "eval_wer": 1.0,
      "step": 4400
    },
    {
      "epoch": 1.5360717984121504,
      "grad_norm": 0.34769880771636963,
      "learning_rate": 3.067311011391094e-05,
      "loss": 2.7569,
      "step": 4450
    },
    {
      "epoch": 1.5533310321021747,
      "grad_norm": 0.4419816732406616,
      "learning_rate": 3.1018294787711426e-05,
      "loss": 2.7692,
      "step": 4500
    },
    {
      "epoch": 1.5533310321021747,
      "eval_loss": 2.7721219062805176,
      "eval_runtime": 1030.0773,
      "eval_samples_per_second": 19.999,
      "eval_steps_per_second": 2.501,
      "eval_wer": 1.0,
      "step": 4500
    },
    {
      "epoch": 1.5705902657921988,
      "grad_norm": 0.30181577801704407,
      "learning_rate": 3.1363479461511906e-05,
      "loss": 2.7204,
      "step": 4550
    },
    {
      "epoch": 1.587849499482223,
      "grad_norm": 0.2788453996181488,
      "learning_rate": 3.1708664135312394e-05,
      "loss": 2.7129,
      "step": 4600
    },
    {
      "epoch": 1.587849499482223,
      "eval_loss": 2.735438108444214,
      "eval_runtime": 1027.5165,
      "eval_samples_per_second": 20.049,
      "eval_steps_per_second": 2.507,
      "eval_wer": 1.0,
      "step": 4600
    },
    {
      "epoch": 1.6051087331722471,
      "grad_norm": 0.4921347200870514,
      "learning_rate": 3.205384880911288e-05,
      "loss": 2.6942,
      "step": 4650
    },
    {
      "epoch": 1.6223679668622712,
      "grad_norm": 0.23185350000858307,
      "learning_rate": 3.239903348291336e-05,
      "loss": 2.6746,
      "step": 4700
    },
    {
      "epoch": 1.6223679668622712,
      "eval_loss": 2.703523874282837,
      "eval_runtime": 1043.7305,
      "eval_samples_per_second": 19.738,
      "eval_steps_per_second": 2.468,
      "eval_wer": 1.0,
      "step": 4700
    },
    {
      "epoch": 1.6396272005522956,
      "grad_norm": 0.5674828886985779,
      "learning_rate": 3.274421815671385e-05,
      "loss": 2.6818,
      "step": 4750
    },
    {
      "epoch": 1.6568864342423195,
      "grad_norm": 0.3024155795574188,
      "learning_rate": 3.308940283051433e-05,
      "loss": 2.6701,
      "step": 4800
    },
    {
      "epoch": 1.6568864342423195,
      "eval_loss": 2.6661295890808105,
      "eval_runtime": 1031.7778,
      "eval_samples_per_second": 19.967,
      "eval_steps_per_second": 2.497,
      "eval_wer": 1.0,
      "step": 4800
    },
    {
      "epoch": 1.6741456679323439,
      "grad_norm": 1.6657239198684692,
      "learning_rate": 3.3434587504314815e-05,
      "loss": 2.6038,
      "step": 4850
    },
    {
      "epoch": 1.691404901622368,
      "grad_norm": 0.40385809540748596,
      "learning_rate": 3.3779772178115296e-05,
      "loss": 2.5729,
      "step": 4900
    },
    {
      "epoch": 1.691404901622368,
      "eval_loss": 2.514028787612915,
      "eval_runtime": 1035.6318,
      "eval_samples_per_second": 19.892,
      "eval_steps_per_second": 2.487,
      "eval_wer": 1.0000038398328905,
      "step": 4900
    },
    {
      "epoch": 1.7086641353123921,
      "grad_norm": 0.43571048974990845,
      "learning_rate": 3.4124956851915776e-05,
      "loss": 2.5257,
      "step": 4950
    },
    {
      "epoch": 1.7259233690024163,
      "grad_norm": 1.6262016296386719,
      "learning_rate": 3.4470141525716256e-05,
      "loss": 2.4809,
      "step": 5000
    },
    {
      "epoch": 1.7259233690024163,
      "eval_loss": 2.4075517654418945,
      "eval_runtime": 1040.5023,
      "eval_samples_per_second": 19.799,
      "eval_steps_per_second": 2.476,
      "eval_wer": 0.9997772896923526,
      "step": 5000
    },
    {
      "epoch": 1.7431826026924404,
      "grad_norm": 0.5365813970565796,
      "learning_rate": 3.4815326199516744e-05,
      "loss": 2.4377,
      "step": 5050
    },
    {
      "epoch": 1.7604418363824648,
      "grad_norm": 0.47128409147262573,
      "learning_rate": 3.5160510873317224e-05,
      "loss": 2.393,
      "step": 5100
    },
    {
      "epoch": 1.7604418363824648,
      "eval_loss": 2.2798900604248047,
      "eval_runtime": 1012.8189,
      "eval_samples_per_second": 20.34,
      "eval_steps_per_second": 2.543,
      "eval_wer": 1.0001151949867142,
      "step": 5100
    },
    {
      "epoch": 1.7777010700724887,
      "grad_norm": 0.7151248455047607,
      "learning_rate": 3.550569554711771e-05,
      "loss": 2.3355,
      "step": 5150
    },
    {
      "epoch": 1.794960303762513,
      "grad_norm": 0.6900324821472168,
      "learning_rate": 3.585088022091819e-05,
      "loss": 2.2597,
      "step": 5200
    },
    {
      "epoch": 1.794960303762513,
      "eval_loss": 2.111785650253296,
      "eval_runtime": 1002.3351,
      "eval_samples_per_second": 20.553,
      "eval_steps_per_second": 2.57,
      "eval_wer": 0.9948546239267667,
      "step": 5200
    },
    {
      "epoch": 1.812219537452537,
      "grad_norm": 0.628966748714447,
      "learning_rate": 3.619606489471868e-05,
      "loss": 2.2076,
      "step": 5250
    },
    {
      "epoch": 1.8294787711425613,
      "grad_norm": 0.6360865831375122,
      "learning_rate": 3.654124956851916e-05,
      "loss": 2.1692,
      "step": 5300
    },
    {
      "epoch": 1.8294787711425613,
      "eval_loss": 1.9104037284851074,
      "eval_runtime": 1021.9903,
      "eval_samples_per_second": 20.158,
      "eval_steps_per_second": 2.521,
      "eval_wer": 0.9488764648962477,
      "step": 5300
    },
    {
      "epoch": 1.8467380048325854,
      "grad_norm": 0.6318406462669373,
      "learning_rate": 3.6886434242319646e-05,
      "loss": 2.0717,
      "step": 5350
    },
    {
      "epoch": 1.8639972385226096,
      "grad_norm": 1.6790069341659546,
      "learning_rate": 3.7231618916120126e-05,
      "loss": 2.0272,
      "step": 5400
    },
    {
      "epoch": 1.8639972385226096,
      "eval_loss": 1.6966320276260376,
      "eval_runtime": 1023.6928,
      "eval_samples_per_second": 20.124,
      "eval_steps_per_second": 2.516,
      "eval_wer": 0.91737063602992,
      "step": 5400
    },
    {
      "epoch": 1.881256472212634,
      "grad_norm": 1.2688915729522705,
      "learning_rate": 3.757680358992061e-05,
      "loss": 1.9528,
      "step": 5450
    },
    {
      "epoch": 1.8985157059026578,
      "grad_norm": 0.5804014205932617,
      "learning_rate": 3.7921988263721093e-05,
      "loss": 1.9247,
      "step": 5500
    },
    {
      "epoch": 1.8985157059026578,
      "eval_loss": 1.65335214138031,
      "eval_runtime": 1023.9492,
      "eval_samples_per_second": 20.119,
      "eval_steps_per_second": 2.516,
      "eval_wer": 0.8051553596387485,
      "step": 5500
    },
    {
      "epoch": 1.9157749395926822,
      "grad_norm": 0.678859531879425,
      "learning_rate": 3.826717293752158e-05,
      "loss": 1.8171,
      "step": 5550
    },
    {
      "epoch": 1.933034173282706,
      "grad_norm": 0.67691570520401,
      "learning_rate": 3.861235761132206e-05,
      "loss": 1.7767,
      "step": 5600
    },
    {
      "epoch": 1.933034173282706,
      "eval_loss": 1.504286289215088,
      "eval_runtime": 1019.0981,
      "eval_samples_per_second": 20.215,
      "eval_steps_per_second": 2.528,
      "eval_wer": 0.7329281029689588,
      "step": 5600
    },
    {
      "epoch": 1.9502934069727305,
      "grad_norm": 1.5084998607635498,
      "learning_rate": 3.895754228512255e-05,
      "loss": 1.7199,
      "step": 5650
    },
    {
      "epoch": 1.9675526406627546,
      "grad_norm": 0.6489958167076111,
      "learning_rate": 3.930272695892303e-05,
      "loss": 1.6606,
      "step": 5700
    },
    {
      "epoch": 1.9675526406627546,
      "eval_loss": 1.5877189636230469,
      "eval_runtime": 996.2453,
      "eval_samples_per_second": 20.679,
      "eval_steps_per_second": 2.586,
      "eval_wer": 0.6697398129233416,
      "step": 5700
    },
    {
      "epoch": 1.9848118743527787,
      "grad_norm": 1.0867018699645996,
      "learning_rate": 3.964791163272351e-05,
      "loss": 1.7415,
      "step": 5750
    },
    {
      "epoch": 2.002071108042803,
      "grad_norm": 0.6687357425689697,
      "learning_rate": 3.999309630652399e-05,
      "loss": 1.5914,
      "step": 5800
    },
    {
      "epoch": 2.002071108042803,
      "eval_loss": 1.3654704093933105,
      "eval_runtime": 996.7906,
      "eval_samples_per_second": 20.667,
      "eval_steps_per_second": 2.584,
      "eval_wer": 0.5978197428847897,
      "step": 5800
    },
    {
      "epoch": 2.019330341732827,
      "grad_norm": 0.962689995765686,
      "learning_rate": 4.0338280980324476e-05,
      "loss": 1.5581,
      "step": 5850
    },
    {
      "epoch": 2.0365895754228514,
      "grad_norm": 0.9611998200416565,
      "learning_rate": 4.0683465654124956e-05,
      "loss": 1.4621,
      "step": 5900
    },
    {
      "epoch": 2.0365895754228514,
      "eval_loss": 1.2259583473205566,
      "eval_runtime": 1018.6081,
      "eval_samples_per_second": 20.225,
      "eval_steps_per_second": 2.529,
      "eval_wer": 0.515908427665228,
      "step": 5900
    },
    {
      "epoch": 2.0538488091128753,
      "grad_norm": 0.8810312151908875,
      "learning_rate": 4.1028650327925443e-05,
      "loss": 1.45,
      "step": 5950
    },
    {
      "epoch": 2.0711080428028996,
      "grad_norm": 0.7442783117294312,
      "learning_rate": 4.1373835001725924e-05,
      "loss": 1.3876,
      "step": 6000
    },
    {
      "epoch": 2.0711080428028996,
      "eval_loss": 1.1977050304412842,
      "eval_runtime": 1015.2202,
      "eval_samples_per_second": 20.292,
      "eval_steps_per_second": 2.537,
      "eval_wer": 0.4888299261216152,
      "step": 6000
    },
    {
      "epoch": 2.0883672764929235,
      "grad_norm": 0.7530454397201538,
      "learning_rate": 4.171901967552641e-05,
      "loss": 1.3649,
      "step": 6050
    },
    {
      "epoch": 2.105626510182948,
      "grad_norm": 65.84537506103516,
      "learning_rate": 4.206420434932689e-05,
      "loss": 1.3783,
      "step": 6100
    },
    {
      "epoch": 2.105626510182948,
      "eval_loss": 1.1473065614700317,
      "eval_runtime": 999.4578,
      "eval_samples_per_second": 20.612,
      "eval_steps_per_second": 2.577,
      "eval_wer": 0.4481123381510437,
      "step": 6100
    },
    {
      "epoch": 2.1228857438729722,
      "grad_norm": 0.7733381390571594,
      "learning_rate": 4.240938902312738e-05,
      "loss": 1.3804,
      "step": 6150
    },
    {
      "epoch": 2.140144977562996,
      "grad_norm": 0.7085464000701904,
      "learning_rate": 4.275457369692786e-05,
      "loss": 1.2724,
      "step": 6200
    },
    {
      "epoch": 2.140144977562996,
      "eval_loss": 1.0739744901657104,
      "eval_runtime": 1012.9305,
      "eval_samples_per_second": 20.338,
      "eval_steps_per_second": 2.543,
      "eval_wer": 0.41631084215214953,
      "step": 6200
    },
    {
      "epoch": 2.1574042112530205,
      "grad_norm": 0.7036454677581787,
      "learning_rate": 4.3099758370728346e-05,
      "loss": 1.2642,
      "step": 6250
    },
    {
      "epoch": 2.1746634449430444,
      "grad_norm": 0.8405923247337341,
      "learning_rate": 4.3444943044528826e-05,
      "loss": 1.3371,
      "step": 6300
    },
    {
      "epoch": 2.1746634449430444,
      "eval_loss": 0.9090977311134338,
      "eval_runtime": 1007.5259,
      "eval_samples_per_second": 20.447,
      "eval_steps_per_second": 2.557,
      "eval_wer": 0.3941127682123274,
      "step": 6300
    },
    {
      "epoch": 2.1919226786330688,
      "grad_norm": 0.6818956732749939,
      "learning_rate": 4.37832240248533e-05,
      "loss": 1.2283,
      "step": 6350
    },
    {
      "epoch": 2.2091819123230927,
      "grad_norm": 0.7307966351509094,
      "learning_rate": 4.4128408698653786e-05,
      "loss": 1.228,
      "step": 6400
    },
    {
      "epoch": 2.2091819123230927,
      "eval_loss": 0.9962966442108154,
      "eval_runtime": 1012.8724,
      "eval_samples_per_second": 20.339,
      "eval_steps_per_second": 2.543,
      "eval_wer": 0.37704471101417664,
      "step": 6400
    },
    {
      "epoch": 2.226441146013117,
      "grad_norm": 0.7280385494232178,
      "learning_rate": 4.4473593372454266e-05,
      "loss": 1.2013,
      "step": 6450
    },
    {
      "epoch": 2.2437003797031414,
      "grad_norm": 0.7679833769798279,
      "learning_rate": 4.481877804625475e-05,
      "loss": 1.1927,
      "step": 6500
    },
    {
      "epoch": 2.2437003797031414,
      "eval_loss": 0.9759249091148376,
      "eval_runtime": 1014.4282,
      "eval_samples_per_second": 20.308,
      "eval_steps_per_second": 2.539,
      "eval_wer": 0.36234199087655705,
      "step": 6500
    },
    {
      "epoch": 2.2609596133931653,
      "grad_norm": 0.7910636067390442,
      "learning_rate": 4.5163962720055234e-05,
      "loss": 1.161,
      "step": 6550
    },
    {
      "epoch": 2.2782188470831897,
      "grad_norm": 0.7768646478652954,
      "learning_rate": 4.5509147393855714e-05,
      "loss": 1.1405,
      "step": 6600
    },
    {
      "epoch": 2.2782188470831897,
      "eval_loss": 0.825416088104248,
      "eval_runtime": 1011.9407,
      "eval_samples_per_second": 20.358,
      "eval_steps_per_second": 2.546,
      "eval_wer": 0.34796181670173715,
      "step": 6600
    },
    {
      "epoch": 2.2954780807732136,
      "grad_norm": 0.7597507238388062,
      "learning_rate": 4.5854332067656194e-05,
      "loss": 1.1712,
      "step": 6650
    },
    {
      "epoch": 2.312737314463238,
      "grad_norm": 0.7570703625679016,
      "learning_rate": 4.619951674145668e-05,
      "loss": 1.1377,
      "step": 6700
    },
    {
      "epoch": 2.312737314463238,
      "eval_loss": 0.9806742668151855,
      "eval_runtime": 1018.4955,
      "eval_samples_per_second": 20.227,
      "eval_steps_per_second": 2.529,
      "eval_wer": 0.3418795214032285,
      "step": 6700
    },
    {
      "epoch": 2.329996548153262,
      "grad_norm": 0.8223168253898621,
      "learning_rate": 4.654470141525716e-05,
      "loss": 1.1582,
      "step": 6750
    },
    {
      "epoch": 2.347255781843286,
      "grad_norm": 0.6907560229301453,
      "learning_rate": 4.688988608905765e-05,
      "loss": 1.1183,
      "step": 6800
    },
    {
      "epoch": 2.347255781843286,
      "eval_loss": 0.9229022264480591,
      "eval_runtime": 1020.5412,
      "eval_samples_per_second": 20.186,
      "eval_steps_per_second": 2.524,
      "eval_wer": 0.3225037246379038,
      "step": 6800
    },
    {
      "epoch": 2.3645150155333106,
      "grad_norm": 0.7168479561805725,
      "learning_rate": 4.723507076285813e-05,
      "loss": 1.2096,
      "step": 6850
    },
    {
      "epoch": 2.3817742492233345,
      "grad_norm": 0.7525056600570679,
      "learning_rate": 4.7580255436658616e-05,
      "loss": 1.0996,
      "step": 6900
    },
    {
      "epoch": 2.3817742492233345,
      "eval_loss": 0.9198316335678101,
      "eval_runtime": 1028.8856,
      "eval_samples_per_second": 20.023,
      "eval_steps_per_second": 2.504,
      "eval_wer": 0.31691292794937564,
      "step": 6900
    },
    {
      "epoch": 2.399033482913359,
      "grad_norm": 0.7929342985153198,
      "learning_rate": 4.7925440110459096e-05,
      "loss": 1.1805,
      "step": 6950
    },
    {
      "epoch": 2.4162927166033827,
      "grad_norm": 0.7546581029891968,
      "learning_rate": 4.8270624784259583e-05,
      "loss": 1.1582,
      "step": 7000
    },
    {
      "epoch": 2.4162927166033827,
      "eval_loss": 0.9246257543563843,
      "eval_runtime": 1029.7912,
      "eval_samples_per_second": 20.005,
      "eval_steps_per_second": 2.501,
      "eval_wer": 0.3048212941772774,
      "step": 7000
    },
    {
      "epoch": 2.433551950293407,
      "grad_norm": 0.7344025373458862,
      "learning_rate": 4.8615809458060064e-05,
      "loss": 1.0604,
      "step": 7050
    },
    {
      "epoch": 2.450811183983431,
      "grad_norm": 0.8235825300216675,
      "learning_rate": 4.896099413186055e-05,
      "loss": 1.0752,
      "step": 7100
    },
    {
      "epoch": 2.450811183983431,
      "eval_loss": 0.748937726020813,
      "eval_runtime": 1015.549,
      "eval_samples_per_second": 20.286,
      "eval_steps_per_second": 2.537,
      "eval_wer": 0.2992842551492159,
      "step": 7100
    },
    {
      "epoch": 2.4680704176734554,
      "grad_norm": 0.755547285079956,
      "learning_rate": 4.930617880566103e-05,
      "loss": 1.0297,
      "step": 7150
    },
    {
      "epoch": 2.4853296513634793,
      "grad_norm": 0.9350526928901672,
      "learning_rate": 4.965136347946152e-05,
      "loss": 1.0195,
      "step": 7200
    },
    {
      "epoch": 2.4853296513634793,
      "eval_loss": 0.8476450443267822,
      "eval_runtime": 1027.4553,
      "eval_samples_per_second": 20.051,
      "eval_steps_per_second": 2.507,
      "eval_wer": 0.29703411307539895,
      "step": 7200
    },
    {
      "epoch": 2.5025888850535036,
      "grad_norm": 0.6266201138496399,
      "learning_rate": 4.9996548153262e-05,
      "loss": 1.0283,
      "step": 7250
    },
    {
      "epoch": 2.5198481187435275,
      "grad_norm": 0.726747989654541,
      "learning_rate": 5.034173282706248e-05,
      "loss": 1.0654,
      "step": 7300
    },
    {
      "epoch": 2.5198481187435275,
      "eval_loss": 0.7263708710670471,
      "eval_runtime": 1020.657,
      "eval_samples_per_second": 20.184,
      "eval_steps_per_second": 2.524,
      "eval_wer": 0.27333466447540206,
      "step": 7300
    },
    {
      "epoch": 2.537107352433552,
      "grad_norm": 0.6768484711647034,
      "learning_rate": 5.0686917500862966e-05,
      "loss": 1.0708,
      "step": 7350
    },
    {
      "epoch": 2.5543665861235763,
      "grad_norm": 1.7002556324005127,
      "learning_rate": 5.1032102174663446e-05,
      "loss": 1.0594,
      "step": 7400
    },
    {
      "epoch": 2.5543665861235763,
      "eval_loss": 0.7290697693824768,
      "eval_runtime": 1007.1559,
      "eval_samples_per_second": 20.455,
      "eval_steps_per_second": 2.558,
      "eval_wer": 0.27377240542491593,
      "step": 7400
    },
    {
      "epoch": 2.5716258198136,
      "grad_norm": 0.765991747379303,
      "learning_rate": 5.1377286848463933e-05,
      "loss": 1.0009,
      "step": 7450
    },
    {
      "epoch": 2.5888850535036245,
      "grad_norm": 0.7416902780532837,
      "learning_rate": 5.1722471522264414e-05,
      "loss": 1.0852,
      "step": 7500
    },
    {
      "epoch": 2.5888850535036245,
      "eval_loss": 0.8311453461647034,
      "eval_runtime": 1005.6407,
      "eval_samples_per_second": 20.485,
      "eval_steps_per_second": 2.562,
      "eval_wer": 0.267517317646336,
      "step": 7500
    },
    {
      "epoch": 2.606144287193649,
      "grad_norm": 0.6872143745422363,
      "learning_rate": 5.2067656196064894e-05,
      "loss": 0.9946,
      "step": 7550
    },
    {
      "epoch": 2.623403520883673,
      "grad_norm": 0.7952913641929626,
      "learning_rate": 5.2412840869865374e-05,
      "loss": 1.0139,
      "step": 7600
    },
    {
      "epoch": 2.623403520883673,
      "eval_loss": 0.720009446144104,
      "eval_runtime": 1012.7142,
      "eval_samples_per_second": 20.342,
      "eval_steps_per_second": 2.544,
      "eval_wer": 0.25613605295897524,
      "step": 7600
    },
    {
      "epoch": 2.6406627545736967,
      "grad_norm": 0.7267958521842957,
      "learning_rate": 5.275802554366587e-05,
      "loss": 0.9964,
      "step": 7650
    },
    {
      "epoch": 2.657921988263721,
      "grad_norm": 0.633553683757782,
      "learning_rate": 5.310321021746635e-05,
      "loss": 0.9688,
      "step": 7700
    },
    {
      "epoch": 2.657921988263721,
      "eval_loss": 0.7046945095062256,
      "eval_runtime": 1031.1285,
      "eval_samples_per_second": 19.979,
      "eval_steps_per_second": 2.498,
      "eval_wer": 0.2423049748874929,
      "step": 7700
    },
    {
      "epoch": 2.6751812219537454,
      "grad_norm": 0.7387465238571167,
      "learning_rate": 5.344839489126683e-05,
      "loss": 1.0035,
      "step": 7750
    },
    {
      "epoch": 2.6924404556437693,
      "grad_norm": 0.6345015168190002,
      "learning_rate": 5.379357956506731e-05,
      "loss": 0.9872,
      "step": 7800
    },
    {
      "epoch": 2.6924404556437693,
      "eval_loss": 0.8439691662788391,
      "eval_runtime": 1019.0195,
      "eval_samples_per_second": 20.216,
      "eval_steps_per_second": 2.528,
      "eval_wer": 0.24877125347504878,
      "step": 7800
    },
    {
      "epoch": 2.7096996893337937,
      "grad_norm": 0.6608285903930664,
      "learning_rate": 5.41387642388678e-05,
      "loss": 1.0027,
      "step": 7850
    },
    {
      "epoch": 2.7269589230238176,
      "grad_norm": 0.6778585910797119,
      "learning_rate": 5.448394891266828e-05,
      "loss": 0.9512,
      "step": 7900
    },
    {
      "epoch": 2.7269589230238176,
      "eval_loss": 0.7800287008285522,
      "eval_runtime": 1031.7247,
      "eval_samples_per_second": 19.968,
      "eval_steps_per_second": 2.497,
      "eval_wer": 0.24113766568878922,
      "step": 7900
    },
    {
      "epoch": 2.744218156713842,
      "grad_norm": 0.7490084171295166,
      "learning_rate": 5.4829133586468764e-05,
      "loss": 0.9249,
      "step": 7950
    },
    {
      "epoch": 2.761477390403866,
      "grad_norm": 0.7557180523872375,
      "learning_rate": 5.5174318260269244e-05,
      "loss": 0.9777,
      "step": 8000
    },
    {
      "epoch": 2.761477390403866,
      "eval_loss": 0.7312057614326477,
      "eval_runtime": 1018.7418,
      "eval_samples_per_second": 20.222,
      "eval_steps_per_second": 2.529,
      "eval_wer": 0.24095719354293701,
      "step": 8000
    },
    {
      "epoch": 2.77873662409389,
      "grad_norm": 0.672946035861969,
      "learning_rate": 5.551950293406973e-05,
      "loss": 0.9423,
      "step": 8050
    },
    {
      "epoch": 2.7959958577839146,
      "grad_norm": 0.7965629696846008,
      "learning_rate": 5.586468760787021e-05,
      "loss": 0.9138,
      "step": 8100
    },
    {
      "epoch": 2.7959958577839146,
      "eval_loss": 0.6580740213394165,
      "eval_runtime": 1031.5293,
      "eval_samples_per_second": 19.971,
      "eval_steps_per_second": 2.497,
      "eval_wer": 0.22193082157064525,
      "step": 8100
    },
    {
      "epoch": 2.8132550914739385,
      "grad_norm": 0.7229291200637817,
      "learning_rate": 5.620987228167069e-05,
      "loss": 0.9359,
      "step": 8150
    },
    {
      "epoch": 2.830514325163963,
      "grad_norm": 0.7088516354560852,
      "learning_rate": 5.655505695547117e-05,
      "loss": 0.9608,
      "step": 8200
    },
    {
      "epoch": 2.830514325163963,
      "eval_loss": 0.6868262887001038,
      "eval_runtime": 1003.1057,
      "eval_samples_per_second": 20.537,
      "eval_steps_per_second": 2.568,
      "eval_wer": 0.227851843887754,
      "step": 8200
    },
    {
      "epoch": 2.8477735588539868,
      "grad_norm": 0.8486354351043701,
      "learning_rate": 5.6900241629271666e-05,
      "loss": 0.9437,
      "step": 8250
    },
    {
      "epoch": 2.865032792544011,
      "grad_norm": 0.8612354397773743,
      "learning_rate": 5.7245426303072146e-05,
      "loss": 0.9406,
      "step": 8300
    },
    {
      "epoch": 2.865032792544011,
      "eval_loss": 0.6439051628112793,
      "eval_runtime": 1019.9061,
      "eval_samples_per_second": 20.199,
      "eval_steps_per_second": 2.526,
      "eval_wer": 0.22224952770055448,
      "step": 8300
    },
    {
      "epoch": 2.882292026234035,
      "grad_norm": 0.8627294301986694,
      "learning_rate": 5.7590610976872627e-05,
      "loss": 1.0637,
      "step": 8350
    },
    {
      "epoch": 2.8995512599240594,
      "grad_norm": 0.6172276139259338,
      "learning_rate": 5.793579565067311e-05,
      "loss": 1.1112,
      "step": 8400
    },
    {
      "epoch": 2.8995512599240594,
      "eval_loss": 0.8925060033798218,
      "eval_runtime": 1021.896,
      "eval_samples_per_second": 20.16,
      "eval_steps_per_second": 2.521,
      "eval_wer": 0.21410524213986207,
      "step": 8400
    },
    {
      "epoch": 2.9168104936140837,
      "grad_norm": 0.6289278864860535,
      "learning_rate": 5.82809803244736e-05,
      "loss": 0.9025,
      "step": 8450
    },
    {
      "epoch": 2.9340697273041076,
      "grad_norm": 0.9324101805686951,
      "learning_rate": 5.862616499827408e-05,
      "loss": 0.8981,
      "step": 8500
    },
    {
      "epoch": 2.9340697273041076,
      "eval_loss": 0.8790662884712219,
      "eval_runtime": 1010.6064,
      "eval_samples_per_second": 20.385,
      "eval_steps_per_second": 2.549,
      "eval_wer": 0.209278572196538,
      "step": 8500
    },
    {
      "epoch": 2.951328960994132,
      "grad_norm": 0.7137991189956665,
      "learning_rate": 5.897134967207456e-05,
      "loss": 0.899,
      "step": 8550
    },
    {
      "epoch": 2.968588194684156,
      "grad_norm": 0.7245414853096008,
      "learning_rate": 5.931653434587504e-05,
      "loss": 0.8722,
      "step": 8600
    },
    {
      "epoch": 2.968588194684156,
      "eval_loss": 0.7673262357711792,
      "eval_runtime": 1021.952,
      "eval_samples_per_second": 20.158,
      "eval_steps_per_second": 2.521,
      "eval_wer": 0.20112660697006465,
      "step": 8600
    },
    {
      "epoch": 2.9858474283741803,
      "grad_norm": 0.6109591126441956,
      "learning_rate": 5.9661719019675536e-05,
      "loss": 0.9753,
      "step": 8650
    },
    {
      "epoch": 3.003106662064204,
      "grad_norm": 0.797600507736206,
      "learning_rate": 6.0006903693476016e-05,
      "loss": 0.8889,
      "step": 8700
    },
    {
      "epoch": 3.003106662064204,
      "eval_loss": 0.673332154750824,
      "eval_runtime": 1006.5883,
      "eval_samples_per_second": 20.466,
      "eval_steps_per_second": 2.559,
      "eval_wer": 0.20158738691692138,
      "step": 8700
    },
    {
      "epoch": 3.0203658957542285,
      "grad_norm": 0.8166970014572144,
      "learning_rate": 6.0352088367276496e-05,
      "loss": 0.8456,
      "step": 8750
    },
    {
      "epoch": 3.037625129444253,
      "grad_norm": 0.8569178581237793,
      "learning_rate": 6.0697273041076977e-05,
      "loss": 0.9161,
      "step": 8800
    },
    {
      "epoch": 3.037625129444253,
      "eval_loss": 0.697725236415863,
      "eval_runtime": 1004.8692,
      "eval_samples_per_second": 20.501,
      "eval_steps_per_second": 2.564,
      "eval_wer": 0.1986844732517241,
      "step": 8800
    },
    {
      "epoch": 3.054884363134277,
      "grad_norm": 0.7733563184738159,
      "learning_rate": 6.104245771487746e-05,
      "loss": 0.8641,
      "step": 8850
    },
    {
      "epoch": 3.072143596824301,
      "grad_norm": 0.8909623622894287,
      "learning_rate": 6.138764238867795e-05,
      "loss": 0.8494,
      "step": 8900
    },
    {
      "epoch": 3.072143596824301,
      "eval_loss": 0.6119822263717651,
      "eval_runtime": 1023.6595,
      "eval_samples_per_second": 20.125,
      "eval_steps_per_second": 2.516,
      "eval_wer": 0.19552429078286512,
      "step": 8900
    },
    {
      "epoch": 3.089402830514325,
      "grad_norm": 0.6518633365631104,
      "learning_rate": 6.173282706247842e-05,
      "loss": 0.9144,
      "step": 8950
    },
    {
      "epoch": 3.1066620642043494,
      "grad_norm": 0.6935817003250122,
      "learning_rate": 6.207801173627891e-05,
      "loss": 0.8861,
      "step": 9000
    },
    {
      "epoch": 3.1066620642043494,
      "eval_loss": 0.6547592878341675,
      "eval_runtime": 1013.9047,
      "eval_samples_per_second": 20.318,
      "eval_steps_per_second": 2.541,
      "eval_wer": 0.19008708740995592,
      "step": 9000
    },
    {
      "epoch": 3.1239212978943733,
      "grad_norm": 0.8275237083435059,
      "learning_rate": 6.24231964100794e-05,
      "loss": 0.8555,
      "step": 9050
    },
    {
      "epoch": 3.1411805315843977,
      "grad_norm": 0.9337189793586731,
      "learning_rate": 6.276838108387989e-05,
      "loss": 0.8716,
      "step": 9100
    },
    {
      "epoch": 3.1411805315843977,
      "eval_loss": 0.638008713722229,
      "eval_runtime": 1007.0506,
      "eval_samples_per_second": 20.457,
      "eval_steps_per_second": 2.558,
      "eval_wer": 0.18550232693873162,
      "step": 9100
    },
    {
      "epoch": 3.158439765274422,
      "grad_norm": 0.7825316190719604,
      "learning_rate": 6.311356575768036e-05,
      "loss": 0.8563,
      "step": 9150
    },
    {
      "epoch": 3.175698998964446,
      "grad_norm": 0.7113686800003052,
      "learning_rate": 6.345875043148085e-05,
      "loss": 0.8757,
      "step": 9200
    },
    {
      "epoch": 3.175698998964446,
      "eval_loss": 0.5780395865440369,
      "eval_runtime": 1004.4274,
      "eval_samples_per_second": 20.51,
      "eval_steps_per_second": 2.565,
      "eval_wer": 0.1838089606340332,
      "step": 9200
    },
    {
      "epoch": 3.1929582326544703,
      "grad_norm": 0.7097784280776978,
      "learning_rate": 6.380393510528133e-05,
      "loss": 0.8519,
      "step": 9250
    },
    {
      "epoch": 3.2102174663444942,
      "grad_norm": 0.8968443870544434,
      "learning_rate": 6.41491197790818e-05,
      "loss": 0.8598,
      "step": 9300
    },
    {
      "epoch": 3.2102174663444942,
      "eval_loss": 0.6341654658317566,
      "eval_runtime": 1008.8806,
      "eval_samples_per_second": 20.42,
      "eval_steps_per_second": 2.553,
      "eval_wer": 0.1819735205123873,
      "step": 9300
    },
    {
      "epoch": 3.2274767000345186,
      "grad_norm": 0.753369152545929,
      "learning_rate": 6.44943044528823e-05,
      "loss": 0.8452,
      "step": 9350
    },
    {
      "epoch": 3.2447359337245425,
      "grad_norm": 58.11061096191406,
      "learning_rate": 6.483948912668277e-05,
      "loss": 0.9821,
      "step": 9400
    },
    {
      "epoch": 3.2447359337245425,
      "eval_loss": 0.6854383945465088,
      "eval_runtime": 1010.469,
      "eval_samples_per_second": 20.388,
      "eval_steps_per_second": 2.549,
      "eval_wer": 0.18102892162133105,
      "step": 9400
    },
    {
      "epoch": 3.261995167414567,
      "grad_norm": 0.7837598323822021,
      "learning_rate": 6.518467380048327e-05,
      "loss": 0.9096,
      "step": 9450
    },
    {
      "epoch": 3.2792544011045908,
      "grad_norm": 0.7448406219482422,
      "learning_rate": 6.552985847428374e-05,
      "loss": 0.8043,
      "step": 9500
    },
    {
      "epoch": 3.2792544011045908,
      "eval_loss": 0.6652385592460632,
      "eval_runtime": 1010.8786,
      "eval_samples_per_second": 20.379,
      "eval_steps_per_second": 2.548,
      "eval_wer": 0.1767475079484541,
      "step": 9500
    },
    {
      "epoch": 3.296513634794615,
      "grad_norm": 0.9446273446083069,
      "learning_rate": 6.587504314808423e-05,
      "loss": 0.8237,
      "step": 9550
    },
    {
      "epoch": 3.313772868484639,
      "grad_norm": 0.7345865368843079,
      "learning_rate": 6.62202278218847e-05,
      "loss": 0.8448,
      "step": 9600
    },
    {
      "epoch": 3.313772868484639,
      "eval_loss": 0.588563859462738,
      "eval_runtime": 978.6166,
      "eval_samples_per_second": 21.051,
      "eval_steps_per_second": 2.632,
      "eval_wer": 0.17408650375535656,
      "step": 9600
    },
    {
      "epoch": 3.3310321021746634,
      "grad_norm": 0.8122875094413757,
      "learning_rate": 6.65654124956852e-05,
      "loss": 0.853,
      "step": 9650
    },
    {
      "epoch": 3.3482913358646877,
      "grad_norm": 1.3412449359893799,
      "learning_rate": 6.691059716948568e-05,
      "loss": 0.8189,
      "step": 9700
    },
    {
      "epoch": 3.3482913358646877,
      "eval_loss": 0.6126781105995178,
      "eval_runtime": 972.2674,
      "eval_samples_per_second": 21.189,
      "eval_steps_per_second": 2.649,
      "eval_wer": 0.16821539926582396,
      "step": 9700
    },
    {
      "epoch": 3.3655505695547117,
      "grad_norm": 0.7574721574783325,
      "learning_rate": 6.725578184328616e-05,
      "loss": 0.8367,
      "step": 9750
    },
    {
      "epoch": 3.382809803244736,
      "grad_norm": 0.8473790287971497,
      "learning_rate": 6.760096651708664e-05,
      "loss": 0.8262,
      "step": 9800
    },
    {
      "epoch": 3.382809803244736,
      "eval_loss": 0.5607167482376099,
      "eval_runtime": 986.0567,
      "eval_samples_per_second": 20.892,
      "eval_steps_per_second": 2.612,
      "eval_wer": 0.17016603437418404,
      "step": 9800
    },
    {
      "epoch": 3.40006903693476,
      "grad_norm": 0.6938612461090088,
      "learning_rate": 6.794615119088712e-05,
      "loss": 0.9325,
      "step": 9850
    },
    {
      "epoch": 3.4173282706247843,
      "grad_norm": 0.7716054916381836,
      "learning_rate": 6.829133586468761e-05,
      "loss": 0.8435,
      "step": 9900
    },
    {
      "epoch": 3.4173282706247843,
      "eval_loss": 0.657586932182312,
      "eval_runtime": 979.1724,
      "eval_samples_per_second": 21.039,
      "eval_steps_per_second": 2.631,
      "eval_wer": 0.1668061805950205,
      "step": 9900
    },
    {
      "epoch": 3.434587504314808,
      "grad_norm": 0.8438212871551514,
      "learning_rate": 6.86365205384881e-05,
      "loss": 0.8174,
      "step": 9950
    },
    {
      "epoch": 3.4518467380048325,
      "grad_norm": 0.7622531652450562,
      "learning_rate": 6.898170521228859e-05,
      "loss": 0.8111,
      "step": 10000
    },
    {
      "epoch": 3.4518467380048325,
      "eval_loss": 0.5857583284378052,
      "eval_runtime": 967.6447,
      "eval_samples_per_second": 21.29,
      "eval_steps_per_second": 2.662,
      "eval_wer": 0.16569646888967393,
      "step": 10000
    },
    {
      "epoch": 3.469105971694857,
      "grad_norm": 0.719879686832428,
      "learning_rate": 6.932688988608906e-05,
      "loss": 0.8808,
      "step": 10050
    },
    {
      "epoch": 3.486365205384881,
      "grad_norm": 0.8293593525886536,
      "learning_rate": 6.967207455988955e-05,
      "loss": 0.8469,
      "step": 10100
    },
    {
      "epoch": 3.486365205384881,
      "eval_loss": 0.6628051996231079,
      "eval_runtime": 965.5774,
      "eval_samples_per_second": 21.335,
      "eval_steps_per_second": 2.668,
      "eval_wer": 0.16548143824780745,
      "step": 10100
    },
    {
      "epoch": 3.503624439074905,
      "grad_norm": 0.6600349545478821,
      "learning_rate": 7.001725923369002e-05,
      "loss": 0.7951,
      "step": 10150
    },
    {
      "epoch": 3.520883672764929,
      "grad_norm": 0.7322726249694824,
      "learning_rate": 7.036244390749052e-05,
      "loss": 0.8219,
      "step": 10200
    },
    {
      "epoch": 3.520883672764929,
      "eval_loss": 0.6060554385185242,
      "eval_runtime": 990.2999,
      "eval_samples_per_second": 20.803,
      "eval_steps_per_second": 2.601,
      "eval_wer": 0.1629356290414241,
      "step": 10200
    },
    {
      "epoch": 3.5381429064549534,
      "grad_norm": 0.6583877801895142,
      "learning_rate": 7.0707628581291e-05,
      "loss": 0.7954,
      "step": 10250
    },
    {
      "epoch": 3.5554021401449774,
      "grad_norm": 0.7379046082496643,
      "learning_rate": 7.105281325509148e-05,
      "loss": 0.8007,
      "step": 10300
    },
    {
      "epoch": 3.5554021401449774,
      "eval_loss": 0.5488827228546143,
      "eval_runtime": 969.0707,
      "eval_samples_per_second": 21.259,
      "eval_steps_per_second": 2.658,
      "eval_wer": 0.16176831984272044,
      "step": 10300
    },
    {
      "epoch": 3.5726613738350017,
      "grad_norm": 0.7516312599182129,
      "learning_rate": 7.139799792889195e-05,
      "loss": 0.7729,
      "step": 10350
    },
    {
      "epoch": 3.589920607525026,
      "grad_norm": 0.7437967658042908,
      "learning_rate": 7.174318260269246e-05,
      "loss": 0.8186,
      "step": 10400
    },
    {
      "epoch": 3.589920607525026,
      "eval_loss": 0.5306975841522217,
      "eval_runtime": 984.4141,
      "eval_samples_per_second": 20.927,
      "eval_steps_per_second": 2.617,
      "eval_wer": 0.15481438247807455,
      "step": 10400
    },
    {
      "epoch": 3.60717984121505,
      "grad_norm": 0.7202388644218445,
      "learning_rate": 7.208836727649293e-05,
      "loss": 0.7976,
      "step": 10450
    },
    {
      "epoch": 3.6244390749050743,
      "grad_norm": 0.7101107239723206,
      "learning_rate": 7.243355195029342e-05,
      "loss": 0.8855,
      "step": 10500
    },
    {
      "epoch": 3.6244390749050743,
      "eval_loss": 0.488119900226593,
      "eval_runtime": 974.223,
      "eval_samples_per_second": 21.146,
      "eval_steps_per_second": 2.644,
      "eval_wer": 0.15533275991828835,
      "step": 10500
    },
    {
      "epoch": 3.6416983085950982,
      "grad_norm": 3.973956346511841,
      "learning_rate": 7.277873662409389e-05,
      "loss": 0.7629,
      "step": 10550
    },
    {
      "epoch": 3.6589575422851226,
      "grad_norm": 0.6988930106163025,
      "learning_rate": 7.312392129789438e-05,
      "loss": 0.7711,
      "step": 10600
    },
    {
      "epoch": 3.6589575422851226,
      "eval_loss": 0.5222898721694946,
      "eval_runtime": 983.2745,
      "eval_samples_per_second": 20.951,
      "eval_steps_per_second": 2.62,
      "eval_wer": 0.15376610809897553,
      "step": 10600
    },
    {
      "epoch": 3.6762167759751465,
      "grad_norm": 0.7806277871131897,
      "learning_rate": 7.346910597169486e-05,
      "loss": 0.7638,
      "step": 10650
    },
    {
      "epoch": 3.693476009665171,
      "grad_norm": 0.7934468984603882,
      "learning_rate": 7.381429064549534e-05,
      "loss": 0.7828,
      "step": 10700
    },
    {
      "epoch": 3.693476009665171,
      "eval_loss": 0.48663273453712463,
      "eval_runtime": 979.5344,
      "eval_samples_per_second": 21.031,
      "eval_steps_per_second": 2.63,
      "eval_wer": 0.1488088838373754,
      "step": 10700
    },
    {
      "epoch": 3.7107352433551952,
      "grad_norm": 0.7459828853607178,
      "learning_rate": 7.415257162581982e-05,
      "loss": 0.756,
      "step": 10750
    },
    {
      "epoch": 3.727994477045219,
      "grad_norm": 0.7601662278175354,
      "learning_rate": 7.44977562996203e-05,
      "loss": 0.7752,
      "step": 10800
    },
    {
      "epoch": 3.727994477045219,
      "eval_loss": 0.5414342880249023,
      "eval_runtime": 977.3644,
      "eval_samples_per_second": 21.078,
      "eval_steps_per_second": 2.636,
      "eval_wer": 0.1539657794092801,
      "step": 10800
    },
    {
      "epoch": 3.7452537107352435,
      "grad_norm": 0.8476618528366089,
      "learning_rate": 7.484294097342078e-05,
      "loss": 0.7563,
      "step": 10850
    },
    {
      "epoch": 3.7625129444252674,
      "grad_norm": 0.7555232644081116,
      "learning_rate": 7.518812564722126e-05,
      "loss": 0.7604,
      "step": 10900
    },
    {
      "epoch": 3.7625129444252674,
      "eval_loss": 0.6076399087905884,
      "eval_runtime": 992.6346,
      "eval_samples_per_second": 20.754,
      "eval_steps_per_second": 2.595,
      "eval_wer": 0.15544027523922158,
      "step": 10900
    },
    {
      "epoch": 3.7797721781152918,
      "grad_norm": 0.656848132610321,
      "learning_rate": 7.553331032102175e-05,
      "loss": 0.7928,
      "step": 10950
    },
    {
      "epoch": 3.7970314118053157,
      "grad_norm": 0.7593361735343933,
      "learning_rate": 7.587849499482224e-05,
      "loss": 0.7725,
      "step": 11000
    },
    {
      "epoch": 3.7970314118053157,
      "eval_loss": 0.6255898475646973,
      "eval_runtime": 975.1467,
      "eval_samples_per_second": 21.126,
      "eval_steps_per_second": 2.642,
      "eval_wer": 0.15119725989524935,
      "step": 11000
    },
    {
      "epoch": 3.81429064549534,
      "grad_norm": 0.6626622676849365,
      "learning_rate": 7.622367966862271e-05,
      "loss": 0.7934,
      "step": 11050
    },
    {
      "epoch": 3.8315498791853644,
      "grad_norm": 0.7441785931587219,
      "learning_rate": 7.65688643424232e-05,
      "loss": 0.7697,
      "step": 11100
    },
    {
      "epoch": 3.8315498791853644,
      "eval_loss": 0.5414624810218811,
      "eval_runtime": 983.8407,
      "eval_samples_per_second": 20.939,
      "eval_steps_per_second": 2.618,
      "eval_wer": 0.1454144715621976,
      "step": 11100
    },
    {
      "epoch": 3.8488091128753883,
      "grad_norm": 1.0121675729751587,
      "learning_rate": 7.691404901622369e-05,
      "loss": 0.7649,
      "step": 11150
    },
    {
      "epoch": 3.8660683465654127,
      "grad_norm": 0.6894168257713318,
      "learning_rate": 7.725923369002417e-05,
      "loss": 0.7834,
      "step": 11200
    },
    {
      "epoch": 3.8660683465654127,
      "eval_loss": 0.547448456287384,
      "eval_runtime": 979.3062,
      "eval_samples_per_second": 21.036,
      "eval_steps_per_second": 2.63,
      "eval_wer": 0.14780284762007156,
      "step": 11200
    },
    {
      "epoch": 3.8833275802554366,
      "grad_norm": 0.6966266632080078,
      "learning_rate": 7.760441836382465e-05,
      "loss": 0.7425,
      "step": 11250
    },
    {
      "epoch": 3.900586813945461,
      "grad_norm": 0.8021095991134644,
      "learning_rate": 7.794960303762513e-05,
      "loss": 0.7555,
      "step": 11300
    },
    {
      "epoch": 3.900586813945461,
      "eval_loss": 0.607923686504364,
      "eval_runtime": 971.8232,
      "eval_samples_per_second": 21.198,
      "eval_steps_per_second": 2.651,
      "eval_wer": 0.15066736295636413,
      "step": 11300
    },
    {
      "epoch": 3.917846047635485,
      "grad_norm": 0.6014962792396545,
      "learning_rate": 7.829478771142562e-05,
      "loss": 0.733,
      "step": 11350
    },
    {
      "epoch": 3.935105281325509,
      "grad_norm": 1.4803489446640015,
      "learning_rate": 7.863997238522611e-05,
      "loss": 0.7531,
      "step": 11400
    },
    {
      "epoch": 3.935105281325509,
      "eval_loss": 0.5659335851669312,
      "eval_runtime": 972.3135,
      "eval_samples_per_second": 21.188,
      "eval_steps_per_second": 2.649,
      "eval_wer": 0.14832506489317585,
      "step": 11400
    },
    {
      "epoch": 3.9523645150155335,
      "grad_norm": 0.7475904226303101,
      "learning_rate": 7.898515705902658e-05,
      "loss": 0.7548,
      "step": 11450
    },
    {
      "epoch": 3.9696237487055575,
      "grad_norm": 0.8445320725440979,
      "learning_rate": 7.933034173282707e-05,
      "loss": 0.762,
      "step": 11500
    },
    {
      "epoch": 3.9696237487055575,
      "eval_loss": 0.5721763968467712,
      "eval_runtime": 978.4886,
      "eval_samples_per_second": 21.054,
      "eval_steps_per_second": 2.633,
      "eval_wer": 0.144727141474803,
      "step": 11500
    },
    {
      "epoch": 3.9868829823955814,
      "grad_norm": 0.7398504018783569,
      "learning_rate": 7.967552640662756e-05,
      "loss": 0.7507,
      "step": 11550
    },
    {
      "epoch": 4.004142216085606,
      "grad_norm": 0.9144055247306824,
      "learning_rate": 8.002071108042803e-05,
      "loss": 0.7325,
      "step": 11600
    },
    {
      "epoch": 4.004142216085606,
      "eval_loss": 0.5364155173301697,
      "eval_runtime": 954.5152,
      "eval_samples_per_second": 21.583,
      "eval_steps_per_second": 2.699,
      "eval_wer": 0.14441611501067472,
      "step": 11600
    },
    {
      "epoch": 4.02140144977563,
      "grad_norm": 1.3561028242111206,
      "learning_rate": 8.036589575422852e-05,
      "loss": 0.7787,
      "step": 11650
    },
    {
      "epoch": 4.038660683465654,
      "grad_norm": 0.7923387289047241,
      "learning_rate": 8.071108042802899e-05,
      "loss": 0.7351,
      "step": 11700
    },
    {
      "epoch": 4.038660683465654,
      "eval_loss": 0.5587519407272339,
      "eval_runtime": 978.8126,
      "eval_samples_per_second": 21.047,
      "eval_steps_per_second": 2.632,
      "eval_wer": 0.14354063311164697,
      "step": 11700
    },
    {
      "epoch": 4.055919917155678,
      "grad_norm": 0.6737884879112244,
      "learning_rate": 8.105626510182949e-05,
      "loss": 0.7068,
      "step": 11750
    },
    {
      "epoch": 4.073179150845703,
      "grad_norm": 0.9166543483734131,
      "learning_rate": 8.140144977562996e-05,
      "loss": 0.7446,
      "step": 11800
    },
    {
      "epoch": 4.073179150845703,
      "eval_loss": 0.49512889981269836,
      "eval_runtime": 968.316,
      "eval_samples_per_second": 21.275,
      "eval_steps_per_second": 2.66,
      "eval_wer": 0.14181654814382477,
      "step": 11800
    },
    {
      "epoch": 4.090438384535727,
      "grad_norm": 0.9571717977523804,
      "learning_rate": 8.174663444943045e-05,
      "loss": 0.7402,
      "step": 11850
    },
    {
      "epoch": 4.1076976182257505,
      "grad_norm": 0.8454440236091614,
      "learning_rate": 8.209181912323092e-05,
      "loss": 0.7045,
      "step": 11900
    },
    {
      "epoch": 4.1076976182257505,
      "eval_loss": 0.5508975982666016,
      "eval_runtime": 985.1431,
      "eval_samples_per_second": 20.912,
      "eval_steps_per_second": 2.615,
      "eval_wer": 0.14098330440659224,
      "step": 11900
    },
    {
      "epoch": 4.124956851915775,
      "grad_norm": 0.7664796113967896,
      "learning_rate": 8.243700379703143e-05,
      "loss": 0.731,
      "step": 11950
    },
    {
      "epoch": 4.142216085605799,
      "grad_norm": 0.8654013872146606,
      "learning_rate": 8.27821884708319e-05,
      "loss": 0.7116,
      "step": 12000
    },
    {
      "epoch": 4.142216085605799,
      "eval_loss": 0.5080496072769165,
      "eval_runtime": 986.329,
      "eval_samples_per_second": 20.887,
      "eval_steps_per_second": 2.612,
      "eval_wer": 0.14108314006174452,
      "step": 12000
    },
    {
      "epoch": 4.159475319295823,
      "grad_norm": 0.7901532649993896,
      "learning_rate": 8.312737314463239e-05,
      "loss": 0.6949,
      "step": 12050
    },
    {
      "epoch": 4.176734552985847,
      "grad_norm": 2.2199575901031494,
      "learning_rate": 8.347255781843286e-05,
      "loss": 0.7298,
      "step": 12100
    },
    {
      "epoch": 4.176734552985847,
      "eval_loss": 0.5329811573028564,
      "eval_runtime": 998.8679,
      "eval_samples_per_second": 20.624,
      "eval_steps_per_second": 2.579,
      "eval_wer": 0.14072603560293057,
      "step": 12100
    },
    {
      "epoch": 4.193993786675872,
      "grad_norm": 0.8269084095954895,
      "learning_rate": 8.381774249223335e-05,
      "loss": 0.7384,
      "step": 12150
    },
    {
      "epoch": 4.211253020365896,
      "grad_norm": 0.7358505725860596,
      "learning_rate": 8.416292716603383e-05,
      "loss": 0.7181,
      "step": 12200
    },
    {
      "epoch": 4.211253020365896,
      "eval_loss": 0.5233821272850037,
      "eval_runtime": 993.0156,
      "eval_samples_per_second": 20.746,
      "eval_steps_per_second": 2.594,
      "eval_wer": 0.1365022194234107,
      "step": 12200
    },
    {
      "epoch": 4.22851225405592,
      "grad_norm": 0.8492196798324585,
      "learning_rate": 8.450811183983432e-05,
      "loss": 0.721,
      "step": 12250
    },
    {
      "epoch": 4.2457714877459445,
      "grad_norm": 0.7473389506340027,
      "learning_rate": 8.48532965136348e-05,
      "loss": 0.7772,
      "step": 12300
    },
    {
      "epoch": 4.2457714877459445,
      "eval_loss": 0.4859229326248169,
      "eval_runtime": 975.8829,
      "eval_samples_per_second": 21.11,
      "eval_steps_per_second": 2.64,
      "eval_wer": 0.13972383921851722,
      "step": 12300
    },
    {
      "epoch": 4.263030721435968,
      "grad_norm": 1.0384751558303833,
      "learning_rate": 8.519848118743528e-05,
      "loss": 0.7138,
      "step": 12350
    },
    {
      "epoch": 4.280289955125992,
      "grad_norm": 0.8716280460357666,
      "learning_rate": 8.554366586123577e-05,
      "loss": 0.676,
      "step": 12400
    },
    {
      "epoch": 4.280289955125992,
      "eval_loss": 0.5142911672592163,
      "eval_runtime": 978.2354,
      "eval_samples_per_second": 21.059,
      "eval_steps_per_second": 2.633,
      "eval_wer": 0.14117145621822538,
      "step": 12400
    },
    {
      "epoch": 4.297549188816016,
      "grad_norm": 0.8529325723648071,
      "learning_rate": 8.588885053503624e-05,
      "loss": 0.6936,
      "step": 12450
    },
    {
      "epoch": 4.314808422506041,
      "grad_norm": 0.6032254695892334,
      "learning_rate": 8.623403520883673e-05,
      "loss": 0.6865,
      "step": 12500
    },
    {
      "epoch": 4.314808422506041,
      "eval_loss": 0.5001653432846069,
      "eval_runtime": 986.5162,
      "eval_samples_per_second": 20.883,
      "eval_steps_per_second": 2.611,
      "eval_wer": 0.1384067765370851,
      "step": 12500
    },
    {
      "epoch": 4.332067656196065,
      "grad_norm": 0.956995964050293,
      "learning_rate": 8.657921988263722e-05,
      "loss": 0.7361,
      "step": 12550
    },
    {
      "epoch": 4.349326889886089,
      "grad_norm": 0.8375464081764221,
      "learning_rate": 8.69244045564377e-05,
      "loss": 0.7206,
      "step": 12600
    },
    {
      "epoch": 4.349326889886089,
      "eval_loss": 0.49783504009246826,
      "eval_runtime": 970.9936,
      "eval_samples_per_second": 21.216,
      "eval_steps_per_second": 2.653,
      "eval_wer": 0.13760425146297633,
      "step": 12600
    },
    {
      "epoch": 4.366586123576113,
      "grad_norm": 1.0429719686508179,
      "learning_rate": 8.726958923023818e-05,
      "loss": 0.6977,
      "step": 12650
    },
    {
      "epoch": 4.3838453572661376,
      "grad_norm": 1.103834867477417,
      "learning_rate": 8.761477390403866e-05,
      "loss": 0.7291,
      "step": 12700
    },
    {
      "epoch": 4.3838453572661376,
      "eval_loss": 0.46908268332481384,
      "eval_runtime": 990.6588,
      "eval_samples_per_second": 20.795,
      "eval_steps_per_second": 2.6,
      "eval_wer": 0.1356305773572734,
      "step": 12700
    },
    {
      "epoch": 4.4011045909561615,
      "grad_norm": 1.2355436086654663,
      "learning_rate": 8.795995857783915e-05,
      "loss": 0.6868,
      "step": 12750
    },
    {
      "epoch": 4.418363824646185,
      "grad_norm": 0.6943678259849548,
      "learning_rate": 8.830514325163964e-05,
      "loss": 0.7019,
      "step": 12800
    },
    {
      "epoch": 4.418363824646185,
      "eval_loss": 0.5008136630058289,
      "eval_runtime": 981.3386,
      "eval_samples_per_second": 20.993,
      "eval_steps_per_second": 2.625,
      "eval_wer": 0.13861412751317062,
      "step": 12800
    },
    {
      "epoch": 4.43562305833621,
      "grad_norm": 0.7190301418304443,
      "learning_rate": 8.86434242319641e-05,
      "loss": 0.7236,
      "step": 12850
    },
    {
      "epoch": 4.452882292026234,
      "grad_norm": 0.7427403330802917,
      "learning_rate": 8.898860890576459e-05,
      "loss": 0.6993,
      "step": 12900
    },
    {
      "epoch": 4.452882292026234,
      "eval_loss": 0.4780290722846985,
      "eval_runtime": 987.1032,
      "eval_samples_per_second": 20.87,
      "eval_steps_per_second": 2.61,
      "eval_wer": 0.13513523891440243,
      "step": 12900
    },
    {
      "epoch": 4.470141525716258,
      "grad_norm": 0.9701685309410095,
      "learning_rate": 8.933379357956508e-05,
      "loss": 0.7501,
      "step": 12950
    },
    {
      "epoch": 4.487400759406283,
      "grad_norm": 0.6833723783493042,
      "learning_rate": 8.967897825336555e-05,
      "loss": 0.7027,
      "step": 13000
    },
    {
      "epoch": 4.487400759406283,
      "eval_loss": 0.49790769815444946,
      "eval_runtime": 963.613,
      "eval_samples_per_second": 21.379,
      "eval_steps_per_second": 2.673,
      "eval_wer": 0.1353656288878308,
      "step": 13000
    },
    {
      "epoch": 4.504659993096307,
      "grad_norm": 0.8971156477928162,
      "learning_rate": 9.002416292716604e-05,
      "loss": 0.727,
      "step": 13050
    },
    {
      "epoch": 4.521919226786331,
      "grad_norm": 0.7874953150749207,
      "learning_rate": 9.036934760096653e-05,
      "loss": 0.7228,
      "step": 13100
    },
    {
      "epoch": 4.521919226786331,
      "eval_loss": 0.47048914432525635,
      "eval_runtime": 981.4222,
      "eval_samples_per_second": 20.991,
      "eval_steps_per_second": 2.625,
      "eval_wer": 0.13488180994363125,
      "step": 13100
    },
    {
      "epoch": 4.5391784604763545,
      "grad_norm": 0.8225328922271729,
      "learning_rate": 9.0714532274767e-05,
      "loss": 0.7055,
      "step": 13150
    },
    {
      "epoch": 4.556437694166379,
      "grad_norm": 0.7410122156143188,
      "learning_rate": 9.105971694856749e-05,
      "loss": 0.6859,
      "step": 13200
    },
    {
      "epoch": 4.556437694166379,
      "eval_loss": 0.4421616196632385,
      "eval_runtime": 982.2132,
      "eval_samples_per_second": 20.974,
      "eval_steps_per_second": 2.623,
      "eval_wer": 0.13396025004991782,
      "step": 13200
    },
    {
      "epoch": 4.573696927856403,
      "grad_norm": 0.6152003407478333,
      "learning_rate": 9.140490162236796e-05,
      "loss": 0.6999,
      "step": 13250
    },
    {
      "epoch": 4.590956161546427,
      "grad_norm": 0.6940244436264038,
      "learning_rate": 9.175008629616846e-05,
      "loss": 0.6949,
      "step": 13300
    },
    {
      "epoch": 4.590956161546427,
      "eval_loss": 0.5095245242118835,
      "eval_runtime": 986.4229,
      "eval_samples_per_second": 20.885,
      "eval_steps_per_second": 2.611,
      "eval_wer": 0.13432119434162226,
      "step": 13300
    },
    {
      "epoch": 4.608215395236451,
      "grad_norm": 0.8110387325286865,
      "learning_rate": 9.209527096996893e-05,
      "loss": 0.716,
      "step": 13350
    },
    {
      "epoch": 4.625474628926476,
      "grad_norm": 0.7866358160972595,
      "learning_rate": 9.244045564376942e-05,
      "loss": 0.6689,
      "step": 13400
    },
    {
      "epoch": 4.625474628926476,
      "eval_loss": 0.47646474838256836,
      "eval_runtime": 976.0477,
      "eval_samples_per_second": 21.107,
      "eval_steps_per_second": 2.639,
      "eval_wer": 0.13249727371864775,
      "step": 13400
    },
    {
      "epoch": 4.6427338626165,
      "grad_norm": 0.7668929100036621,
      "learning_rate": 9.27856403175699e-05,
      "loss": 0.7101,
      "step": 13450
    },
    {
      "epoch": 4.659993096306524,
      "grad_norm": 0.6811645030975342,
      "learning_rate": 9.31308249913704e-05,
      "loss": 0.7061,
      "step": 13500
    },
    {
      "epoch": 4.659993096306524,
      "eval_loss": 0.502320408821106,
      "eval_runtime": 986.0194,
      "eval_samples_per_second": 20.893,
      "eval_steps_per_second": 2.613,
      "eval_wer": 0.13333819712166126,
      "step": 13500
    },
    {
      "epoch": 4.6772523299965485,
      "grad_norm": 0.7473960518836975,
      "learning_rate": 9.347600966517087e-05,
      "loss": 0.726,
      "step": 13550
    },
    {
      "epoch": 4.694511563686572,
      "grad_norm": 0.7718010544776917,
      "learning_rate": 9.382119433897136e-05,
      "loss": 0.7961,
      "step": 13600
    },
    {
      "epoch": 4.694511563686572,
      "eval_loss": 0.48430484533309937,
      "eval_runtime": 986.2127,
      "eval_samples_per_second": 20.889,
      "eval_steps_per_second": 2.612,
      "eval_wer": 0.13356474726219916,
      "step": 13600
    },
    {
      "epoch": 4.711770797376596,
      "grad_norm": 0.8326733112335205,
      "learning_rate": 9.416637901277183e-05,
      "loss": 0.7086,
      "step": 13650
    },
    {
      "epoch": 4.729030031066621,
      "grad_norm": 0.7649198770523071,
      "learning_rate": 9.451156368657233e-05,
      "loss": 0.9993,
      "step": 13700
    },
    {
      "epoch": 4.729030031066621,
      "eval_loss": 0.4911298155784607,
      "eval_runtime": 990.0827,
      "eval_samples_per_second": 20.807,
      "eval_steps_per_second": 2.602,
      "eval_wer": 0.13144515950665828,
      "step": 13700
    },
    {
      "epoch": 4.746289264756645,
      "grad_norm": 0.9282324314117432,
      "learning_rate": 9.48567483603728e-05,
      "loss": 0.6646,
      "step": 13750
    },
    {
      "epoch": 4.763548498446669,
      "grad_norm": 1.2628538608551025,
      "learning_rate": 9.520193303417329e-05,
      "loss": 0.6873,
      "step": 13800
    },
    {
      "epoch": 4.763548498446669,
      "eval_loss": 0.4631235599517822,
      "eval_runtime": 993.5075,
      "eval_samples_per_second": 20.736,
      "eval_steps_per_second": 2.593,
      "eval_wer": 0.1315219561644677,
      "step": 13800
    },
    {
      "epoch": 4.780807732136693,
      "grad_norm": 0.6390907764434814,
      "learning_rate": 9.554711770797376e-05,
      "loss": 0.8783,
      "step": 13850
    },
    {
      "epoch": 4.798066965826718,
      "grad_norm": 0.7288882732391357,
      "learning_rate": 9.589230238177425e-05,
      "loss": 0.6798,
      "step": 13900
    },
    {
      "epoch": 4.798066965826718,
      "eval_loss": 0.5580480694770813,
      "eval_runtime": 991.3402,
      "eval_samples_per_second": 20.781,
      "eval_steps_per_second": 2.599,
      "eval_wer": 0.1299553043451549,
      "step": 13900
    },
    {
      "epoch": 4.815326199516742,
      "grad_norm": 0.7761167287826538,
      "learning_rate": 9.623748705557474e-05,
      "loss": 0.714,
      "step": 13950
    },
    {
      "epoch": 4.8325854332067655,
      "grad_norm": 0.7552556395530701,
      "learning_rate": 9.658267172937521e-05,
      "loss": 0.6723,
      "step": 14000
    },
    {
      "epoch": 4.8325854332067655,
      "eval_loss": 0.4549829363822937,
      "eval_runtime": 996.5898,
      "eval_samples_per_second": 20.671,
      "eval_steps_per_second": 2.585,
      "eval_wer": 0.13162947148540097,
      "step": 14000
    },
    {
      "epoch": 4.849844666896789,
      "grad_norm": 0.725889265537262,
      "learning_rate": 9.69278564031757e-05,
      "loss": 0.6427,
      "step": 14050
    },
    {
      "epoch": 4.867103900586814,
      "grad_norm": 0.8644730448722839,
      "learning_rate": 9.727304107697619e-05,
      "loss": 0.6495,
      "step": 14100
    },
    {
      "epoch": 4.867103900586814,
      "eval_loss": 0.4709705412387848,
      "eval_runtime": 973.5606,
      "eval_samples_per_second": 21.16,
      "eval_steps_per_second": 2.646,
      "eval_wer": 0.1321017709309291,
      "step": 14100
    },
    {
      "epoch": 4.884363134276838,
      "grad_norm": 0.9709334373474121,
      "learning_rate": 9.761822575077667e-05,
      "loss": 0.7635,
      "step": 14150
    },
    {
      "epoch": 4.901622367966862,
      "grad_norm": 0.6988120675086975,
      "learning_rate": 9.796341042457715e-05,
      "loss": 0.7375,
      "step": 14200
    },
    {
      "epoch": 4.901622367966862,
      "eval_loss": 0.4413965344429016,
      "eval_runtime": 973.8397,
      "eval_samples_per_second": 21.154,
      "eval_steps_per_second": 2.645,
      "eval_wer": 0.1298439491913312,
      "step": 14200
    },
    {
      "epoch": 4.918881601656887,
      "grad_norm": 0.6824158430099487,
      "learning_rate": 9.830859509837763e-05,
      "loss": 0.7065,
      "step": 14250
    },
    {
      "epoch": 4.936140835346911,
      "grad_norm": 0.7262349128723145,
      "learning_rate": 9.865377977217812e-05,
      "loss": 0.6776,
      "step": 14300
    },
    {
      "epoch": 4.936140835346911,
      "eval_loss": 0.4684808850288391,
      "eval_runtime": 979.5532,
      "eval_samples_per_second": 21.031,
      "eval_steps_per_second": 2.63,
      "eval_wer": 0.12864592132950373,
      "step": 14300
    },
    {
      "epoch": 4.953400069036935,
      "grad_norm": 0.8381058573722839,
      "learning_rate": 9.899896444597861e-05,
      "loss": 0.7213,
      "step": 14350
    },
    {
      "epoch": 4.9706593027269586,
      "grad_norm": 0.8073152899742126,
      "learning_rate": 9.934414911977908e-05,
      "loss": 0.6887,
      "step": 14400
    },
    {
      "epoch": 4.9706593027269586,
      "eval_loss": 0.454183429479599,
      "eval_runtime": 976.9886,
      "eval_samples_per_second": 21.086,
      "eval_steps_per_second": 2.637,
      "eval_wer": 0.13196737677976256,
      "step": 14400
    },
    {
      "epoch": 4.987918536416983,
      "grad_norm": 0.9019997119903564,
      "learning_rate": 9.968933379357957e-05,
      "loss": 0.6989,
      "step": 14450
    },
    {
      "epoch": 5.005177770107007,
      "grad_norm": 1.0440913438796997,
      "learning_rate": 9.999616461473555e-05,
      "loss": 0.6924,
      "step": 14500
    },
    {
      "epoch": 5.005177770107007,
      "eval_loss": 0.43073326349258423,
      "eval_runtime": 966.4679,
      "eval_samples_per_second": 21.316,
      "eval_steps_per_second": 2.665,
      "eval_wer": 0.12974795336906939,
      "step": 14500
    },
    {
      "epoch": 5.022437003797031,
      "grad_norm": 0.9526986479759216,
      "learning_rate": 9.995781076209105e-05,
      "loss": 0.6909,
      "step": 14550
    },
    {
      "epoch": 5.039696237487056,
      "grad_norm": 1.0777323246002197,
      "learning_rate": 9.991945690944656e-05,
      "loss": 0.8366,
      "step": 14600
    },
    {
      "epoch": 5.039696237487056,
      "eval_loss": 0.41224583983421326,
      "eval_runtime": 964.9254,
      "eval_samples_per_second": 21.35,
      "eval_steps_per_second": 2.67,
      "eval_wer": 0.12803922773280907,
      "step": 14600
    },
    {
      "epoch": 5.05695547117708,
      "grad_norm": 0.800583004951477,
      "learning_rate": 9.988110305680207e-05,
      "loss": 0.6528,
      "step": 14650
    },
    {
      "epoch": 5.074214704867104,
      "grad_norm": 0.9033134579658508,
      "learning_rate": 9.984274920415756e-05,
      "loss": 0.6536,
      "step": 14700
    },
    {
      "epoch": 5.074214704867104,
      "eval_loss": 0.525360107421875,
      "eval_runtime": 983.9086,
      "eval_samples_per_second": 20.938,
      "eval_steps_per_second": 2.618,
      "eval_wer": 0.1300513001674167,
      "step": 14700
    },
    {
      "epoch": 5.091473938557128,
      "grad_norm": 1.115477204322815,
      "learning_rate": 9.980439535151306e-05,
      "loss": 0.6679,
      "step": 14750
    },
    {
      "epoch": 5.1087331722471525,
      "grad_norm": 1.0892874002456665,
      "learning_rate": 9.976604149886857e-05,
      "loss": 0.6762,
      "step": 14800
    },
    {
      "epoch": 5.1087331722471525,
      "eval_loss": 0.42393678426742554,
      "eval_runtime": 967.5729,
      "eval_samples_per_second": 21.291,
      "eval_steps_per_second": 2.662,
      "eval_wer": 0.12829649653647074,
      "step": 14800
    },
    {
      "epoch": 5.125992405937176,
      "grad_norm": 0.8128817677497864,
      "learning_rate": 9.972768764622406e-05,
      "loss": 0.6584,
      "step": 14850
    },
    {
      "epoch": 5.1432516396272,
      "grad_norm": 0.9979865550994873,
      "learning_rate": 9.968933379357957e-05,
      "loss": 0.6539,
      "step": 14900
    },
    {
      "epoch": 5.1432516396272,
      "eval_loss": 0.47615474462509155,
      "eval_runtime": 977.1903,
      "eval_samples_per_second": 21.082,
      "eval_steps_per_second": 2.636,
      "eval_wer": 0.12764372494509038,
      "step": 14900
    },
    {
      "epoch": 5.160510873317225,
      "grad_norm": 1.369385004043579,
      "learning_rate": 9.965097994093508e-05,
      "loss": 0.7879,
      "step": 14950
    },
    {
      "epoch": 5.177770107007249,
      "grad_norm": 0.7630758285522461,
      "learning_rate": 9.961262608829057e-05,
      "loss": 0.6554,
      "step": 15000
    },
    {
      "epoch": 5.177770107007249,
      "eval_loss": 0.4581364095211029,
      "eval_runtime": 995.9553,
      "eval_samples_per_second": 20.685,
      "eval_steps_per_second": 2.586,
      "eval_wer": 0.12571612883407315,
      "step": 15000
    },
    {
      "epoch": 5.195029340697273,
      "grad_norm": 0.6969584822654724,
      "learning_rate": 9.957427223564607e-05,
      "loss": 0.6599,
      "step": 15050
    },
    {
      "epoch": 5.212288574387297,
      "grad_norm": 0.7458241581916809,
      "learning_rate": 9.953591838300158e-05,
      "loss": 0.6787,
      "step": 15100
    },
    {
      "epoch": 5.212288574387297,
      "eval_loss": 0.4773215651512146,
      "eval_runtime": 980.4595,
      "eval_samples_per_second": 21.012,
      "eval_steps_per_second": 2.627,
      "eval_wer": 0.1249097639270739,
      "step": 15100
    },
    {
      "epoch": 5.229547808077322,
      "grad_norm": 0.8373770713806152,
      "learning_rate": 9.949756453035709e-05,
      "loss": 0.6451,
      "step": 15150
    },
    {
      "epoch": 5.246807041767346,
      "grad_norm": 0.8725295662879944,
      "learning_rate": 9.945921067771258e-05,
      "loss": 0.6312,
      "step": 15200
    },
    {
      "epoch": 5.246807041767346,
      "eval_loss": 0.46359723806381226,
      "eval_runtime": 983.5865,
      "eval_samples_per_second": 20.945,
      "eval_steps_per_second": 2.619,
      "eval_wer": 0.12658393106731994,
      "step": 15200
    },
    {
      "epoch": 5.2640662754573695,
      "grad_norm": 1.0081300735473633,
      "learning_rate": 9.942085682506808e-05,
      "loss": 0.6842,
      "step": 15250
    },
    {
      "epoch": 5.281325509147393,
      "grad_norm": 0.7768113613128662,
      "learning_rate": 9.938250297242359e-05,
      "loss": 0.6404,
      "step": 15300
    },
    {
      "epoch": 5.281325509147393,
      "eval_loss": 0.4598928987979889,
      "eval_runtime": 972.7998,
      "eval_samples_per_second": 21.177,
      "eval_steps_per_second": 2.648,
      "eval_wer": 0.12910670127636045,
      "step": 15300
    },
    {
      "epoch": 5.298584742837418,
      "grad_norm": 1.7088699340820312,
      "learning_rate": 9.934414911977908e-05,
      "loss": 0.663,
      "step": 15350
    },
    {
      "epoch": 5.315843976527442,
      "grad_norm": 1.237661600112915,
      "learning_rate": 9.930579526713459e-05,
      "loss": 0.6556,
      "step": 15400
    },
    {
      "epoch": 5.315843976527442,
      "eval_loss": 0.5001706480979919,
      "eval_runtime": 980.2231,
      "eval_samples_per_second": 21.017,
      "eval_steps_per_second": 2.628,
      "eval_wer": 0.1250595174098023,
      "step": 15400
    },
    {
      "epoch": 5.333103210217466,
      "grad_norm": 0.7848055362701416,
      "learning_rate": 9.92674414144901e-05,
      "loss": 0.6339,
      "step": 15450
    },
    {
      "epoch": 5.350362443907491,
      "grad_norm": 0.8604140281677246,
      "learning_rate": 9.922908756184559e-05,
      "loss": 0.6404,
      "step": 15500
    },
    {
      "epoch": 5.350362443907491,
      "eval_loss": 0.43278467655181885,
      "eval_runtime": 989.7938,
      "eval_samples_per_second": 20.813,
      "eval_steps_per_second": 2.603,
      "eval_wer": 0.12229099789577158,
      "step": 15500
    },
    {
      "epoch": 5.367621677597515,
      "grad_norm": 0.7434145212173462,
      "learning_rate": 9.919073370920109e-05,
      "loss": 0.6352,
      "step": 15550
    },
    {
      "epoch": 5.384880911287539,
      "grad_norm": 0.9740639328956604,
      "learning_rate": 9.91523798565566e-05,
      "loss": 0.6667,
      "step": 15600
    },
    {
      "epoch": 5.384880911287539,
      "eval_loss": 0.42980116605758667,
      "eval_runtime": 982.7321,
      "eval_samples_per_second": 20.963,
      "eval_steps_per_second": 2.621,
      "eval_wer": 0.12313960096456603,
      "step": 15600
    },
    {
      "epoch": 5.4021401449775635,
      "grad_norm": 1.0168817043304443,
      "learning_rate": 9.911402600391209e-05,
      "loss": 0.6351,
      "step": 15650
    },
    {
      "epoch": 5.419399378667587,
      "grad_norm": 0.720402181148529,
      "learning_rate": 9.90756721512676e-05,
      "loss": 0.6771,
      "step": 15700
    },
    {
      "epoch": 5.419399378667587,
      "eval_loss": 0.4440287947654724,
      "eval_runtime": 973.8877,
      "eval_samples_per_second": 21.153,
      "eval_steps_per_second": 2.645,
      "eval_wer": 0.12245227087717142,
      "step": 15700
    },
    {
      "epoch": 5.436658612357611,
      "grad_norm": 0.7882418036460876,
      "learning_rate": 9.90373182986231e-05,
      "loss": 0.6315,
      "step": 15750
    },
    {
      "epoch": 5.453917846047635,
      "grad_norm": 0.9368664026260376,
      "learning_rate": 9.899896444597861e-05,
      "loss": 0.6461,
      "step": 15800
    },
    {
      "epoch": 5.453917846047635,
      "eval_loss": 0.4127119183540344,
      "eval_runtime": 982.9671,
      "eval_samples_per_second": 20.958,
      "eval_steps_per_second": 2.621,
      "eval_wer": 0.12214508424593362,
      "step": 15800
    },
    {
      "epoch": 5.47117707973766,
      "grad_norm": 1.0652985572814941,
      "learning_rate": 9.89606105933341e-05,
      "loss": 0.668,
      "step": 15850
    },
    {
      "epoch": 5.488436313427684,
      "grad_norm": 1.134732961654663,
      "learning_rate": 9.892225674068961e-05,
      "loss": 0.6706,
      "step": 15900
    },
    {
      "epoch": 5.488436313427684,
      "eval_loss": 0.43755412101745605,
      "eval_runtime": 981.8771,
      "eval_samples_per_second": 20.981,
      "eval_steps_per_second": 2.624,
      "eval_wer": 0.12326247561706115,
      "step": 15900
    },
    {
      "epoch": 5.505695547117708,
      "grad_norm": 0.7827234268188477,
      "learning_rate": 9.888390288804511e-05,
      "loss": 0.6253,
      "step": 15950
    },
    {
      "epoch": 5.522954780807732,
      "grad_norm": 0.8246830105781555,
      "learning_rate": 9.88455490354006e-05,
      "loss": 0.6604,
      "step": 16000
    },
    {
      "epoch": 5.522954780807732,
      "eval_loss": 0.4228949248790741,
      "eval_runtime": 980.0118,
      "eval_samples_per_second": 21.021,
      "eval_steps_per_second": 2.629,
      "eval_wer": 0.12226411906553827,
      "step": 16000
    },
    {
      "epoch": 5.5402140144977565,
      "grad_norm": 0.9367132782936096,
      "learning_rate": 9.880719518275611e-05,
      "loss": 0.6393,
      "step": 16050
    },
    {
      "epoch": 5.55747324818778,
      "grad_norm": 0.8067456483840942,
      "learning_rate": 9.876884133011162e-05,
      "loss": 0.6553,
      "step": 16100
    },
    {
      "epoch": 5.55747324818778,
      "eval_loss": 0.4115952253341675,
      "eval_runtime": 974.9833,
      "eval_samples_per_second": 21.13,
      "eval_steps_per_second": 2.642,
      "eval_wer": 0.1233392722748706,
      "step": 16100
    }
  ],
  "logging_steps": 50,
  "max_steps": 144850,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4219249480095447e+20,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
