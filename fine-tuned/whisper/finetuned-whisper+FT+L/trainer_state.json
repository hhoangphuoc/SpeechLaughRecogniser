{
  "best_metric": 0.2428079929961448,
  "best_model_checkpoint": "../checkpoints/whisper-batch16-30epochs-lr1e4/checkpoint-26073",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 28970,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03451846738004832,
      "grad_norm": 16.437711715698242,
      "learning_rate": 7.363657283117282e-07,
      "loss": 3.9016,
      "step": 100
    },
    {
      "epoch": 0.06903693476009665,
      "grad_norm": 4.173903465270996,
      "learning_rate": 1.5034133619697783e-06,
      "loss": 1.0256,
      "step": 200
    },
    {
      "epoch": 0.10355540214014498,
      "grad_norm": 3.090409278869629,
      "learning_rate": 2.2704609956278286e-06,
      "loss": 0.2219,
      "step": 300
    },
    {
      "epoch": 0.1380738695201933,
      "grad_norm": 2.584890365600586,
      "learning_rate": 3.0375086292858787e-06,
      "loss": 0.2021,
      "step": 400
    },
    {
      "epoch": 0.17259233690024162,
      "grad_norm": 1.8284205198287964,
      "learning_rate": 3.804556262943929e-06,
      "loss": 0.1892,
      "step": 500
    },
    {
      "epoch": 0.20711080428028997,
      "grad_norm": 2.037623167037964,
      "learning_rate": 4.57160389660198e-06,
      "loss": 0.1853,
      "step": 600
    },
    {
      "epoch": 0.2416292716603383,
      "grad_norm": 1.620039463043213,
      "learning_rate": 5.338651530260029e-06,
      "loss": 0.1867,
      "step": 700
    },
    {
      "epoch": 0.2761477390403866,
      "grad_norm": 1.670066475868225,
      "learning_rate": 6.10569916391808e-06,
      "loss": 0.1767,
      "step": 800
    },
    {
      "epoch": 0.3106662064204349,
      "grad_norm": 2.539682626724243,
      "learning_rate": 6.8727467975761295e-06,
      "loss": 0.1769,
      "step": 900
    },
    {
      "epoch": 0.34518467380048323,
      "grad_norm": 1.547996997833252,
      "learning_rate": 7.63979443123418e-06,
      "loss": 0.1746,
      "step": 1000
    },
    {
      "epoch": 0.3797031411805316,
      "grad_norm": 1.2656190395355225,
      "learning_rate": 8.40684206489223e-06,
      "loss": 0.1814,
      "step": 1100
    },
    {
      "epoch": 0.41422160856057993,
      "grad_norm": 1.8952339887619019,
      "learning_rate": 9.173889698550281e-06,
      "loss": 0.1764,
      "step": 1200
    },
    {
      "epoch": 0.44874007594062826,
      "grad_norm": 1.8723512887954712,
      "learning_rate": 9.94093733220833e-06,
      "loss": 0.1728,
      "step": 1300
    },
    {
      "epoch": 0.4832585433206766,
      "grad_norm": 3.3941519260406494,
      "learning_rate": 1.0707984965866382e-05,
      "loss": 0.1716,
      "step": 1400
    },
    {
      "epoch": 0.5177770107007249,
      "grad_norm": 1.5956722497940063,
      "learning_rate": 1.1475032599524432e-05,
      "loss": 0.1841,
      "step": 1500
    },
    {
      "epoch": 0.5522954780807732,
      "grad_norm": 1.4848670959472656,
      "learning_rate": 1.2242080233182481e-05,
      "loss": 0.1779,
      "step": 1600
    },
    {
      "epoch": 0.5868139454608216,
      "grad_norm": 1.2174705266952515,
      "learning_rate": 1.3009127866840531e-05,
      "loss": 0.1776,
      "step": 1700
    },
    {
      "epoch": 0.6213324128408698,
      "grad_norm": 1.394303321838379,
      "learning_rate": 1.377617550049858e-05,
      "loss": 0.1794,
      "step": 1800
    },
    {
      "epoch": 0.6558508802209182,
      "grad_norm": 1.6510287523269653,
      "learning_rate": 1.454322313415663e-05,
      "loss": 0.1804,
      "step": 1900
    },
    {
      "epoch": 0.6903693476009665,
      "grad_norm": 2.2874436378479004,
      "learning_rate": 1.531027076781468e-05,
      "loss": 0.1777,
      "step": 2000
    },
    {
      "epoch": 0.7248878149810148,
      "grad_norm": 1.370835781097412,
      "learning_rate": 1.607731840147273e-05,
      "loss": 0.1828,
      "step": 2100
    },
    {
      "epoch": 0.7594062823610632,
      "grad_norm": 1.8295350074768066,
      "learning_rate": 1.684436603513078e-05,
      "loss": 0.1844,
      "step": 2200
    },
    {
      "epoch": 0.7939247497411115,
      "grad_norm": 1.525498628616333,
      "learning_rate": 1.761141366878883e-05,
      "loss": 0.1861,
      "step": 2300
    },
    {
      "epoch": 0.8284432171211599,
      "grad_norm": 1.601014256477356,
      "learning_rate": 1.8378461302446883e-05,
      "loss": 0.1906,
      "step": 2400
    },
    {
      "epoch": 0.8629616845012081,
      "grad_norm": 1.4148662090301514,
      "learning_rate": 1.9145508936104933e-05,
      "loss": 0.1867,
      "step": 2500
    },
    {
      "epoch": 0.8974801518812565,
      "grad_norm": 2.565661907196045,
      "learning_rate": 1.9912556569762983e-05,
      "loss": 0.1895,
      "step": 2600
    },
    {
      "epoch": 0.9319986192613048,
      "grad_norm": 2.004685640335083,
      "learning_rate": 2.0679604203421032e-05,
      "loss": 0.1924,
      "step": 2700
    },
    {
      "epoch": 0.9665170866413532,
      "grad_norm": 1.5717511177062988,
      "learning_rate": 2.1446651837079085e-05,
      "loss": 0.1939,
      "step": 2800
    },
    {
      "epoch": 1.0010355540214015,
      "grad_norm": 1.3768088817596436,
      "learning_rate": 2.2213699470737135e-05,
      "loss": 0.1883,
      "step": 2900
    },
    {
      "epoch": 1.0355540214014498,
      "grad_norm": 1.5252751111984253,
      "learning_rate": 2.2980747104395185e-05,
      "loss": 0.1963,
      "step": 3000
    },
    {
      "epoch": 1.070072488781498,
      "grad_norm": 1.5679250955581665,
      "learning_rate": 2.3747794738053234e-05,
      "loss": 0.1912,
      "step": 3100
    },
    {
      "epoch": 1.1045909561615463,
      "grad_norm": 1.799655795097351,
      "learning_rate": 2.4514842371711287e-05,
      "loss": 0.1889,
      "step": 3200
    },
    {
      "epoch": 1.1391094235415948,
      "grad_norm": 1.458052158355713,
      "learning_rate": 2.5281890005369334e-05,
      "loss": 0.1918,
      "step": 3300
    },
    {
      "epoch": 1.173627890921643,
      "grad_norm": 1.3675026893615723,
      "learning_rate": 2.6048937639027387e-05,
      "loss": 0.1851,
      "step": 3400
    },
    {
      "epoch": 1.2081463583016914,
      "grad_norm": 1.5124677419662476,
      "learning_rate": 2.6815985272685433e-05,
      "loss": 0.1845,
      "step": 3500
    },
    {
      "epoch": 1.2426648256817396,
      "grad_norm": 1.567418098449707,
      "learning_rate": 2.7583032906343486e-05,
      "loss": 0.1837,
      "step": 3600
    },
    {
      "epoch": 1.2771832930617881,
      "grad_norm": 1.3890578746795654,
      "learning_rate": 2.8350080540001532e-05,
      "loss": 0.1792,
      "step": 3700
    },
    {
      "epoch": 1.3117017604418364,
      "grad_norm": 1.5341869592666626,
      "learning_rate": 2.9117128173659585e-05,
      "loss": 0.1775,
      "step": 3800
    },
    {
      "epoch": 1.3462202278218847,
      "grad_norm": 1.3133047819137573,
      "learning_rate": 2.988417580731764e-05,
      "loss": 0.1757,
      "step": 3900
    },
    {
      "epoch": 1.380738695201933,
      "grad_norm": 1.4311901330947876,
      "learning_rate": 3.0651223440975685e-05,
      "loss": 0.1816,
      "step": 4000
    },
    {
      "epoch": 1.4152571625819814,
      "grad_norm": 1.3311220407485962,
      "learning_rate": 3.141827107463374e-05,
      "loss": 0.174,
      "step": 4100
    },
    {
      "epoch": 1.4497756299620297,
      "grad_norm": 1.3182005882263184,
      "learning_rate": 3.2185318708291784e-05,
      "loss": 0.1733,
      "step": 4200
    },
    {
      "epoch": 1.484294097342078,
      "grad_norm": 1.3645782470703125,
      "learning_rate": 3.295236634194984e-05,
      "loss": 0.168,
      "step": 4300
    },
    {
      "epoch": 1.5188125647221264,
      "grad_norm": 1.2748032808303833,
      "learning_rate": 3.371941397560789e-05,
      "loss": 0.1749,
      "step": 4400
    },
    {
      "epoch": 1.5533310321021747,
      "grad_norm": 1.6928858757019043,
      "learning_rate": 3.4486461609265936e-05,
      "loss": 0.1714,
      "step": 4500
    },
    {
      "epoch": 1.587849499482223,
      "grad_norm": 2.1964364051818848,
      "learning_rate": 3.525350924292399e-05,
      "loss": 0.1696,
      "step": 4600
    },
    {
      "epoch": 1.6223679668622712,
      "grad_norm": 1.8937830924987793,
      "learning_rate": 3.602055687658204e-05,
      "loss": 0.1663,
      "step": 4700
    },
    {
      "epoch": 1.6568864342423195,
      "grad_norm": 1.4079968929290771,
      "learning_rate": 3.678760451024009e-05,
      "loss": 0.166,
      "step": 4800
    },
    {
      "epoch": 1.691404901622368,
      "grad_norm": 1.5763765573501587,
      "learning_rate": 3.755465214389814e-05,
      "loss": 0.1662,
      "step": 4900
    },
    {
      "epoch": 1.7259233690024163,
      "grad_norm": 1.3568507432937622,
      "learning_rate": 3.832169977755619e-05,
      "loss": 0.1681,
      "step": 5000
    },
    {
      "epoch": 1.7604418363824648,
      "grad_norm": 1.4189971685409546,
      "learning_rate": 3.908874741121424e-05,
      "loss": 0.1708,
      "step": 5100
    },
    {
      "epoch": 1.794960303762513,
      "grad_norm": 1.7245495319366455,
      "learning_rate": 3.9855795044872294e-05,
      "loss": 0.1661,
      "step": 5200
    },
    {
      "epoch": 1.8294787711425613,
      "grad_norm": 1.5281909704208374,
      "learning_rate": 4.062284267853034e-05,
      "loss": 0.1716,
      "step": 5300
    },
    {
      "epoch": 1.8639972385226096,
      "grad_norm": 1.1399623155593872,
      "learning_rate": 4.1389890312188386e-05,
      "loss": 0.1647,
      "step": 5400
    },
    {
      "epoch": 1.8985157059026578,
      "grad_norm": 1.4757425785064697,
      "learning_rate": 4.215693794584644e-05,
      "loss": 0.1721,
      "step": 5500
    },
    {
      "epoch": 1.933034173282706,
      "grad_norm": 1.9753954410552979,
      "learning_rate": 4.2923985579504486e-05,
      "loss": 0.1703,
      "step": 5600
    },
    {
      "epoch": 1.9675526406627546,
      "grad_norm": 1.2039421796798706,
      "learning_rate": 4.369103321316254e-05,
      "loss": 0.1712,
      "step": 5700
    },
    {
      "epoch": 2.002071108042803,
      "grad_norm": 2.068314790725708,
      "learning_rate": 4.4458080846820585e-05,
      "loss": 0.1652,
      "step": 5800
    },
    {
      "epoch": 2.0365895754228514,
      "grad_norm": 1.6163781881332397,
      "learning_rate": 4.522512848047864e-05,
      "loss": 0.1712,
      "step": 5900
    },
    {
      "epoch": 2.0711080428028996,
      "grad_norm": 1.4308738708496094,
      "learning_rate": 4.599217611413669e-05,
      "loss": 0.1655,
      "step": 6000
    },
    {
      "epoch": 2.105626510182948,
      "grad_norm": 1.809465765953064,
      "learning_rate": 4.675922374779474e-05,
      "loss": 0.1655,
      "step": 6100
    },
    {
      "epoch": 2.140144977562996,
      "grad_norm": 1.1983938217163086,
      "learning_rate": 4.752627138145279e-05,
      "loss": 0.1691,
      "step": 6200
    },
    {
      "epoch": 2.1746634449430444,
      "grad_norm": 1.1571654081344604,
      "learning_rate": 4.8293319015110837e-05,
      "loss": 0.1661,
      "step": 6300
    },
    {
      "epoch": 2.2091819123230927,
      "grad_norm": 1.5591026544570923,
      "learning_rate": 4.906036664876889e-05,
      "loss": 0.1645,
      "step": 6400
    },
    {
      "epoch": 2.2437003797031414,
      "grad_norm": 1.5288466215133667,
      "learning_rate": 4.982741428242694e-05,
      "loss": 0.1643,
      "step": 6500
    },
    {
      "epoch": 2.2782188470831897,
      "grad_norm": 1.4822238683700562,
      "learning_rate": 5.059446191608499e-05,
      "loss": 0.1628,
      "step": 6600
    },
    {
      "epoch": 2.312737314463238,
      "grad_norm": 4.289336204528809,
      "learning_rate": 5.1361509549743035e-05,
      "loss": 0.1658,
      "step": 6700
    },
    {
      "epoch": 2.347255781843286,
      "grad_norm": 1.9869149923324585,
      "learning_rate": 5.2128557183401095e-05,
      "loss": 0.1658,
      "step": 6800
    },
    {
      "epoch": 2.3817742492233345,
      "grad_norm": 1.8263919353485107,
      "learning_rate": 5.289560481705914e-05,
      "loss": 0.1728,
      "step": 6900
    },
    {
      "epoch": 2.4162927166033827,
      "grad_norm": 2.576864719390869,
      "learning_rate": 5.366265245071719e-05,
      "loss": 0.1658,
      "step": 7000
    },
    {
      "epoch": 2.450811183983431,
      "grad_norm": 1.6180498600006104,
      "learning_rate": 5.442970008437525e-05,
      "loss": 0.1675,
      "step": 7100
    },
    {
      "epoch": 2.4853296513634793,
      "grad_norm": 2.3834640979766846,
      "learning_rate": 5.5196747718033294e-05,
      "loss": 0.1653,
      "step": 7200
    },
    {
      "epoch": 2.5198481187435275,
      "grad_norm": 1.3891485929489136,
      "learning_rate": 5.596379535169134e-05,
      "loss": 0.1715,
      "step": 7300
    },
    {
      "epoch": 2.5543665861235763,
      "grad_norm": 1.2805721759796143,
      "learning_rate": 5.67308429853494e-05,
      "loss": 0.1697,
      "step": 7400
    },
    {
      "epoch": 2.5888850535036245,
      "grad_norm": 1.4183192253112793,
      "learning_rate": 5.7497890619007446e-05,
      "loss": 0.1687,
      "step": 7500
    },
    {
      "epoch": 2.623403520883673,
      "grad_norm": 1.2891600131988525,
      "learning_rate": 5.826493825266549e-05,
      "loss": 0.1661,
      "step": 7600
    },
    {
      "epoch": 2.657921988263721,
      "grad_norm": 1.887508511543274,
      "learning_rate": 5.903198588632355e-05,
      "loss": 0.1683,
      "step": 7700
    },
    {
      "epoch": 2.6924404556437693,
      "grad_norm": 1.1817164421081543,
      "learning_rate": 5.97990335199816e-05,
      "loss": 0.167,
      "step": 7800
    },
    {
      "epoch": 2.7269589230238176,
      "grad_norm": 1.5057417154312134,
      "learning_rate": 6.0566081153639644e-05,
      "loss": 0.1698,
      "step": 7900
    },
    {
      "epoch": 2.761477390403866,
      "grad_norm": 1.2045913934707642,
      "learning_rate": 6.133312878729768e-05,
      "loss": 0.1711,
      "step": 8000
    },
    {
      "epoch": 2.7959958577839146,
      "grad_norm": 2.362670660018921,
      "learning_rate": 6.210017642095574e-05,
      "loss": 0.1754,
      "step": 8100
    },
    {
      "epoch": 2.830514325163963,
      "grad_norm": 1.0338811874389648,
      "learning_rate": 6.286722405461379e-05,
      "loss": 0.1732,
      "step": 8200
    },
    {
      "epoch": 2.865032792544011,
      "grad_norm": 1.3439247608184814,
      "learning_rate": 6.363427168827184e-05,
      "loss": 0.1721,
      "step": 8300
    },
    {
      "epoch": 2.8995512599240594,
      "grad_norm": 2.028209924697876,
      "learning_rate": 6.44013193219299e-05,
      "loss": 0.177,
      "step": 8400
    },
    {
      "epoch": 2.9340697273041076,
      "grad_norm": 1.6115021705627441,
      "learning_rate": 6.516836695558794e-05,
      "loss": 0.1774,
      "step": 8500
    },
    {
      "epoch": 2.968588194684156,
      "grad_norm": 1.486113429069519,
      "learning_rate": 6.593541458924599e-05,
      "loss": 0.1729,
      "step": 8600
    },
    {
      "epoch": 3.003106662064204,
      "grad_norm": 1.6238961219787598,
      "learning_rate": 6.670246222290405e-05,
      "loss": 0.1772,
      "step": 8700
    },
    {
      "epoch": 3.037625129444253,
      "grad_norm": 1.7431244850158691,
      "learning_rate": 6.74695098565621e-05,
      "loss": 0.181,
      "step": 8800
    },
    {
      "epoch": 3.072143596824301,
      "grad_norm": 1.379980206489563,
      "learning_rate": 6.823655749022014e-05,
      "loss": 0.1768,
      "step": 8900
    },
    {
      "epoch": 3.1066620642043494,
      "grad_norm": 1.7019975185394287,
      "learning_rate": 6.90036051238782e-05,
      "loss": 0.1748,
      "step": 9000
    },
    {
      "epoch": 3.1411805315843977,
      "grad_norm": 1.8437260389328003,
      "learning_rate": 6.977065275753625e-05,
      "loss": 0.1796,
      "step": 9100
    },
    {
      "epoch": 3.175698998964446,
      "grad_norm": 1.3449459075927734,
      "learning_rate": 7.05377003911943e-05,
      "loss": 0.1758,
      "step": 9200
    },
    {
      "epoch": 3.2102174663444942,
      "grad_norm": 2.255277633666992,
      "learning_rate": 7.130474802485234e-05,
      "loss": 0.1813,
      "step": 9300
    },
    {
      "epoch": 3.2447359337245425,
      "grad_norm": 2.076322078704834,
      "learning_rate": 7.20717956585104e-05,
      "loss": 0.1756,
      "step": 9400
    },
    {
      "epoch": 3.2792544011045908,
      "grad_norm": 1.430654764175415,
      "learning_rate": 7.283884329216845e-05,
      "loss": 0.1735,
      "step": 9500
    },
    {
      "epoch": 3.313772868484639,
      "grad_norm": 1.6131263971328735,
      "learning_rate": 7.360589092582649e-05,
      "loss": 0.1805,
      "step": 9600
    },
    {
      "epoch": 3.3482913358646877,
      "grad_norm": 1.6867321729660034,
      "learning_rate": 7.437293855948455e-05,
      "loss": 0.1817,
      "step": 9700
    },
    {
      "epoch": 3.382809803244736,
      "grad_norm": 1.334987759590149,
      "learning_rate": 7.51399861931426e-05,
      "loss": 0.1822,
      "step": 9800
    },
    {
      "epoch": 3.4173282706247843,
      "grad_norm": 1.732893466949463,
      "learning_rate": 7.590703382680064e-05,
      "loss": 0.1837,
      "step": 9900
    },
    {
      "epoch": 3.4518467380048325,
      "grad_norm": 1.3498629331588745,
      "learning_rate": 7.66740814604587e-05,
      "loss": 0.1823,
      "step": 10000
    },
    {
      "epoch": 3.486365205384881,
      "grad_norm": 1.2991905212402344,
      "learning_rate": 7.744112909411675e-05,
      "loss": 0.1806,
      "step": 10100
    },
    {
      "epoch": 3.520883672764929,
      "grad_norm": 1.8523634672164917,
      "learning_rate": 7.82081767277748e-05,
      "loss": 0.1919,
      "step": 10200
    },
    {
      "epoch": 3.5554021401449774,
      "grad_norm": 2.2396650314331055,
      "learning_rate": 7.897522436143286e-05,
      "loss": 0.1838,
      "step": 10300
    },
    {
      "epoch": 3.589920607525026,
      "grad_norm": 1.9056228399276733,
      "learning_rate": 7.97422719950909e-05,
      "loss": 0.1869,
      "step": 10400
    },
    {
      "epoch": 3.6244390749050743,
      "grad_norm": 2.9103682041168213,
      "learning_rate": 8.050931962874895e-05,
      "loss": 0.1889,
      "step": 10500
    },
    {
      "epoch": 3.6589575422851226,
      "grad_norm": 1.8249459266662598,
      "learning_rate": 8.1276367262407e-05,
      "loss": 0.1853,
      "step": 10600
    },
    {
      "epoch": 3.693476009665171,
      "grad_norm": 1.2817367315292358,
      "learning_rate": 8.204341489606505e-05,
      "loss": 0.1799,
      "step": 10700
    },
    {
      "epoch": 3.727994477045219,
      "grad_norm": 1.3947725296020508,
      "learning_rate": 8.278745110071335e-05,
      "loss": 0.2465,
      "step": 10800
    },
    {
      "epoch": 3.7625129444252674,
      "grad_norm": 1.4129308462142944,
      "learning_rate": 8.355449873437141e-05,
      "loss": 0.1917,
      "step": 10900
    },
    {
      "epoch": 3.7970314118053157,
      "grad_norm": 1.3012921810150146,
      "learning_rate": 8.431387589169288e-05,
      "loss": 0.7368,
      "step": 11000
    },
    {
      "epoch": 3.8315498791853644,
      "grad_norm": 1.414388656616211,
      "learning_rate": 8.508092352535093e-05,
      "loss": 0.1947,
      "step": 11100
    },
    {
      "epoch": 3.8660683465654127,
      "grad_norm": 1.7311944961547852,
      "learning_rate": 8.584797115900897e-05,
      "loss": 0.1834,
      "step": 11200
    },
    {
      "epoch": 3.900586813945461,
      "grad_norm": 1.5937342643737793,
      "learning_rate": 8.661501879266702e-05,
      "loss": 0.1942,
      "step": 11300
    },
    {
      "epoch": 3.935105281325509,
      "grad_norm": 1.1818612813949585,
      "learning_rate": 8.738206642632508e-05,
      "loss": 0.1942,
      "step": 11400
    },
    {
      "epoch": 3.9696237487055575,
      "grad_norm": 2.001777410507202,
      "learning_rate": 8.814911405998312e-05,
      "loss": 0.1893,
      "step": 11500
    },
    {
      "epoch": 4.004142216085606,
      "grad_norm": 1.242147445678711,
      "learning_rate": 8.891616169364117e-05,
      "loss": 0.1906,
      "step": 11600
    },
    {
      "epoch": 4.038660683465654,
      "grad_norm": 1.5108720064163208,
      "learning_rate": 8.968320932729923e-05,
      "loss": 0.1928,
      "step": 11700
    },
    {
      "epoch": 4.073179150845703,
      "grad_norm": 1.326769471168518,
      "learning_rate": 9.045025696095728e-05,
      "loss": 0.1904,
      "step": 11800
    },
    {
      "epoch": 4.1076976182257505,
      "grad_norm": 2.4058260917663574,
      "learning_rate": 9.121730459461532e-05,
      "loss": 0.1894,
      "step": 11900
    },
    {
      "epoch": 4.142216085605799,
      "grad_norm": 1.3724050521850586,
      "learning_rate": 9.198435222827338e-05,
      "loss": 0.1938,
      "step": 12000
    },
    {
      "epoch": 4.176734552985847,
      "grad_norm": 1.3491735458374023,
      "learning_rate": 9.275139986193143e-05,
      "loss": 0.1929,
      "step": 12100
    },
    {
      "epoch": 4.211253020365896,
      "grad_norm": 1.3905854225158691,
      "learning_rate": 9.351844749558947e-05,
      "loss": 0.1981,
      "step": 12200
    },
    {
      "epoch": 4.2457714877459445,
      "grad_norm": 1.624941110610962,
      "learning_rate": 9.428549512924752e-05,
      "loss": 0.1936,
      "step": 12300
    },
    {
      "epoch": 4.280289955125992,
      "grad_norm": 1.6018686294555664,
      "learning_rate": 9.505254276290558e-05,
      "loss": 0.1934,
      "step": 12400
    },
    {
      "epoch": 4.314808422506041,
      "grad_norm": 1.5167970657348633,
      "learning_rate": 9.581959039656363e-05,
      "loss": 0.1947,
      "step": 12500
    },
    {
      "epoch": 4.349326889886089,
      "grad_norm": 1.8224115371704102,
      "learning_rate": 9.658663803022167e-05,
      "loss": 0.1923,
      "step": 12600
    },
    {
      "epoch": 4.3838453572661376,
      "grad_norm": 1.6724433898925781,
      "learning_rate": 9.735368566387973e-05,
      "loss": 0.1966,
      "step": 12700
    },
    {
      "epoch": 4.418363824646185,
      "grad_norm": 1.208069086074829,
      "learning_rate": 9.812073329753778e-05,
      "loss": 0.1945,
      "step": 12800
    },
    {
      "epoch": 4.452882292026234,
      "grad_norm": 1.7811214923858643,
      "learning_rate": 9.888778093119583e-05,
      "loss": 0.1931,
      "step": 12900
    },
    {
      "epoch": 4.487400759406283,
      "grad_norm": 1.0175094604492188,
      "learning_rate": 9.965482856485389e-05,
      "loss": 0.1906,
      "step": 13000
    },
    {
      "epoch": 4.521919226786331,
      "grad_norm": 1.4212692975997925,
      "learning_rate": 9.992554789977395e-05,
      "loss": 0.2028,
      "step": 13100
    },
    {
      "epoch": 4.556437694166379,
      "grad_norm": 2.1519157886505127,
      "learning_rate": 9.979018044481746e-05,
      "loss": 0.1938,
      "step": 13200
    },
    {
      "epoch": 4.590956161546427,
      "grad_norm": 1.6017084121704102,
      "learning_rate": 9.965481298986098e-05,
      "loss": 0.2018,
      "step": 13300
    },
    {
      "epoch": 4.625474628926476,
      "grad_norm": 1.3130571842193604,
      "learning_rate": 9.95194455349045e-05,
      "loss": 0.1968,
      "step": 13400
    },
    {
      "epoch": 4.659993096306524,
      "grad_norm": 1.2647309303283691,
      "learning_rate": 9.938407807994803e-05,
      "loss": 0.1905,
      "step": 13500
    },
    {
      "epoch": 4.694511563686572,
      "grad_norm": 1.9368891716003418,
      "learning_rate": 9.924871062499155e-05,
      "loss": 0.1855,
      "step": 13600
    },
    {
      "epoch": 4.729030031066621,
      "grad_norm": 1.2979217767715454,
      "learning_rate": 9.911334317003507e-05,
      "loss": 0.1996,
      "step": 13700
    },
    {
      "epoch": 4.763548498446669,
      "grad_norm": 1.300102949142456,
      "learning_rate": 9.897797571507858e-05,
      "loss": 0.1853,
      "step": 13800
    },
    {
      "epoch": 4.798066965826718,
      "grad_norm": 1.337873101234436,
      "learning_rate": 9.884260826012211e-05,
      "loss": 0.1979,
      "step": 13900
    },
    {
      "epoch": 4.8325854332067655,
      "grad_norm": 2.0335450172424316,
      "learning_rate": 9.870724080516562e-05,
      "loss": 0.1898,
      "step": 14000
    },
    {
      "epoch": 4.867103900586814,
      "grad_norm": 2.7741973400115967,
      "learning_rate": 9.857187335020914e-05,
      "loss": 0.1806,
      "step": 14100
    },
    {
      "epoch": 4.901622367966862,
      "grad_norm": 1.2439756393432617,
      "learning_rate": 9.843650589525267e-05,
      "loss": 0.1905,
      "step": 14200
    },
    {
      "epoch": 4.936140835346911,
      "grad_norm": 1.2351477146148682,
      "learning_rate": 9.83011384402962e-05,
      "loss": 0.1878,
      "step": 14300
    },
    {
      "epoch": 4.9706593027269586,
      "grad_norm": 3.2244904041290283,
      "learning_rate": 9.81657709853397e-05,
      "loss": 0.1781,
      "step": 14400
    },
    {
      "epoch": 5.005177770107007,
      "grad_norm": 1.7323291301727295,
      "learning_rate": 9.803040353038323e-05,
      "loss": 0.1765,
      "step": 14500
    },
    {
      "epoch": 5.039696237487056,
      "grad_norm": 1.163334608078003,
      "learning_rate": 9.789503607542675e-05,
      "loss": 0.1789,
      "step": 14600
    },
    {
      "epoch": 5.074214704867104,
      "grad_norm": 1.6086071729660034,
      "learning_rate": 9.775966862047027e-05,
      "loss": 0.1762,
      "step": 14700
    },
    {
      "epoch": 5.1087331722471525,
      "grad_norm": 0.9245924949645996,
      "learning_rate": 9.762430116551379e-05,
      "loss": 0.1708,
      "step": 14800
    },
    {
      "epoch": 5.1432516396272,
      "grad_norm": 1.2635128498077393,
      "learning_rate": 9.748893371055732e-05,
      "loss": 0.1732,
      "step": 14900
    },
    {
      "epoch": 5.177770107007249,
      "grad_norm": 1.3924487829208374,
      "learning_rate": 9.735356625560084e-05,
      "loss": 0.1697,
      "step": 15000
    },
    {
      "epoch": 5.212288574387297,
      "grad_norm": 1.1797153949737549,
      "learning_rate": 9.721819880064435e-05,
      "loss": 0.171,
      "step": 15100
    },
    {
      "epoch": 5.246807041767346,
      "grad_norm": 1.090725064277649,
      "learning_rate": 9.708283134568788e-05,
      "loss": 0.1661,
      "step": 15200
    },
    {
      "epoch": 5.281325509147393,
      "grad_norm": 1.2549749612808228,
      "learning_rate": 9.694746389073139e-05,
      "loss": 0.1636,
      "step": 15300
    },
    {
      "epoch": 5.315843976527442,
      "grad_norm": 1.3706892728805542,
      "learning_rate": 9.681209643577491e-05,
      "loss": 0.1665,
      "step": 15400
    },
    {
      "epoch": 5.350362443907491,
      "grad_norm": 1.2055859565734863,
      "learning_rate": 9.668079000446712e-05,
      "loss": 2.3613,
      "step": 15500
    },
    {
      "epoch": 5.384880911287539,
      "grad_norm": 1.9298726320266724,
      "learning_rate": 9.654542254951066e-05,
      "loss": 0.319,
      "step": 15600
    },
    {
      "epoch": 5.419399378667587,
      "grad_norm": 2.0660526752471924,
      "learning_rate": 9.641005509455417e-05,
      "loss": 0.1697,
      "step": 15700
    },
    {
      "epoch": 5.453917846047635,
      "grad_norm": 1.0108494758605957,
      "learning_rate": 9.62746876395977e-05,
      "loss": 0.1595,
      "step": 15800
    },
    {
      "epoch": 5.488436313427684,
      "grad_norm": 1.5239613056182861,
      "learning_rate": 9.61393201846412e-05,
      "loss": 0.1582,
      "step": 15900
    },
    {
      "epoch": 5.522954780807732,
      "grad_norm": 1.2143745422363281,
      "learning_rate": 9.600395272968473e-05,
      "loss": 0.1604,
      "step": 16000
    },
    {
      "epoch": 5.55747324818778,
      "grad_norm": 1.1710578203201294,
      "learning_rate": 9.586858527472826e-05,
      "loss": 0.1528,
      "step": 16100
    },
    {
      "epoch": 5.591991715567829,
      "grad_norm": 2.115018844604492,
      "learning_rate": 9.573321781977177e-05,
      "loss": 0.1578,
      "step": 16200
    },
    {
      "epoch": 5.626510182947877,
      "grad_norm": 1.3941495418548584,
      "learning_rate": 9.55978503648153e-05,
      "loss": 0.154,
      "step": 16300
    },
    {
      "epoch": 5.661028650327926,
      "grad_norm": 1.000432014465332,
      "learning_rate": 9.546248290985882e-05,
      "loss": 0.148,
      "step": 16400
    },
    {
      "epoch": 5.6955471177079735,
      "grad_norm": 1.1649655103683472,
      "learning_rate": 9.532711545490234e-05,
      "loss": 0.1433,
      "step": 16500
    },
    {
      "epoch": 5.730065585088022,
      "grad_norm": 1.0513373613357544,
      "learning_rate": 9.519174799994585e-05,
      "loss": 0.1538,
      "step": 16600
    },
    {
      "epoch": 5.76458405246807,
      "grad_norm": 2.0759968757629395,
      "learning_rate": 9.505638054498938e-05,
      "loss": 0.1481,
      "step": 16700
    },
    {
      "epoch": 5.799102519848119,
      "grad_norm": 1.2598356008529663,
      "learning_rate": 9.492101309003289e-05,
      "loss": 0.151,
      "step": 16800
    },
    {
      "epoch": 5.8336209872281675,
      "grad_norm": 2.0523197650909424,
      "learning_rate": 9.478564563507642e-05,
      "loss": 0.5299,
      "step": 16900
    },
    {
      "epoch": 5.868139454608215,
      "grad_norm": 1.225022792816162,
      "learning_rate": 9.465027818011994e-05,
      "loss": 0.148,
      "step": 17000
    },
    {
      "epoch": 5.902657921988264,
      "grad_norm": 1.3347996473312378,
      "learning_rate": 9.451491072516347e-05,
      "loss": 0.1495,
      "step": 17100
    },
    {
      "epoch": 5.937176389368312,
      "grad_norm": 1.1769174337387085,
      "learning_rate": 9.437954327020698e-05,
      "loss": 0.144,
      "step": 17200
    },
    {
      "epoch": 5.9716948567483605,
      "grad_norm": 2.3320469856262207,
      "learning_rate": 9.42441758152505e-05,
      "loss": 0.1393,
      "step": 17300
    },
    {
      "epoch": 6.006213324128408,
      "grad_norm": 1.5526262521743774,
      "learning_rate": 9.410880836029403e-05,
      "loss": 0.1379,
      "step": 17400
    },
    {
      "epoch": 6.040731791508457,
      "grad_norm": 1.4420545101165771,
      "learning_rate": 9.397344090533754e-05,
      "loss": 0.1391,
      "step": 17500
    },
    {
      "epoch": 6.075250258888506,
      "grad_norm": 1.021245002746582,
      "learning_rate": 9.383807345038106e-05,
      "loss": 0.1335,
      "step": 17600
    },
    {
      "epoch": 6.109768726268554,
      "grad_norm": 0.9755706787109375,
      "learning_rate": 9.370270599542459e-05,
      "loss": 0.1336,
      "step": 17700
    },
    {
      "epoch": 6.144287193648602,
      "grad_norm": 1.0951018333435059,
      "learning_rate": 9.356733854046811e-05,
      "loss": 0.1335,
      "step": 17800
    },
    {
      "epoch": 6.17880566102865,
      "grad_norm": 1.1797082424163818,
      "learning_rate": 9.343197108551162e-05,
      "loss": 0.1269,
      "step": 17900
    },
    {
      "epoch": 6.213324128408699,
      "grad_norm": 1.580867052078247,
      "learning_rate": 9.329660363055515e-05,
      "loss": 0.1336,
      "step": 18000
    },
    {
      "epoch": 6.247842595788747,
      "grad_norm": 1.047555923461914,
      "learning_rate": 9.316123617559866e-05,
      "loss": 0.1254,
      "step": 18100
    },
    {
      "epoch": 6.282361063168795,
      "grad_norm": 1.0629801750183105,
      "learning_rate": 9.302586872064219e-05,
      "loss": 0.1293,
      "step": 18200
    },
    {
      "epoch": 6.316879530548844,
      "grad_norm": 0.9719558954238892,
      "learning_rate": 9.28905012656857e-05,
      "loss": 0.1259,
      "step": 18300
    },
    {
      "epoch": 6.351397997928892,
      "grad_norm": 1.1493475437164307,
      "learning_rate": 9.275513381072924e-05,
      "loss": 0.149,
      "step": 18400
    },
    {
      "epoch": 6.385916465308941,
      "grad_norm": 5.943984031677246,
      "learning_rate": 9.261976635577275e-05,
      "loss": 0.1351,
      "step": 18500
    },
    {
      "epoch": 6.4204349326889885,
      "grad_norm": 1.7542070150375366,
      "learning_rate": 9.248439890081627e-05,
      "loss": 0.1265,
      "step": 18600
    },
    {
      "epoch": 6.454953400069037,
      "grad_norm": 1.114384412765503,
      "learning_rate": 9.234903144585978e-05,
      "loss": 0.1215,
      "step": 18700
    },
    {
      "epoch": 6.489471867449085,
      "grad_norm": 1.0790728330612183,
      "learning_rate": 9.221366399090331e-05,
      "loss": 0.1209,
      "step": 18800
    },
    {
      "epoch": 6.523990334829134,
      "grad_norm": 1.3289648294448853,
      "learning_rate": 9.207829653594683e-05,
      "loss": 0.1258,
      "step": 18900
    },
    {
      "epoch": 6.5585088022091815,
      "grad_norm": 1.1007156372070312,
      "learning_rate": 9.194292908099035e-05,
      "loss": 0.1204,
      "step": 19000
    },
    {
      "epoch": 6.59302726958923,
      "grad_norm": 1.0112175941467285,
      "learning_rate": 9.180756162603388e-05,
      "loss": 0.1207,
      "step": 19100
    },
    {
      "epoch": 6.627545736969278,
      "grad_norm": 1.1788666248321533,
      "learning_rate": 9.16721941710774e-05,
      "loss": 0.1202,
      "step": 19200
    },
    {
      "epoch": 6.662064204349327,
      "grad_norm": 1.079982876777649,
      "learning_rate": 9.153682671612092e-05,
      "loss": 0.1102,
      "step": 19300
    },
    {
      "epoch": 6.6965826717293755,
      "grad_norm": 1.1049679517745972,
      "learning_rate": 9.140145926116443e-05,
      "loss": 0.1112,
      "step": 19400
    },
    {
      "epoch": 6.731101139109423,
      "grad_norm": 1.081131100654602,
      "learning_rate": 9.126609180620796e-05,
      "loss": 0.119,
      "step": 19500
    },
    {
      "epoch": 6.765619606489472,
      "grad_norm": 0.9902765154838562,
      "learning_rate": 9.113072435125147e-05,
      "loss": 0.1133,
      "step": 19600
    },
    {
      "epoch": 6.80013807386952,
      "grad_norm": 0.9780551791191101,
      "learning_rate": 9.0995356896295e-05,
      "loss": 0.1173,
      "step": 19700
    },
    {
      "epoch": 6.834656541249569,
      "grad_norm": 1.299332857131958,
      "learning_rate": 9.085998944133852e-05,
      "loss": 0.1185,
      "step": 19800
    },
    {
      "epoch": 6.869175008629616,
      "grad_norm": 0.9444118738174438,
      "learning_rate": 9.072462198638204e-05,
      "loss": 0.1129,
      "step": 19900
    },
    {
      "epoch": 6.903693476009665,
      "grad_norm": 0.7810178995132446,
      "learning_rate": 9.058925453142555e-05,
      "loss": 0.1156,
      "step": 20000
    },
    {
      "epoch": 6.938211943389714,
      "grad_norm": 1.3095906972885132,
      "learning_rate": 9.045388707646908e-05,
      "loss": 0.1148,
      "step": 20100
    },
    {
      "epoch": 6.972730410769762,
      "grad_norm": 1.1924002170562744,
      "learning_rate": 9.03185196215126e-05,
      "loss": 0.1036,
      "step": 20200
    },
    {
      "epoch": 7.00724887814981,
      "grad_norm": 1.266143560409546,
      "learning_rate": 9.018315216655612e-05,
      "loss": 0.1068,
      "step": 20300
    },
    {
      "epoch": 7.041767345529858,
      "grad_norm": 1.561375617980957,
      "learning_rate": 9.004778471159964e-05,
      "loss": 0.1105,
      "step": 20400
    },
    {
      "epoch": 7.076285812909907,
      "grad_norm": 1.2043852806091309,
      "learning_rate": 8.991241725664317e-05,
      "loss": 0.1025,
      "step": 20500
    },
    {
      "epoch": 7.110804280289955,
      "grad_norm": 0.9600781798362732,
      "learning_rate": 8.977704980168669e-05,
      "loss": 0.1051,
      "step": 20600
    },
    {
      "epoch": 7.145322747670003,
      "grad_norm": 1.3169841766357422,
      "learning_rate": 8.96416823467302e-05,
      "loss": 0.1067,
      "step": 20700
    },
    {
      "epoch": 7.179841215050052,
      "grad_norm": 0.9294451475143433,
      "learning_rate": 8.950631489177373e-05,
      "loss": 0.1011,
      "step": 20800
    },
    {
      "epoch": 7.2143596824301,
      "grad_norm": 1.1165120601654053,
      "learning_rate": 8.937094743681724e-05,
      "loss": 0.1047,
      "step": 20900
    },
    {
      "epoch": 7.248878149810149,
      "grad_norm": 1.6173171997070312,
      "learning_rate": 8.923557998186076e-05,
      "loss": 0.1001,
      "step": 21000
    },
    {
      "epoch": 7.2833966171901965,
      "grad_norm": 0.9746047258377075,
      "learning_rate": 8.910021252690428e-05,
      "loss": 0.102,
      "step": 21100
    },
    {
      "epoch": 7.317915084570245,
      "grad_norm": 2.1759955883026123,
      "learning_rate": 8.896484507194781e-05,
      "loss": 0.1043,
      "step": 21200
    },
    {
      "epoch": 7.352433551950293,
      "grad_norm": 0.8180681467056274,
      "learning_rate": 8.882947761699133e-05,
      "loss": 0.1115,
      "step": 21300
    },
    {
      "epoch": 7.386952019330342,
      "grad_norm": 1.0945343971252441,
      "learning_rate": 8.869411016203485e-05,
      "loss": 0.1059,
      "step": 21400
    },
    {
      "epoch": 7.4214704867103904,
      "grad_norm": 0.9785796999931335,
      "learning_rate": 8.855874270707836e-05,
      "loss": 0.1014,
      "step": 21500
    },
    {
      "epoch": 7.455988954090438,
      "grad_norm": 0.7958143353462219,
      "learning_rate": 8.842337525212189e-05,
      "loss": 0.0945,
      "step": 21600
    },
    {
      "epoch": 7.490507421470487,
      "grad_norm": 1.9580931663513184,
      "learning_rate": 8.828800779716541e-05,
      "loss": 0.0979,
      "step": 21700
    },
    {
      "epoch": 7.525025888850535,
      "grad_norm": 0.6876654028892517,
      "learning_rate": 8.815264034220892e-05,
      "loss": 0.1016,
      "step": 21800
    },
    {
      "epoch": 7.5595443562305835,
      "grad_norm": 0.6609406471252441,
      "learning_rate": 8.801727288725246e-05,
      "loss": 0.0954,
      "step": 21900
    },
    {
      "epoch": 7.594062823610631,
      "grad_norm": 0.9547025561332703,
      "learning_rate": 8.788190543229597e-05,
      "loss": 0.0969,
      "step": 22000
    },
    {
      "epoch": 7.62858129099068,
      "grad_norm": 1.0690466165542603,
      "learning_rate": 8.77465379773395e-05,
      "loss": 0.0979,
      "step": 22100
    },
    {
      "epoch": 7.663099758370729,
      "grad_norm": 0.8682637810707092,
      "learning_rate": 8.761117052238301e-05,
      "loss": 0.093,
      "step": 22200
    },
    {
      "epoch": 7.697618225750777,
      "grad_norm": 0.9390236735343933,
      "learning_rate": 8.747580306742653e-05,
      "loss": 0.0889,
      "step": 22300
    },
    {
      "epoch": 7.732136693130825,
      "grad_norm": 1.099827527999878,
      "learning_rate": 8.734043561247005e-05,
      "loss": 0.0964,
      "step": 22400
    },
    {
      "epoch": 7.766655160510873,
      "grad_norm": 1.4270689487457275,
      "learning_rate": 8.720506815751357e-05,
      "loss": 0.0963,
      "step": 22500
    },
    {
      "epoch": 7.801173627890922,
      "grad_norm": 1.1373664140701294,
      "learning_rate": 8.70697007025571e-05,
      "loss": 0.0941,
      "step": 22600
    },
    {
      "epoch": 7.83569209527097,
      "grad_norm": 1.4565712213516235,
      "learning_rate": 8.693433324760062e-05,
      "loss": 0.0937,
      "step": 22700
    },
    {
      "epoch": 7.870210562651018,
      "grad_norm": 0.9914373159408569,
      "learning_rate": 8.679896579264413e-05,
      "loss": 0.0897,
      "step": 22800
    },
    {
      "epoch": 7.904729030031067,
      "grad_norm": 1.0314738750457764,
      "learning_rate": 8.666359833768766e-05,
      "loss": 0.0928,
      "step": 22900
    },
    {
      "epoch": 7.939247497411115,
      "grad_norm": 1.063502550125122,
      "learning_rate": 8.652823088273118e-05,
      "loss": 0.0921,
      "step": 23000
    },
    {
      "epoch": 7.973765964791164,
      "grad_norm": 0.9928939938545227,
      "learning_rate": 8.63928634277747e-05,
      "loss": 0.0891,
      "step": 23100
    },
    {
      "epoch": 8.008284432171212,
      "grad_norm": 1.4400365352630615,
      "learning_rate": 8.625749597281822e-05,
      "loss": 0.0866,
      "step": 23200
    },
    {
      "epoch": 8.04280289955126,
      "grad_norm": 1.0473341941833496,
      "learning_rate": 8.612212851786174e-05,
      "loss": 0.0909,
      "step": 23300
    },
    {
      "epoch": 8.077321366931308,
      "grad_norm": 1.0936847925186157,
      "learning_rate": 8.598676106290527e-05,
      "loss": 0.0834,
      "step": 23400
    },
    {
      "epoch": 8.111839834311356,
      "grad_norm": 0.6177169680595398,
      "learning_rate": 8.585139360794878e-05,
      "loss": 0.0864,
      "step": 23500
    },
    {
      "epoch": 8.146358301691405,
      "grad_norm": 1.1170318126678467,
      "learning_rate": 8.57160261529923e-05,
      "loss": 0.0863,
      "step": 23600
    },
    {
      "epoch": 8.180876769071453,
      "grad_norm": 0.9137024879455566,
      "learning_rate": 8.558065869803582e-05,
      "loss": 0.0848,
      "step": 23700
    },
    {
      "epoch": 8.215395236451501,
      "grad_norm": 1.0272520780563354,
      "learning_rate": 8.544529124307934e-05,
      "loss": 0.0862,
      "step": 23800
    },
    {
      "epoch": 8.24991370383155,
      "grad_norm": 0.7476533651351929,
      "learning_rate": 8.530992378812285e-05,
      "loss": 0.0795,
      "step": 23900
    },
    {
      "epoch": 8.284432171211598,
      "grad_norm": 0.6880142092704773,
      "learning_rate": 8.517455633316639e-05,
      "loss": 0.0828,
      "step": 24000
    },
    {
      "epoch": 8.318950638591646,
      "grad_norm": 0.902614414691925,
      "learning_rate": 8.50391888782099e-05,
      "loss": 0.0847,
      "step": 24100
    },
    {
      "epoch": 8.353469105971694,
      "grad_norm": 0.7625252604484558,
      "learning_rate": 8.490382142325343e-05,
      "loss": 0.0886,
      "step": 24200
    },
    {
      "epoch": 8.387987573351744,
      "grad_norm": 1.0490803718566895,
      "learning_rate": 8.476845396829694e-05,
      "loss": 0.087,
      "step": 24300
    },
    {
      "epoch": 8.422506040731792,
      "grad_norm": 0.6203135251998901,
      "learning_rate": 8.463308651334046e-05,
      "loss": 0.0849,
      "step": 24400
    },
    {
      "epoch": 8.45702450811184,
      "grad_norm": 0.9258949160575867,
      "learning_rate": 8.449771905838399e-05,
      "loss": 0.0824,
      "step": 24500
    },
    {
      "epoch": 8.491542975491889,
      "grad_norm": 1.104141116142273,
      "learning_rate": 8.43623516034275e-05,
      "loss": 0.082,
      "step": 24600
    },
    {
      "epoch": 8.526061442871937,
      "grad_norm": 0.8000738024711609,
      "learning_rate": 8.422698414847104e-05,
      "loss": 0.0835,
      "step": 24700
    },
    {
      "epoch": 8.560579910251985,
      "grad_norm": 0.6273342967033386,
      "learning_rate": 8.409161669351455e-05,
      "loss": 0.0766,
      "step": 24800
    },
    {
      "epoch": 8.595098377632032,
      "grad_norm": 1.0340856313705444,
      "learning_rate": 8.395624923855808e-05,
      "loss": 0.083,
      "step": 24900
    },
    {
      "epoch": 8.629616845012082,
      "grad_norm": 1.0838382244110107,
      "learning_rate": 8.382088178360159e-05,
      "loss": 0.0822,
      "step": 25000
    },
    {
      "epoch": 8.66413531239213,
      "grad_norm": 0.8141922354698181,
      "learning_rate": 8.368551432864511e-05,
      "loss": 0.0743,
      "step": 25100
    },
    {
      "epoch": 8.698653779772178,
      "grad_norm": 0.8033334016799927,
      "learning_rate": 8.355014687368862e-05,
      "loss": 0.0768,
      "step": 25200
    },
    {
      "epoch": 8.733172247152226,
      "grad_norm": 0.7984203100204468,
      "learning_rate": 8.341477941873215e-05,
      "loss": 0.0777,
      "step": 25300
    },
    {
      "epoch": 8.767690714532275,
      "grad_norm": 0.90219646692276,
      "learning_rate": 8.327941196377567e-05,
      "loss": 0.0805,
      "step": 25400
    },
    {
      "epoch": 8.802209181912323,
      "grad_norm": 1.0864392518997192,
      "learning_rate": 8.31440445088192e-05,
      "loss": 0.0773,
      "step": 25500
    },
    {
      "epoch": 8.83672764929237,
      "grad_norm": 0.9871200323104858,
      "learning_rate": 8.300867705386271e-05,
      "loss": 0.0803,
      "step": 25600
    },
    {
      "epoch": 8.87124611667242,
      "grad_norm": 0.698334813117981,
      "learning_rate": 8.287330959890624e-05,
      "loss": 0.0796,
      "step": 25700
    },
    {
      "epoch": 8.905764584052468,
      "grad_norm": 0.6968787312507629,
      "learning_rate": 8.273794214394975e-05,
      "loss": 0.0777,
      "step": 25800
    },
    {
      "epoch": 8.940283051432516,
      "grad_norm": 0.9071696400642395,
      "learning_rate": 8.260257468899327e-05,
      "loss": 0.0801,
      "step": 25900
    },
    {
      "epoch": 8.974801518812566,
      "grad_norm": 0.9089698791503906,
      "learning_rate": 8.24672072340368e-05,
      "loss": 0.0722,
      "step": 26000
    },
    {
      "epoch": 9.009319986192613,
      "grad_norm": 0.7080366611480713,
      "learning_rate": 8.233183977908032e-05,
      "loss": 0.0736,
      "step": 26100
    },
    {
      "epoch": 9.043838453572661,
      "grad_norm": 0.81602942943573,
      "learning_rate": 8.219647232412385e-05,
      "loss": 0.0754,
      "step": 26200
    },
    {
      "epoch": 9.078356920952709,
      "grad_norm": 2.244941234588623,
      "learning_rate": 8.206110486916736e-05,
      "loss": 0.074,
      "step": 26300
    },
    {
      "epoch": 9.112875388332759,
      "grad_norm": 0.8162432312965393,
      "learning_rate": 8.192573741421088e-05,
      "loss": 0.0725,
      "step": 26400
    },
    {
      "epoch": 9.147393855712806,
      "grad_norm": 0.8993543386459351,
      "learning_rate": 8.17903699592544e-05,
      "loss": 0.0733,
      "step": 26500
    },
    {
      "epoch": 9.181912323092854,
      "grad_norm": 0.8871236443519592,
      "learning_rate": 8.165500250429792e-05,
      "loss": 0.0655,
      "step": 26600
    },
    {
      "epoch": 9.216430790472902,
      "grad_norm": 0.9257796406745911,
      "learning_rate": 8.151963504934143e-05,
      "loss": 0.0744,
      "step": 26700
    },
    {
      "epoch": 9.250949257852952,
      "grad_norm": 0.8722217082977295,
      "learning_rate": 8.138426759438497e-05,
      "loss": 0.0687,
      "step": 26800
    },
    {
      "epoch": 9.285467725233,
      "grad_norm": 0.486891508102417,
      "learning_rate": 8.124890013942848e-05,
      "loss": 0.0709,
      "step": 26900
    },
    {
      "epoch": 9.319986192613047,
      "grad_norm": 1.0775293111801147,
      "learning_rate": 8.1113532684472e-05,
      "loss": 0.0728,
      "step": 27000
    },
    {
      "epoch": 9.354504659993097,
      "grad_norm": 0.5958520770072937,
      "learning_rate": 8.097816522951552e-05,
      "loss": 0.0742,
      "step": 27100
    },
    {
      "epoch": 9.389023127373145,
      "grad_norm": 1.0849195718765259,
      "learning_rate": 8.084279777455904e-05,
      "loss": 0.0748,
      "step": 27200
    },
    {
      "epoch": 9.423541594753193,
      "grad_norm": 0.9914372563362122,
      "learning_rate": 8.070743031960257e-05,
      "loss": 0.0733,
      "step": 27300
    },
    {
      "epoch": 9.45806006213324,
      "grad_norm": 1.2824517488479614,
      "learning_rate": 8.057206286464608e-05,
      "loss": 0.0662,
      "step": 27400
    },
    {
      "epoch": 9.49257852951329,
      "grad_norm": 0.9422186613082886,
      "learning_rate": 8.04366954096896e-05,
      "loss": 0.0709,
      "step": 27500
    },
    {
      "epoch": 9.527096996893338,
      "grad_norm": 0.9151649475097656,
      "learning_rate": 8.030132795473313e-05,
      "loss": 0.0706,
      "step": 27600
    },
    {
      "epoch": 9.561615464273386,
      "grad_norm": 1.1446008682250977,
      "learning_rate": 8.016596049977665e-05,
      "loss": 0.0705,
      "step": 27700
    },
    {
      "epoch": 9.596133931653435,
      "grad_norm": 0.7251843214035034,
      "learning_rate": 8.003059304482017e-05,
      "loss": 0.0705,
      "step": 27800
    },
    {
      "epoch": 9.630652399033483,
      "grad_norm": 0.5994897484779358,
      "learning_rate": 7.989522558986369e-05,
      "loss": 0.069,
      "step": 27900
    },
    {
      "epoch": 9.665170866413531,
      "grad_norm": 0.755567193031311,
      "learning_rate": 7.97598581349072e-05,
      "loss": 0.0652,
      "step": 28000
    },
    {
      "epoch": 9.699689333793579,
      "grad_norm": 0.779396116733551,
      "learning_rate": 7.962449067995073e-05,
      "loss": 0.0638,
      "step": 28100
    },
    {
      "epoch": 9.734207801173628,
      "grad_norm": 0.8016577959060669,
      "learning_rate": 7.948912322499425e-05,
      "loss": 0.068,
      "step": 28200
    },
    {
      "epoch": 9.768726268553676,
      "grad_norm": 0.6884955167770386,
      "learning_rate": 7.935375577003778e-05,
      "loss": 0.0665,
      "step": 28300
    },
    {
      "epoch": 9.803244735933724,
      "grad_norm": 0.7460110783576965,
      "learning_rate": 7.921838831508129e-05,
      "loss": 0.0672,
      "step": 28400
    },
    {
      "epoch": 9.837763203313774,
      "grad_norm": 0.5377070307731628,
      "learning_rate": 7.908302086012481e-05,
      "loss": 0.0659,
      "step": 28500
    },
    {
      "epoch": 9.872281670693821,
      "grad_norm": 0.8101962804794312,
      "learning_rate": 7.894765340516832e-05,
      "loss": 0.0667,
      "step": 28600
    },
    {
      "epoch": 9.90680013807387,
      "grad_norm": 0.8326902389526367,
      "learning_rate": 7.881228595021185e-05,
      "loss": 0.0686,
      "step": 28700
    },
    {
      "epoch": 9.941318605453917,
      "grad_norm": 0.9693453311920166,
      "learning_rate": 7.867691849525537e-05,
      "loss": 0.067,
      "step": 28800
    },
    {
      "epoch": 9.975837072833967,
      "grad_norm": 1.060250163078308,
      "learning_rate": 7.85415510402989e-05,
      "loss": 0.0633,
      "step": 28900
    }
  ],
  "logging_steps": 100,
  "max_steps": 86910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.9364015359836165e+21,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
