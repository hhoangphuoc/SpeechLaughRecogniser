{
  "best_metric": 0.46964612100081404,
  "best_model_checkpoint": "../checkpoints/whisper-batch16-30epochs-lr1e4/checkpoint-5794",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 11588,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03451846738004832,
      "grad_norm": 16.437711715698242,
      "learning_rate": 7.363657283117282e-07,
      "loss": 3.9016,
      "step": 100
    },
    {
      "epoch": 0.06903693476009665,
      "grad_norm": 4.173903465270996,
      "learning_rate": 1.5034133619697783e-06,
      "loss": 1.0256,
      "step": 200
    },
    {
      "epoch": 0.10355540214014498,
      "grad_norm": 3.090409278869629,
      "learning_rate": 2.2704609956278286e-06,
      "loss": 0.2219,
      "step": 300
    },
    {
      "epoch": 0.1380738695201933,
      "grad_norm": 2.584890365600586,
      "learning_rate": 3.0375086292858787e-06,
      "loss": 0.2021,
      "step": 400
    },
    {
      "epoch": 0.17259233690024162,
      "grad_norm": 1.8284205198287964,
      "learning_rate": 3.804556262943929e-06,
      "loss": 0.1892,
      "step": 500
    },
    {
      "epoch": 0.20711080428028997,
      "grad_norm": 2.037623167037964,
      "learning_rate": 4.57160389660198e-06,
      "loss": 0.1853,
      "step": 600
    },
    {
      "epoch": 0.2416292716603383,
      "grad_norm": 1.620039463043213,
      "learning_rate": 5.338651530260029e-06,
      "loss": 0.1867,
      "step": 700
    },
    {
      "epoch": 0.2761477390403866,
      "grad_norm": 1.670066475868225,
      "learning_rate": 6.10569916391808e-06,
      "loss": 0.1767,
      "step": 800
    },
    {
      "epoch": 0.3106662064204349,
      "grad_norm": 2.539682626724243,
      "learning_rate": 6.8727467975761295e-06,
      "loss": 0.1769,
      "step": 900
    },
    {
      "epoch": 0.34518467380048323,
      "grad_norm": 1.547996997833252,
      "learning_rate": 7.63979443123418e-06,
      "loss": 0.1746,
      "step": 1000
    },
    {
      "epoch": 0.3797031411805316,
      "grad_norm": 1.2656190395355225,
      "learning_rate": 8.40684206489223e-06,
      "loss": 0.1814,
      "step": 1100
    },
    {
      "epoch": 0.41422160856057993,
      "grad_norm": 1.8952339887619019,
      "learning_rate": 9.173889698550281e-06,
      "loss": 0.1764,
      "step": 1200
    },
    {
      "epoch": 0.44874007594062826,
      "grad_norm": 1.8723512887954712,
      "learning_rate": 9.94093733220833e-06,
      "loss": 0.1728,
      "step": 1300
    },
    {
      "epoch": 0.4832585433206766,
      "grad_norm": 3.3941519260406494,
      "learning_rate": 1.0707984965866382e-05,
      "loss": 0.1716,
      "step": 1400
    },
    {
      "epoch": 0.5177770107007249,
      "grad_norm": 1.5956722497940063,
      "learning_rate": 1.1475032599524432e-05,
      "loss": 0.1841,
      "step": 1500
    },
    {
      "epoch": 0.5522954780807732,
      "grad_norm": 1.4848670959472656,
      "learning_rate": 1.2242080233182481e-05,
      "loss": 0.1779,
      "step": 1600
    },
    {
      "epoch": 0.5868139454608216,
      "grad_norm": 1.2174705266952515,
      "learning_rate": 1.3009127866840531e-05,
      "loss": 0.1776,
      "step": 1700
    },
    {
      "epoch": 0.6213324128408698,
      "grad_norm": 1.394303321838379,
      "learning_rate": 1.377617550049858e-05,
      "loss": 0.1794,
      "step": 1800
    },
    {
      "epoch": 0.6558508802209182,
      "grad_norm": 1.6510287523269653,
      "learning_rate": 1.454322313415663e-05,
      "loss": 0.1804,
      "step": 1900
    },
    {
      "epoch": 0.6903693476009665,
      "grad_norm": 2.2874436378479004,
      "learning_rate": 1.531027076781468e-05,
      "loss": 0.1777,
      "step": 2000
    },
    {
      "epoch": 0.7248878149810148,
      "grad_norm": 1.370835781097412,
      "learning_rate": 1.607731840147273e-05,
      "loss": 0.1828,
      "step": 2100
    },
    {
      "epoch": 0.7594062823610632,
      "grad_norm": 1.8295350074768066,
      "learning_rate": 1.684436603513078e-05,
      "loss": 0.1844,
      "step": 2200
    },
    {
      "epoch": 0.7939247497411115,
      "grad_norm": 1.525498628616333,
      "learning_rate": 1.761141366878883e-05,
      "loss": 0.1861,
      "step": 2300
    },
    {
      "epoch": 0.8284432171211599,
      "grad_norm": 1.601014256477356,
      "learning_rate": 1.8378461302446883e-05,
      "loss": 0.1906,
      "step": 2400
    },
    {
      "epoch": 0.8629616845012081,
      "grad_norm": 1.4148662090301514,
      "learning_rate": 1.9145508936104933e-05,
      "loss": 0.1867,
      "step": 2500
    },
    {
      "epoch": 0.8974801518812565,
      "grad_norm": 2.565661907196045,
      "learning_rate": 1.9912556569762983e-05,
      "loss": 0.1895,
      "step": 2600
    },
    {
      "epoch": 0.9319986192613048,
      "grad_norm": 2.004685640335083,
      "learning_rate": 2.0679604203421032e-05,
      "loss": 0.1924,
      "step": 2700
    },
    {
      "epoch": 0.9665170866413532,
      "grad_norm": 1.5717511177062988,
      "learning_rate": 2.1446651837079085e-05,
      "loss": 0.1939,
      "step": 2800
    },
    {
      "epoch": 1.0010355540214015,
      "grad_norm": 1.3768088817596436,
      "learning_rate": 2.2213699470737135e-05,
      "loss": 0.1883,
      "step": 2900
    },
    {
      "epoch": 1.0355540214014498,
      "grad_norm": 1.5252751111984253,
      "learning_rate": 2.2980747104395185e-05,
      "loss": 0.1963,
      "step": 3000
    },
    {
      "epoch": 1.070072488781498,
      "grad_norm": 1.5679250955581665,
      "learning_rate": 2.3747794738053234e-05,
      "loss": 0.1912,
      "step": 3100
    },
    {
      "epoch": 1.1045909561615463,
      "grad_norm": 1.799655795097351,
      "learning_rate": 2.4514842371711287e-05,
      "loss": 0.1889,
      "step": 3200
    },
    {
      "epoch": 1.1391094235415948,
      "grad_norm": 1.458052158355713,
      "learning_rate": 2.5281890005369334e-05,
      "loss": 0.1918,
      "step": 3300
    },
    {
      "epoch": 1.173627890921643,
      "grad_norm": 1.3675026893615723,
      "learning_rate": 2.6048937639027387e-05,
      "loss": 0.1851,
      "step": 3400
    },
    {
      "epoch": 1.2081463583016914,
      "grad_norm": 1.5124677419662476,
      "learning_rate": 2.6815985272685433e-05,
      "loss": 0.1845,
      "step": 3500
    },
    {
      "epoch": 1.2426648256817396,
      "grad_norm": 1.567418098449707,
      "learning_rate": 2.7583032906343486e-05,
      "loss": 0.1837,
      "step": 3600
    },
    {
      "epoch": 1.2771832930617881,
      "grad_norm": 1.3890578746795654,
      "learning_rate": 2.8350080540001532e-05,
      "loss": 0.1792,
      "step": 3700
    },
    {
      "epoch": 1.3117017604418364,
      "grad_norm": 1.5341869592666626,
      "learning_rate": 2.9117128173659585e-05,
      "loss": 0.1775,
      "step": 3800
    },
    {
      "epoch": 1.3462202278218847,
      "grad_norm": 1.3133047819137573,
      "learning_rate": 2.988417580731764e-05,
      "loss": 0.1757,
      "step": 3900
    },
    {
      "epoch": 1.380738695201933,
      "grad_norm": 1.4311901330947876,
      "learning_rate": 3.0651223440975685e-05,
      "loss": 0.1816,
      "step": 4000
    },
    {
      "epoch": 1.4152571625819814,
      "grad_norm": 1.3311220407485962,
      "learning_rate": 3.141827107463374e-05,
      "loss": 0.174,
      "step": 4100
    },
    {
      "epoch": 1.4497756299620297,
      "grad_norm": 1.3182005882263184,
      "learning_rate": 3.2185318708291784e-05,
      "loss": 0.1733,
      "step": 4200
    },
    {
      "epoch": 1.484294097342078,
      "grad_norm": 1.3645782470703125,
      "learning_rate": 3.295236634194984e-05,
      "loss": 0.168,
      "step": 4300
    },
    {
      "epoch": 1.5188125647221264,
      "grad_norm": 1.2748032808303833,
      "learning_rate": 3.371941397560789e-05,
      "loss": 0.1749,
      "step": 4400
    },
    {
      "epoch": 1.5533310321021747,
      "grad_norm": 1.6928858757019043,
      "learning_rate": 3.4486461609265936e-05,
      "loss": 0.1714,
      "step": 4500
    },
    {
      "epoch": 1.587849499482223,
      "grad_norm": 2.1964364051818848,
      "learning_rate": 3.525350924292399e-05,
      "loss": 0.1696,
      "step": 4600
    },
    {
      "epoch": 1.6223679668622712,
      "grad_norm": 1.8937830924987793,
      "learning_rate": 3.602055687658204e-05,
      "loss": 0.1663,
      "step": 4700
    },
    {
      "epoch": 1.6568864342423195,
      "grad_norm": 1.4079968929290771,
      "learning_rate": 3.678760451024009e-05,
      "loss": 0.166,
      "step": 4800
    },
    {
      "epoch": 1.691404901622368,
      "grad_norm": 1.5763765573501587,
      "learning_rate": 3.755465214389814e-05,
      "loss": 0.1662,
      "step": 4900
    },
    {
      "epoch": 1.7259233690024163,
      "grad_norm": 1.3568507432937622,
      "learning_rate": 3.832169977755619e-05,
      "loss": 0.1681,
      "step": 5000
    },
    {
      "epoch": 1.7604418363824648,
      "grad_norm": 1.4189971685409546,
      "learning_rate": 3.908874741121424e-05,
      "loss": 0.1708,
      "step": 5100
    },
    {
      "epoch": 1.794960303762513,
      "grad_norm": 1.7245495319366455,
      "learning_rate": 3.9855795044872294e-05,
      "loss": 0.1661,
      "step": 5200
    },
    {
      "epoch": 1.8294787711425613,
      "grad_norm": 1.5281909704208374,
      "learning_rate": 4.062284267853034e-05,
      "loss": 0.1716,
      "step": 5300
    },
    {
      "epoch": 1.8639972385226096,
      "grad_norm": 1.1399623155593872,
      "learning_rate": 4.1389890312188386e-05,
      "loss": 0.1647,
      "step": 5400
    },
    {
      "epoch": 1.8985157059026578,
      "grad_norm": 1.4757425785064697,
      "learning_rate": 4.215693794584644e-05,
      "loss": 0.1721,
      "step": 5500
    },
    {
      "epoch": 1.933034173282706,
      "grad_norm": 1.9753954410552979,
      "learning_rate": 4.2923985579504486e-05,
      "loss": 0.1703,
      "step": 5600
    },
    {
      "epoch": 1.9675526406627546,
      "grad_norm": 1.2039421796798706,
      "learning_rate": 4.369103321316254e-05,
      "loss": 0.1712,
      "step": 5700
    },
    {
      "epoch": 2.002071108042803,
      "grad_norm": 2.068314790725708,
      "learning_rate": 4.4458080846820585e-05,
      "loss": 0.1652,
      "step": 5800
    },
    {
      "epoch": 2.0365895754228514,
      "grad_norm": 1.6163781881332397,
      "learning_rate": 4.522512848047864e-05,
      "loss": 0.1712,
      "step": 5900
    },
    {
      "epoch": 2.0711080428028996,
      "grad_norm": 1.4308738708496094,
      "learning_rate": 4.599217611413669e-05,
      "loss": 0.1655,
      "step": 6000
    },
    {
      "epoch": 2.105626510182948,
      "grad_norm": 1.809465765953064,
      "learning_rate": 4.675922374779474e-05,
      "loss": 0.1655,
      "step": 6100
    },
    {
      "epoch": 2.140144977562996,
      "grad_norm": 1.1983938217163086,
      "learning_rate": 4.752627138145279e-05,
      "loss": 0.1691,
      "step": 6200
    },
    {
      "epoch": 2.1746634449430444,
      "grad_norm": 1.1571654081344604,
      "learning_rate": 4.8293319015110837e-05,
      "loss": 0.1661,
      "step": 6300
    },
    {
      "epoch": 2.2091819123230927,
      "grad_norm": 1.5591026544570923,
      "learning_rate": 4.906036664876889e-05,
      "loss": 0.1645,
      "step": 6400
    },
    {
      "epoch": 2.2437003797031414,
      "grad_norm": 1.5288466215133667,
      "learning_rate": 4.982741428242694e-05,
      "loss": 0.1643,
      "step": 6500
    },
    {
      "epoch": 2.2782188470831897,
      "grad_norm": 1.4822238683700562,
      "learning_rate": 5.059446191608499e-05,
      "loss": 0.1628,
      "step": 6600
    },
    {
      "epoch": 2.312737314463238,
      "grad_norm": 4.289336204528809,
      "learning_rate": 5.1361509549743035e-05,
      "loss": 0.1658,
      "step": 6700
    },
    {
      "epoch": 2.347255781843286,
      "grad_norm": 1.9869149923324585,
      "learning_rate": 5.2128557183401095e-05,
      "loss": 0.1658,
      "step": 6800
    },
    {
      "epoch": 2.3817742492233345,
      "grad_norm": 1.8263919353485107,
      "learning_rate": 5.289560481705914e-05,
      "loss": 0.1728,
      "step": 6900
    },
    {
      "epoch": 2.4162927166033827,
      "grad_norm": 2.576864719390869,
      "learning_rate": 5.366265245071719e-05,
      "loss": 0.1658,
      "step": 7000
    },
    {
      "epoch": 2.450811183983431,
      "grad_norm": 1.6180498600006104,
      "learning_rate": 5.442970008437525e-05,
      "loss": 0.1675,
      "step": 7100
    },
    {
      "epoch": 2.4853296513634793,
      "grad_norm": 2.3834640979766846,
      "learning_rate": 5.5196747718033294e-05,
      "loss": 0.1653,
      "step": 7200
    },
    {
      "epoch": 2.5198481187435275,
      "grad_norm": 1.3891485929489136,
      "learning_rate": 5.596379535169134e-05,
      "loss": 0.1715,
      "step": 7300
    },
    {
      "epoch": 2.5543665861235763,
      "grad_norm": 1.2805721759796143,
      "learning_rate": 5.67308429853494e-05,
      "loss": 0.1697,
      "step": 7400
    },
    {
      "epoch": 2.5888850535036245,
      "grad_norm": 1.4183192253112793,
      "learning_rate": 5.7497890619007446e-05,
      "loss": 0.1687,
      "step": 7500
    },
    {
      "epoch": 2.623403520883673,
      "grad_norm": 1.2891600131988525,
      "learning_rate": 5.826493825266549e-05,
      "loss": 0.1661,
      "step": 7600
    },
    {
      "epoch": 2.657921988263721,
      "grad_norm": 1.887508511543274,
      "learning_rate": 5.903198588632355e-05,
      "loss": 0.1683,
      "step": 7700
    },
    {
      "epoch": 2.6924404556437693,
      "grad_norm": 1.1817164421081543,
      "learning_rate": 5.97990335199816e-05,
      "loss": 0.167,
      "step": 7800
    },
    {
      "epoch": 2.7269589230238176,
      "grad_norm": 1.5057417154312134,
      "learning_rate": 6.0566081153639644e-05,
      "loss": 0.1698,
      "step": 7900
    },
    {
      "epoch": 2.761477390403866,
      "grad_norm": 1.2045913934707642,
      "learning_rate": 6.133312878729768e-05,
      "loss": 0.1711,
      "step": 8000
    },
    {
      "epoch": 2.7959958577839146,
      "grad_norm": 2.362670660018921,
      "learning_rate": 6.210017642095574e-05,
      "loss": 0.1754,
      "step": 8100
    },
    {
      "epoch": 2.830514325163963,
      "grad_norm": 1.0338811874389648,
      "learning_rate": 6.286722405461379e-05,
      "loss": 0.1732,
      "step": 8200
    },
    {
      "epoch": 2.865032792544011,
      "grad_norm": 1.3439247608184814,
      "learning_rate": 6.363427168827184e-05,
      "loss": 0.1721,
      "step": 8300
    },
    {
      "epoch": 2.8995512599240594,
      "grad_norm": 2.028209924697876,
      "learning_rate": 6.44013193219299e-05,
      "loss": 0.177,
      "step": 8400
    },
    {
      "epoch": 2.9340697273041076,
      "grad_norm": 1.6115021705627441,
      "learning_rate": 6.516836695558794e-05,
      "loss": 0.1774,
      "step": 8500
    },
    {
      "epoch": 2.968588194684156,
      "grad_norm": 1.486113429069519,
      "learning_rate": 6.593541458924599e-05,
      "loss": 0.1729,
      "step": 8600
    },
    {
      "epoch": 3.003106662064204,
      "grad_norm": 1.6238961219787598,
      "learning_rate": 6.670246222290405e-05,
      "loss": 0.1772,
      "step": 8700
    },
    {
      "epoch": 3.037625129444253,
      "grad_norm": 1.7431244850158691,
      "learning_rate": 6.74695098565621e-05,
      "loss": 0.181,
      "step": 8800
    },
    {
      "epoch": 3.072143596824301,
      "grad_norm": 1.379980206489563,
      "learning_rate": 6.823655749022014e-05,
      "loss": 0.1768,
      "step": 8900
    },
    {
      "epoch": 3.1066620642043494,
      "grad_norm": 1.7019975185394287,
      "learning_rate": 6.90036051238782e-05,
      "loss": 0.1748,
      "step": 9000
    },
    {
      "epoch": 3.1411805315843977,
      "grad_norm": 1.8437260389328003,
      "learning_rate": 6.977065275753625e-05,
      "loss": 0.1796,
      "step": 9100
    },
    {
      "epoch": 3.175698998964446,
      "grad_norm": 1.3449459075927734,
      "learning_rate": 7.05377003911943e-05,
      "loss": 0.1758,
      "step": 9200
    },
    {
      "epoch": 3.2102174663444942,
      "grad_norm": 2.255277633666992,
      "learning_rate": 7.130474802485234e-05,
      "loss": 0.1813,
      "step": 9300
    },
    {
      "epoch": 3.2447359337245425,
      "grad_norm": 2.076322078704834,
      "learning_rate": 7.20717956585104e-05,
      "loss": 0.1756,
      "step": 9400
    },
    {
      "epoch": 3.2792544011045908,
      "grad_norm": 1.430654764175415,
      "learning_rate": 7.283884329216845e-05,
      "loss": 0.1735,
      "step": 9500
    },
    {
      "epoch": 3.313772868484639,
      "grad_norm": 1.6131263971328735,
      "learning_rate": 7.360589092582649e-05,
      "loss": 0.1805,
      "step": 9600
    },
    {
      "epoch": 3.3482913358646877,
      "grad_norm": 1.6867321729660034,
      "learning_rate": 7.437293855948455e-05,
      "loss": 0.1817,
      "step": 9700
    },
    {
      "epoch": 3.382809803244736,
      "grad_norm": 1.334987759590149,
      "learning_rate": 7.51399861931426e-05,
      "loss": 0.1822,
      "step": 9800
    },
    {
      "epoch": 3.4173282706247843,
      "grad_norm": 1.732893466949463,
      "learning_rate": 7.590703382680064e-05,
      "loss": 0.1837,
      "step": 9900
    },
    {
      "epoch": 3.4518467380048325,
      "grad_norm": 1.3498629331588745,
      "learning_rate": 7.66740814604587e-05,
      "loss": 0.1823,
      "step": 10000
    },
    {
      "epoch": 3.486365205384881,
      "grad_norm": 1.2991905212402344,
      "learning_rate": 7.744112909411675e-05,
      "loss": 0.1806,
      "step": 10100
    },
    {
      "epoch": 3.520883672764929,
      "grad_norm": 1.8523634672164917,
      "learning_rate": 7.82081767277748e-05,
      "loss": 0.1919,
      "step": 10200
    },
    {
      "epoch": 3.5554021401449774,
      "grad_norm": 2.2396650314331055,
      "learning_rate": 7.897522436143286e-05,
      "loss": 0.1838,
      "step": 10300
    },
    {
      "epoch": 3.589920607525026,
      "grad_norm": 1.9056228399276733,
      "learning_rate": 7.97422719950909e-05,
      "loss": 0.1869,
      "step": 10400
    },
    {
      "epoch": 3.6244390749050743,
      "grad_norm": 2.9103682041168213,
      "learning_rate": 8.050931962874895e-05,
      "loss": 0.1889,
      "step": 10500
    },
    {
      "epoch": 3.6589575422851226,
      "grad_norm": 1.8249459266662598,
      "learning_rate": 8.1276367262407e-05,
      "loss": 0.1853,
      "step": 10600
    },
    {
      "epoch": 3.693476009665171,
      "grad_norm": 1.2817367315292358,
      "learning_rate": 8.204341489606505e-05,
      "loss": 0.1799,
      "step": 10700
    },
    {
      "epoch": 3.727994477045219,
      "grad_norm": 1.3947725296020508,
      "learning_rate": 8.278745110071335e-05,
      "loss": 0.2465,
      "step": 10800
    },
    {
      "epoch": 3.7625129444252674,
      "grad_norm": 1.4129308462142944,
      "learning_rate": 8.355449873437141e-05,
      "loss": 0.1917,
      "step": 10900
    },
    {
      "epoch": 3.7970314118053157,
      "grad_norm": 1.3012921810150146,
      "learning_rate": 8.431387589169288e-05,
      "loss": 0.7368,
      "step": 11000
    },
    {
      "epoch": 3.8315498791853644,
      "grad_norm": 1.414388656616211,
      "learning_rate": 8.508092352535093e-05,
      "loss": 0.1947,
      "step": 11100
    },
    {
      "epoch": 3.8660683465654127,
      "grad_norm": 1.7311944961547852,
      "learning_rate": 8.584797115900897e-05,
      "loss": 0.1834,
      "step": 11200
    },
    {
      "epoch": 3.900586813945461,
      "grad_norm": 1.5937342643737793,
      "learning_rate": 8.661501879266702e-05,
      "loss": 0.1942,
      "step": 11300
    },
    {
      "epoch": 3.935105281325509,
      "grad_norm": 1.1818612813949585,
      "learning_rate": 8.738206642632508e-05,
      "loss": 0.1942,
      "step": 11400
    },
    {
      "epoch": 3.9696237487055575,
      "grad_norm": 2.001777410507202,
      "learning_rate": 8.814911405998312e-05,
      "loss": 0.1893,
      "step": 11500
    }
  ],
  "logging_steps": 100,
  "max_steps": 86910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5745606143934464e+21,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
