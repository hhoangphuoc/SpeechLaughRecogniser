{
  "best_metric": 0.46964612100081404,
  "best_model_checkpoint": "../checkpoints/whisper-batch16-30epochs-lr1e4/checkpoint-5794",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 5794,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03451846738004832,
      "grad_norm": 16.437711715698242,
      "learning_rate": 7.363657283117282e-07,
      "loss": 3.9016,
      "step": 100
    },
    {
      "epoch": 0.06903693476009665,
      "grad_norm": 4.173903465270996,
      "learning_rate": 1.5034133619697783e-06,
      "loss": 1.0256,
      "step": 200
    },
    {
      "epoch": 0.10355540214014498,
      "grad_norm": 3.090409278869629,
      "learning_rate": 2.2704609956278286e-06,
      "loss": 0.2219,
      "step": 300
    },
    {
      "epoch": 0.1380738695201933,
      "grad_norm": 2.584890365600586,
      "learning_rate": 3.0375086292858787e-06,
      "loss": 0.2021,
      "step": 400
    },
    {
      "epoch": 0.17259233690024162,
      "grad_norm": 1.8284205198287964,
      "learning_rate": 3.804556262943929e-06,
      "loss": 0.1892,
      "step": 500
    },
    {
      "epoch": 0.20711080428028997,
      "grad_norm": 2.037623167037964,
      "learning_rate": 4.57160389660198e-06,
      "loss": 0.1853,
      "step": 600
    },
    {
      "epoch": 0.2416292716603383,
      "grad_norm": 1.620039463043213,
      "learning_rate": 5.338651530260029e-06,
      "loss": 0.1867,
      "step": 700
    },
    {
      "epoch": 0.2761477390403866,
      "grad_norm": 1.670066475868225,
      "learning_rate": 6.10569916391808e-06,
      "loss": 0.1767,
      "step": 800
    },
    {
      "epoch": 0.3106662064204349,
      "grad_norm": 2.539682626724243,
      "learning_rate": 6.8727467975761295e-06,
      "loss": 0.1769,
      "step": 900
    },
    {
      "epoch": 0.34518467380048323,
      "grad_norm": 1.547996997833252,
      "learning_rate": 7.63979443123418e-06,
      "loss": 0.1746,
      "step": 1000
    },
    {
      "epoch": 0.3797031411805316,
      "grad_norm": 1.2656190395355225,
      "learning_rate": 8.40684206489223e-06,
      "loss": 0.1814,
      "step": 1100
    },
    {
      "epoch": 0.41422160856057993,
      "grad_norm": 1.8952339887619019,
      "learning_rate": 9.173889698550281e-06,
      "loss": 0.1764,
      "step": 1200
    },
    {
      "epoch": 0.44874007594062826,
      "grad_norm": 1.8723512887954712,
      "learning_rate": 9.94093733220833e-06,
      "loss": 0.1728,
      "step": 1300
    },
    {
      "epoch": 0.4832585433206766,
      "grad_norm": 3.3941519260406494,
      "learning_rate": 1.0707984965866382e-05,
      "loss": 0.1716,
      "step": 1400
    },
    {
      "epoch": 0.5177770107007249,
      "grad_norm": 1.5956722497940063,
      "learning_rate": 1.1475032599524432e-05,
      "loss": 0.1841,
      "step": 1500
    },
    {
      "epoch": 0.5522954780807732,
      "grad_norm": 1.4848670959472656,
      "learning_rate": 1.2242080233182481e-05,
      "loss": 0.1779,
      "step": 1600
    },
    {
      "epoch": 0.5868139454608216,
      "grad_norm": 1.2174705266952515,
      "learning_rate": 1.3009127866840531e-05,
      "loss": 0.1776,
      "step": 1700
    },
    {
      "epoch": 0.6213324128408698,
      "grad_norm": 1.394303321838379,
      "learning_rate": 1.377617550049858e-05,
      "loss": 0.1794,
      "step": 1800
    },
    {
      "epoch": 0.6558508802209182,
      "grad_norm": 1.6510287523269653,
      "learning_rate": 1.454322313415663e-05,
      "loss": 0.1804,
      "step": 1900
    },
    {
      "epoch": 0.6903693476009665,
      "grad_norm": 2.2874436378479004,
      "learning_rate": 1.531027076781468e-05,
      "loss": 0.1777,
      "step": 2000
    },
    {
      "epoch": 0.7248878149810148,
      "grad_norm": 1.370835781097412,
      "learning_rate": 1.607731840147273e-05,
      "loss": 0.1828,
      "step": 2100
    },
    {
      "epoch": 0.7594062823610632,
      "grad_norm": 1.8295350074768066,
      "learning_rate": 1.684436603513078e-05,
      "loss": 0.1844,
      "step": 2200
    },
    {
      "epoch": 0.7939247497411115,
      "grad_norm": 1.525498628616333,
      "learning_rate": 1.761141366878883e-05,
      "loss": 0.1861,
      "step": 2300
    },
    {
      "epoch": 0.8284432171211599,
      "grad_norm": 1.601014256477356,
      "learning_rate": 1.8378461302446883e-05,
      "loss": 0.1906,
      "step": 2400
    },
    {
      "epoch": 0.8629616845012081,
      "grad_norm": 1.4148662090301514,
      "learning_rate": 1.9145508936104933e-05,
      "loss": 0.1867,
      "step": 2500
    },
    {
      "epoch": 0.8974801518812565,
      "grad_norm": 2.565661907196045,
      "learning_rate": 1.9912556569762983e-05,
      "loss": 0.1895,
      "step": 2600
    },
    {
      "epoch": 0.9319986192613048,
      "grad_norm": 2.004685640335083,
      "learning_rate": 2.0679604203421032e-05,
      "loss": 0.1924,
      "step": 2700
    },
    {
      "epoch": 0.9665170866413532,
      "grad_norm": 1.5717511177062988,
      "learning_rate": 2.1446651837079085e-05,
      "loss": 0.1939,
      "step": 2800
    },
    {
      "epoch": 1.0010355540214015,
      "grad_norm": 1.3768088817596436,
      "learning_rate": 2.2213699470737135e-05,
      "loss": 0.1883,
      "step": 2900
    },
    {
      "epoch": 1.0355540214014498,
      "grad_norm": 1.5252751111984253,
      "learning_rate": 2.2980747104395185e-05,
      "loss": 0.1963,
      "step": 3000
    },
    {
      "epoch": 1.070072488781498,
      "grad_norm": 1.5679250955581665,
      "learning_rate": 2.3747794738053234e-05,
      "loss": 0.1912,
      "step": 3100
    },
    {
      "epoch": 1.1045909561615463,
      "grad_norm": 1.799655795097351,
      "learning_rate": 2.4514842371711287e-05,
      "loss": 0.1889,
      "step": 3200
    },
    {
      "epoch": 1.1391094235415948,
      "grad_norm": 1.458052158355713,
      "learning_rate": 2.5281890005369334e-05,
      "loss": 0.1918,
      "step": 3300
    },
    {
      "epoch": 1.173627890921643,
      "grad_norm": 1.3675026893615723,
      "learning_rate": 2.6048937639027387e-05,
      "loss": 0.1851,
      "step": 3400
    },
    {
      "epoch": 1.2081463583016914,
      "grad_norm": 1.5124677419662476,
      "learning_rate": 2.6815985272685433e-05,
      "loss": 0.1845,
      "step": 3500
    },
    {
      "epoch": 1.2426648256817396,
      "grad_norm": 1.567418098449707,
      "learning_rate": 2.7583032906343486e-05,
      "loss": 0.1837,
      "step": 3600
    },
    {
      "epoch": 1.2771832930617881,
      "grad_norm": 1.3890578746795654,
      "learning_rate": 2.8350080540001532e-05,
      "loss": 0.1792,
      "step": 3700
    },
    {
      "epoch": 1.3117017604418364,
      "grad_norm": 1.5341869592666626,
      "learning_rate": 2.9117128173659585e-05,
      "loss": 0.1775,
      "step": 3800
    },
    {
      "epoch": 1.3462202278218847,
      "grad_norm": 1.3133047819137573,
      "learning_rate": 2.988417580731764e-05,
      "loss": 0.1757,
      "step": 3900
    },
    {
      "epoch": 1.380738695201933,
      "grad_norm": 1.4311901330947876,
      "learning_rate": 3.0651223440975685e-05,
      "loss": 0.1816,
      "step": 4000
    },
    {
      "epoch": 1.4152571625819814,
      "grad_norm": 1.3311220407485962,
      "learning_rate": 3.141827107463374e-05,
      "loss": 0.174,
      "step": 4100
    },
    {
      "epoch": 1.4497756299620297,
      "grad_norm": 1.3182005882263184,
      "learning_rate": 3.2185318708291784e-05,
      "loss": 0.1733,
      "step": 4200
    },
    {
      "epoch": 1.484294097342078,
      "grad_norm": 1.3645782470703125,
      "learning_rate": 3.295236634194984e-05,
      "loss": 0.168,
      "step": 4300
    },
    {
      "epoch": 1.5188125647221264,
      "grad_norm": 1.2748032808303833,
      "learning_rate": 3.371941397560789e-05,
      "loss": 0.1749,
      "step": 4400
    },
    {
      "epoch": 1.5533310321021747,
      "grad_norm": 1.6928858757019043,
      "learning_rate": 3.4486461609265936e-05,
      "loss": 0.1714,
      "step": 4500
    },
    {
      "epoch": 1.587849499482223,
      "grad_norm": 2.1964364051818848,
      "learning_rate": 3.525350924292399e-05,
      "loss": 0.1696,
      "step": 4600
    },
    {
      "epoch": 1.6223679668622712,
      "grad_norm": 1.8937830924987793,
      "learning_rate": 3.602055687658204e-05,
      "loss": 0.1663,
      "step": 4700
    },
    {
      "epoch": 1.6568864342423195,
      "grad_norm": 1.4079968929290771,
      "learning_rate": 3.678760451024009e-05,
      "loss": 0.166,
      "step": 4800
    },
    {
      "epoch": 1.691404901622368,
      "grad_norm": 1.5763765573501587,
      "learning_rate": 3.755465214389814e-05,
      "loss": 0.1662,
      "step": 4900
    },
    {
      "epoch": 1.7259233690024163,
      "grad_norm": 1.3568507432937622,
      "learning_rate": 3.832169977755619e-05,
      "loss": 0.1681,
      "step": 5000
    },
    {
      "epoch": 1.7604418363824648,
      "grad_norm": 1.4189971685409546,
      "learning_rate": 3.908874741121424e-05,
      "loss": 0.1708,
      "step": 5100
    },
    {
      "epoch": 1.794960303762513,
      "grad_norm": 1.7245495319366455,
      "learning_rate": 3.9855795044872294e-05,
      "loss": 0.1661,
      "step": 5200
    },
    {
      "epoch": 1.8294787711425613,
      "grad_norm": 1.5281909704208374,
      "learning_rate": 4.062284267853034e-05,
      "loss": 0.1716,
      "step": 5300
    },
    {
      "epoch": 1.8639972385226096,
      "grad_norm": 1.1399623155593872,
      "learning_rate": 4.1389890312188386e-05,
      "loss": 0.1647,
      "step": 5400
    },
    {
      "epoch": 1.8985157059026578,
      "grad_norm": 1.4757425785064697,
      "learning_rate": 4.215693794584644e-05,
      "loss": 0.1721,
      "step": 5500
    },
    {
      "epoch": 1.933034173282706,
      "grad_norm": 1.9753954410552979,
      "learning_rate": 4.2923985579504486e-05,
      "loss": 0.1703,
      "step": 5600
    },
    {
      "epoch": 1.9675526406627546,
      "grad_norm": 1.2039421796798706,
      "learning_rate": 4.369103321316254e-05,
      "loss": 0.1712,
      "step": 5700
    }
  ],
  "logging_steps": 100,
  "max_steps": 86910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.872803071967232e+20,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
