{
  "best_metric": 0.6162702111120995,
  "best_model_checkpoint": "../checkpoints/finetuned-whisper-nolaugh/checkpoint-2819",
  "epoch": 8.999822663592836,
  "eval_steps": 500,
  "global_step": 25375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03546728143287817,
      "grad_norm": 3.143568992614746,
      "learning_rate": 3.4409365023057827e-06,
      "loss": 2.5146,
      "step": 100
    },
    {
      "epoch": 0.07093456286575633,
      "grad_norm": 2.930614709854126,
      "learning_rate": 6.988293721177723e-06,
      "loss": 0.2202,
      "step": 200
    },
    {
      "epoch": 0.10640184429863452,
      "grad_norm": 1.4403514862060547,
      "learning_rate": 1.0535650940049663e-05,
      "loss": 0.1959,
      "step": 300
    },
    {
      "epoch": 0.14186912573151267,
      "grad_norm": 1.4817454814910889,
      "learning_rate": 1.4083008158921605e-05,
      "loss": 0.1973,
      "step": 400
    },
    {
      "epoch": 0.17733640716439084,
      "grad_norm": 1.4488990306854248,
      "learning_rate": 1.7630365377793544e-05,
      "loss": 0.1947,
      "step": 500
    },
    {
      "epoch": 0.21280368859726903,
      "grad_norm": 1.8195348978042603,
      "learning_rate": 2.1177722596665487e-05,
      "loss": 0.2036,
      "step": 600
    },
    {
      "epoch": 0.2482709700301472,
      "grad_norm": 1.7302324771881104,
      "learning_rate": 2.4725079815537424e-05,
      "loss": 0.2064,
      "step": 700
    },
    {
      "epoch": 0.28373825146302534,
      "grad_norm": 1.789404273033142,
      "learning_rate": 2.8272437034409367e-05,
      "loss": 0.2104,
      "step": 800
    },
    {
      "epoch": 0.31920553289590353,
      "grad_norm": 1.8862218856811523,
      "learning_rate": 3.18197942532813e-05,
      "loss": 0.2126,
      "step": 900
    },
    {
      "epoch": 0.35467281432878167,
      "grad_norm": 1.526935338973999,
      "learning_rate": 3.536715147215325e-05,
      "loss": 0.2273,
      "step": 1000
    },
    {
      "epoch": 0.39014009576165987,
      "grad_norm": 1.6168129444122314,
      "learning_rate": 3.891450869102519e-05,
      "loss": 0.2339,
      "step": 1100
    },
    {
      "epoch": 0.42560737719453806,
      "grad_norm": 2.0256783962249756,
      "learning_rate": 4.246186590989713e-05,
      "loss": 0.2336,
      "step": 1200
    },
    {
      "epoch": 0.4610746586274162,
      "grad_norm": 1.722780466079712,
      "learning_rate": 4.600922312876907e-05,
      "loss": 0.241,
      "step": 1300
    },
    {
      "epoch": 0.4965419400602944,
      "grad_norm": 1.4293127059936523,
      "learning_rate": 4.955658034764101e-05,
      "loss": 0.2494,
      "step": 1400
    },
    {
      "epoch": 0.5320092214931725,
      "grad_norm": 1.5218265056610107,
      "learning_rate": 5.310393756651295e-05,
      "loss": 0.262,
      "step": 1500
    },
    {
      "epoch": 0.5674765029260507,
      "grad_norm": 1.885733723640442,
      "learning_rate": 5.665129478538489e-05,
      "loss": 0.261,
      "step": 1600
    },
    {
      "epoch": 0.6029437843589289,
      "grad_norm": 2.1644186973571777,
      "learning_rate": 6.019865200425683e-05,
      "loss": 0.2759,
      "step": 1700
    },
    {
      "epoch": 0.6384110657918071,
      "grad_norm": 1.5908972024917603,
      "learning_rate": 6.374600922312878e-05,
      "loss": 0.2746,
      "step": 1800
    },
    {
      "epoch": 0.6738783472246852,
      "grad_norm": 1.6334617137908936,
      "learning_rate": 6.729336644200072e-05,
      "loss": 0.2793,
      "step": 1900
    },
    {
      "epoch": 0.7093456286575633,
      "grad_norm": 1.601141095161438,
      "learning_rate": 7.084072366087266e-05,
      "loss": 0.291,
      "step": 2000
    },
    {
      "epoch": 0.7448129100904416,
      "grad_norm": 1.6052300930023193,
      "learning_rate": 7.438808087974459e-05,
      "loss": 0.3005,
      "step": 2100
    },
    {
      "epoch": 0.7802801915233197,
      "grad_norm": 1.6280238628387451,
      "learning_rate": 7.793543809861653e-05,
      "loss": 0.3097,
      "step": 2200
    },
    {
      "epoch": 0.8157474729561979,
      "grad_norm": 1.97129487991333,
      "learning_rate": 8.148279531748847e-05,
      "loss": 0.3209,
      "step": 2300
    },
    {
      "epoch": 0.8512147543890761,
      "grad_norm": 2.2917449474334717,
      "learning_rate": 8.503015253636042e-05,
      "loss": 0.3193,
      "step": 2400
    },
    {
      "epoch": 0.8866820358219543,
      "grad_norm": 1.933845043182373,
      "learning_rate": 8.857750975523236e-05,
      "loss": 0.334,
      "step": 2500
    },
    {
      "epoch": 0.9221493172548324,
      "grad_norm": 2.2088558673858643,
      "learning_rate": 9.21248669741043e-05,
      "loss": 0.3417,
      "step": 2600
    },
    {
      "epoch": 0.9576165986877105,
      "grad_norm": 1.750515341758728,
      "learning_rate": 9.567222419297624e-05,
      "loss": 0.3515,
      "step": 2700
    },
    {
      "epoch": 0.9930838801205888,
      "grad_norm": 1.7146934270858765,
      "learning_rate": 9.921958141184818e-05,
      "loss": 0.3476,
      "step": 2800
    },
    {
      "epoch": 1.0285511615534668,
      "grad_norm": 1.4680724143981934,
      "learning_rate": 9.969256237436444e-05,
      "loss": 0.3617,
      "step": 2900
    },
    {
      "epoch": 1.064018442986345,
      "grad_norm": 1.3870917558670044,
      "learning_rate": 9.929841157226756e-05,
      "loss": 0.3545,
      "step": 3000
    },
    {
      "epoch": 1.0994857244192233,
      "grad_norm": 1.3161791563034058,
      "learning_rate": 9.890426077017068e-05,
      "loss": 0.3538,
      "step": 3100
    },
    {
      "epoch": 1.1349530058521013,
      "grad_norm": 1.5401347875595093,
      "learning_rate": 9.85101099680738e-05,
      "loss": 0.352,
      "step": 3200
    },
    {
      "epoch": 1.1704202872849796,
      "grad_norm": 1.9718387126922607,
      "learning_rate": 9.811595916597691e-05,
      "loss": 0.3415,
      "step": 3300
    },
    {
      "epoch": 1.2058875687178578,
      "grad_norm": 1.4147064685821533,
      "learning_rate": 9.772180836388003e-05,
      "loss": 0.3384,
      "step": 3400
    },
    {
      "epoch": 1.2413548501507359,
      "grad_norm": 1.3064278364181519,
      "learning_rate": 9.732765756178315e-05,
      "loss": 0.3359,
      "step": 3500
    },
    {
      "epoch": 1.2768221315836141,
      "grad_norm": 1.5693364143371582,
      "learning_rate": 9.693350675968627e-05,
      "loss": 0.3125,
      "step": 3600
    },
    {
      "epoch": 1.3122894130164924,
      "grad_norm": 1.900887131690979,
      "learning_rate": 9.653935595758938e-05,
      "loss": 0.3168,
      "step": 3700
    },
    {
      "epoch": 1.3477566944493704,
      "grad_norm": 1.3285186290740967,
      "learning_rate": 9.61452051554925e-05,
      "loss": 0.314,
      "step": 3800
    },
    {
      "epoch": 1.3832239758822487,
      "grad_norm": 2.0699172019958496,
      "learning_rate": 9.57510543533956e-05,
      "loss": 0.3151,
      "step": 3900
    },
    {
      "epoch": 1.418691257315127,
      "grad_norm": 1.7377456426620483,
      "learning_rate": 9.535690355129872e-05,
      "loss": 0.306,
      "step": 4000
    },
    {
      "epoch": 1.454158538748005,
      "grad_norm": 5.174080848693848,
      "learning_rate": 9.496275274920184e-05,
      "loss": 0.301,
      "step": 4100
    },
    {
      "epoch": 1.4896258201808832,
      "grad_norm": 1.3850644826889038,
      "learning_rate": 9.456860194710496e-05,
      "loss": 0.2935,
      "step": 4200
    },
    {
      "epoch": 1.5250931016137614,
      "grad_norm": 1.5402745008468628,
      "learning_rate": 9.417445114500808e-05,
      "loss": 0.2959,
      "step": 4300
    },
    {
      "epoch": 1.5605603830466395,
      "grad_norm": 1.5799920558929443,
      "learning_rate": 9.37803003429112e-05,
      "loss": 0.2822,
      "step": 4400
    },
    {
      "epoch": 1.5960276644795175,
      "grad_norm": 1.542230486869812,
      "learning_rate": 9.338614954081432e-05,
      "loss": 0.2799,
      "step": 4500
    },
    {
      "epoch": 1.631494945912396,
      "grad_norm": 1.402195692062378,
      "learning_rate": 9.299199873871744e-05,
      "loss": 0.2733,
      "step": 4600
    },
    {
      "epoch": 1.666962227345274,
      "grad_norm": 1.6633856296539307,
      "learning_rate": 9.259784793662056e-05,
      "loss": 0.261,
      "step": 4700
    },
    {
      "epoch": 1.702429508778152,
      "grad_norm": 1.2455930709838867,
      "learning_rate": 9.220369713452368e-05,
      "loss": 0.2569,
      "step": 4800
    },
    {
      "epoch": 1.7378967902110303,
      "grad_norm": 1.3283122777938843,
      "learning_rate": 9.180954633242678e-05,
      "loss": 0.2599,
      "step": 4900
    },
    {
      "epoch": 1.7733640716439085,
      "grad_norm": 1.324419617652893,
      "learning_rate": 9.141933703835088e-05,
      "loss": 0.2516,
      "step": 5000
    },
    {
      "epoch": 1.8088313530767866,
      "grad_norm": 1.4645978212356567,
      "learning_rate": 9.102518623625399e-05,
      "loss": 0.2538,
      "step": 5100
    },
    {
      "epoch": 1.8442986345096648,
      "grad_norm": 1.5619431734085083,
      "learning_rate": 9.063103543415711e-05,
      "loss": 0.2542,
      "step": 5200
    },
    {
      "epoch": 1.879765915942543,
      "grad_norm": 1.0927850008010864,
      "learning_rate": 9.023688463206023e-05,
      "loss": 0.2429,
      "step": 5300
    },
    {
      "epoch": 1.915233197375421,
      "grad_norm": 1.5148464441299438,
      "learning_rate": 8.984273382996335e-05,
      "loss": 0.2482,
      "step": 5400
    },
    {
      "epoch": 1.9507004788082993,
      "grad_norm": 1.1081364154815674,
      "learning_rate": 8.944858302786647e-05,
      "loss": 0.2392,
      "step": 5500
    },
    {
      "epoch": 1.9861677602411776,
      "grad_norm": 1.274762749671936,
      "learning_rate": 8.905443222576958e-05,
      "loss": 0.2315,
      "step": 5600
    },
    {
      "epoch": 2.0216350416740556,
      "grad_norm": 1.2032933235168457,
      "learning_rate": 8.86602814236727e-05,
      "loss": 0.236,
      "step": 5700
    },
    {
      "epoch": 2.0571023231069336,
      "grad_norm": 1.2775813341140747,
      "learning_rate": 8.826613062157581e-05,
      "loss": 0.2324,
      "step": 5800
    },
    {
      "epoch": 2.092569604539812,
      "grad_norm": 1.2671445608139038,
      "learning_rate": 8.787197981947893e-05,
      "loss": 0.2251,
      "step": 5900
    },
    {
      "epoch": 2.12803688597269,
      "grad_norm": 1.8423694372177124,
      "learning_rate": 8.747782901738205e-05,
      "loss": 0.2253,
      "step": 6000
    },
    {
      "epoch": 2.163504167405568,
      "grad_norm": 0.9323269724845886,
      "learning_rate": 8.708367821528517e-05,
      "loss": 0.2179,
      "step": 6100
    },
    {
      "epoch": 2.1989714488384466,
      "grad_norm": 1.98787522315979,
      "learning_rate": 8.668952741318829e-05,
      "loss": 0.2178,
      "step": 6200
    },
    {
      "epoch": 2.2344387302713247,
      "grad_norm": 1.3227765560150146,
      "learning_rate": 8.62953766110914e-05,
      "loss": 0.216,
      "step": 6300
    },
    {
      "epoch": 2.2699060117042027,
      "grad_norm": 1.1122632026672363,
      "learning_rate": 8.590122580899453e-05,
      "loss": 0.2036,
      "step": 6400
    },
    {
      "epoch": 2.305373293137081,
      "grad_norm": 1.395487904548645,
      "learning_rate": 8.550707500689764e-05,
      "loss": 0.202,
      "step": 6500
    },
    {
      "epoch": 2.340840574569959,
      "grad_norm": 0.9901321530342102,
      "learning_rate": 8.511292420480076e-05,
      "loss": 0.2038,
      "step": 6600
    },
    {
      "epoch": 2.3763078560028372,
      "grad_norm": 2.893563985824585,
      "learning_rate": 8.471877340270388e-05,
      "loss": 0.2091,
      "step": 6700
    },
    {
      "epoch": 2.4117751374357157,
      "grad_norm": 1.6493948698043823,
      "learning_rate": 8.432462260060699e-05,
      "loss": 0.2027,
      "step": 6800
    },
    {
      "epoch": 2.4472424188685937,
      "grad_norm": 1.8093247413635254,
      "learning_rate": 8.393047179851011e-05,
      "loss": 0.1981,
      "step": 6900
    },
    {
      "epoch": 2.4827097003014718,
      "grad_norm": 1.8829667568206787,
      "learning_rate": 8.353632099641323e-05,
      "loss": 0.1889,
      "step": 7000
    },
    {
      "epoch": 2.5181769817343502,
      "grad_norm": 1.436166524887085,
      "learning_rate": 8.314217019431635e-05,
      "loss": 0.1933,
      "step": 7100
    },
    {
      "epoch": 2.5536442631672283,
      "grad_norm": 1.3279972076416016,
      "learning_rate": 8.274801939221947e-05,
      "loss": 0.1891,
      "step": 7200
    },
    {
      "epoch": 2.5891115446001063,
      "grad_norm": 3.649263381958008,
      "learning_rate": 8.236963462220645e-05,
      "loss": 2.1867,
      "step": 7300
    },
    {
      "epoch": 2.6245788260329848,
      "grad_norm": 3.007314682006836,
      "learning_rate": 8.197548382010957e-05,
      "loss": 5.1712,
      "step": 7400
    },
    {
      "epoch": 2.660046107465863,
      "grad_norm": 1.2083734273910522,
      "learning_rate": 8.158133301801269e-05,
      "loss": 0.9894,
      "step": 7500
    },
    {
      "epoch": 2.695513388898741,
      "grad_norm": 2.380851984024048,
      "learning_rate": 8.118718221591581e-05,
      "loss": 0.1817,
      "step": 7600
    },
    {
      "epoch": 2.7309806703316193,
      "grad_norm": 1.1511476039886475,
      "learning_rate": 8.079303141381893e-05,
      "loss": 0.2221,
      "step": 7700
    },
    {
      "epoch": 2.7664479517644973,
      "grad_norm": 0.9691649675369263,
      "learning_rate": 8.039888061172205e-05,
      "loss": 0.1719,
      "step": 7800
    },
    {
      "epoch": 2.8019152331973753,
      "grad_norm": 1.1815775632858276,
      "learning_rate": 8.000472980962517e-05,
      "loss": 0.1724,
      "step": 7900
    },
    {
      "epoch": 2.837382514630254,
      "grad_norm": 1.3838295936584473,
      "learning_rate": 7.961057900752829e-05,
      "loss": 0.1721,
      "step": 8000
    },
    {
      "epoch": 2.872849796063132,
      "grad_norm": 1.1042505502700806,
      "learning_rate": 7.921642820543141e-05,
      "loss": 0.1647,
      "step": 8100
    },
    {
      "epoch": 2.90831707749601,
      "grad_norm": 1.0804026126861572,
      "learning_rate": 7.882227740333453e-05,
      "loss": 0.1609,
      "step": 8200
    },
    {
      "epoch": 2.9437843589288883,
      "grad_norm": 1.0397034883499146,
      "learning_rate": 7.842812660123763e-05,
      "loss": 0.16,
      "step": 8300
    },
    {
      "epoch": 2.9792516403617664,
      "grad_norm": 0.9974684715270996,
      "learning_rate": 7.803397579914075e-05,
      "loss": 0.1517,
      "step": 8400
    },
    {
      "epoch": 3.0147189217946444,
      "grad_norm": 1.2509320974349976,
      "learning_rate": 7.763982499704387e-05,
      "loss": 0.1535,
      "step": 8500
    },
    {
      "epoch": 3.0501862032275224,
      "grad_norm": 0.8146088719367981,
      "learning_rate": 7.724567419494699e-05,
      "loss": 0.1536,
      "step": 8600
    },
    {
      "epoch": 3.085653484660401,
      "grad_norm": 0.945932149887085,
      "learning_rate": 7.685152339285011e-05,
      "loss": 0.145,
      "step": 8700
    },
    {
      "epoch": 3.121120766093279,
      "grad_norm": 1.0640647411346436,
      "learning_rate": 7.645737259075323e-05,
      "loss": 0.1463,
      "step": 8800
    },
    {
      "epoch": 3.156588047526157,
      "grad_norm": 1.0441445112228394,
      "learning_rate": 7.606322178865635e-05,
      "loss": 0.1451,
      "step": 8900
    },
    {
      "epoch": 3.1920553289590354,
      "grad_norm": 1.5703774690628052,
      "learning_rate": 7.566907098655947e-05,
      "loss": 0.1417,
      "step": 9000
    },
    {
      "epoch": 3.2275226103919135,
      "grad_norm": 1.021820068359375,
      "learning_rate": 7.527492018446259e-05,
      "loss": 0.1379,
      "step": 9100
    },
    {
      "epoch": 3.2629898918247915,
      "grad_norm": 1.1167643070220947,
      "learning_rate": 7.488076938236571e-05,
      "loss": 0.1376,
      "step": 9200
    },
    {
      "epoch": 3.29845717325767,
      "grad_norm": 0.8727354407310486,
      "learning_rate": 7.448661858026881e-05,
      "loss": 0.1324,
      "step": 9300
    },
    {
      "epoch": 3.333924454690548,
      "grad_norm": 1.0217256546020508,
      "learning_rate": 7.409246777817193e-05,
      "loss": 0.1309,
      "step": 9400
    },
    {
      "epoch": 3.369391736123426,
      "grad_norm": 1.1462154388427734,
      "learning_rate": 7.369831697607505e-05,
      "loss": 0.1313,
      "step": 9500
    },
    {
      "epoch": 3.4048590175563045,
      "grad_norm": 1.489815592765808,
      "learning_rate": 7.330416617397817e-05,
      "loss": 0.1328,
      "step": 9600
    },
    {
      "epoch": 3.4403262989891825,
      "grad_norm": 1.2433613538742065,
      "learning_rate": 7.291001537188129e-05,
      "loss": 0.1318,
      "step": 9700
    },
    {
      "epoch": 3.4757935804220605,
      "grad_norm": 0.7672411799430847,
      "learning_rate": 7.25158645697844e-05,
      "loss": 0.128,
      "step": 9800
    },
    {
      "epoch": 3.5112608618549386,
      "grad_norm": 1.199633002281189,
      "learning_rate": 7.212171376768752e-05,
      "loss": 0.1266,
      "step": 9900
    },
    {
      "epoch": 3.546728143287817,
      "grad_norm": 1.375311017036438,
      "learning_rate": 7.172756296559063e-05,
      "loss": 0.1218,
      "step": 10000
    },
    {
      "epoch": 3.582195424720695,
      "grad_norm": 1.2330199480056763,
      "learning_rate": 7.133341216349375e-05,
      "loss": 0.134,
      "step": 10100
    },
    {
      "epoch": 3.617662706153573,
      "grad_norm": 0.9538618922233582,
      "learning_rate": 7.093926136139687e-05,
      "loss": 0.1915,
      "step": 10200
    },
    {
      "epoch": 3.6531299875864516,
      "grad_norm": 1.4339182376861572,
      "learning_rate": 7.054511055929999e-05,
      "loss": 0.1485,
      "step": 10300
    },
    {
      "epoch": 3.6885972690193296,
      "grad_norm": 0.9309330582618713,
      "learning_rate": 7.015095975720311e-05,
      "loss": 0.1172,
      "step": 10400
    },
    {
      "epoch": 3.7240645504522076,
      "grad_norm": 1.152207374572754,
      "learning_rate": 6.975680895510622e-05,
      "loss": 0.1136,
      "step": 10500
    },
    {
      "epoch": 3.759531831885086,
      "grad_norm": 0.7768313884735107,
      "learning_rate": 6.936265815300934e-05,
      "loss": 0.1174,
      "step": 10600
    },
    {
      "epoch": 3.794999113317964,
      "grad_norm": 0.8490020632743835,
      "learning_rate": 6.896850735091246e-05,
      "loss": 0.1136,
      "step": 10700
    },
    {
      "epoch": 3.830466394750842,
      "grad_norm": 0.8158101439476013,
      "learning_rate": 6.857435654881558e-05,
      "loss": 0.111,
      "step": 10800
    },
    {
      "epoch": 3.8659336761837206,
      "grad_norm": 1.0024465322494507,
      "learning_rate": 6.81802057467187e-05,
      "loss": 0.1045,
      "step": 10900
    },
    {
      "epoch": 3.9014009576165987,
      "grad_norm": 1.0691404342651367,
      "learning_rate": 6.778605494462181e-05,
      "loss": 0.1069,
      "step": 11000
    },
    {
      "epoch": 3.9368682390494767,
      "grad_norm": 1.0550698041915894,
      "learning_rate": 6.739190414252493e-05,
      "loss": 0.1047,
      "step": 11100
    },
    {
      "epoch": 3.972335520482355,
      "grad_norm": 1.0565369129180908,
      "learning_rate": 6.699775334042805e-05,
      "loss": 0.0987,
      "step": 11200
    },
    {
      "epoch": 4.007802801915234,
      "grad_norm": 1.0322023630142212,
      "learning_rate": 6.660360253833117e-05,
      "loss": 0.0966,
      "step": 11300
    },
    {
      "epoch": 4.043270083348111,
      "grad_norm": 1.0951178073883057,
      "learning_rate": 6.620945173623429e-05,
      "loss": 0.0989,
      "step": 11400
    },
    {
      "epoch": 4.07873736478099,
      "grad_norm": 0.9056419134140015,
      "learning_rate": 6.58153009341374e-05,
      "loss": 0.0938,
      "step": 11500
    },
    {
      "epoch": 4.114204646213867,
      "grad_norm": 1.2160176038742065,
      "learning_rate": 6.542115013204052e-05,
      "loss": 0.0914,
      "step": 11600
    },
    {
      "epoch": 4.149671927646746,
      "grad_norm": 0.7444105744361877,
      "learning_rate": 6.502699932994364e-05,
      "loss": 0.0945,
      "step": 11700
    },
    {
      "epoch": 4.185139209079624,
      "grad_norm": 0.664659857749939,
      "learning_rate": 6.463284852784676e-05,
      "loss": 0.0885,
      "step": 11800
    },
    {
      "epoch": 4.220606490512502,
      "grad_norm": 0.7266243100166321,
      "learning_rate": 6.423869772574987e-05,
      "loss": 0.0902,
      "step": 11900
    },
    {
      "epoch": 4.25607377194538,
      "grad_norm": 0.8973394632339478,
      "learning_rate": 6.3844546923653e-05,
      "loss": 0.0875,
      "step": 12000
    },
    {
      "epoch": 4.291541053378259,
      "grad_norm": 0.7936742305755615,
      "learning_rate": 6.345039612155611e-05,
      "loss": 0.0859,
      "step": 12100
    },
    {
      "epoch": 4.327008334811136,
      "grad_norm": 0.9003823399543762,
      "learning_rate": 6.305624531945923e-05,
      "loss": 0.084,
      "step": 12200
    },
    {
      "epoch": 4.362475616244015,
      "grad_norm": 0.7744758129119873,
      "learning_rate": 6.266209451736235e-05,
      "loss": 0.0846,
      "step": 12300
    },
    {
      "epoch": 4.397942897676893,
      "grad_norm": 0.6145954728126526,
      "learning_rate": 6.226794371526546e-05,
      "loss": 0.0854,
      "step": 12400
    },
    {
      "epoch": 4.433410179109771,
      "grad_norm": 0.5713800191879272,
      "learning_rate": 6.187379291316858e-05,
      "loss": 0.0845,
      "step": 12500
    },
    {
      "epoch": 4.468877460542649,
      "grad_norm": 0.6851378679275513,
      "learning_rate": 6.14796421110717e-05,
      "loss": 0.083,
      "step": 12600
    },
    {
      "epoch": 4.504344741975528,
      "grad_norm": 1.2927122116088867,
      "learning_rate": 6.108549130897482e-05,
      "loss": 0.0826,
      "step": 12700
    },
    {
      "epoch": 4.539812023408405,
      "grad_norm": 0.8549216389656067,
      "learning_rate": 6.0691340506877935e-05,
      "loss": 0.081,
      "step": 12800
    },
    {
      "epoch": 4.575279304841284,
      "grad_norm": 0.9967914819717407,
      "learning_rate": 6.0297189704781054e-05,
      "loss": 0.0769,
      "step": 12900
    },
    {
      "epoch": 4.610746586274162,
      "grad_norm": 1.4801990985870361,
      "learning_rate": 5.9903038902684174e-05,
      "loss": 0.1067,
      "step": 13000
    },
    {
      "epoch": 4.64621386770704,
      "grad_norm": 0.8965036869049072,
      "learning_rate": 5.950888810058729e-05,
      "loss": 0.0952,
      "step": 13100
    },
    {
      "epoch": 4.681681149139918,
      "grad_norm": 1.0600943565368652,
      "learning_rate": 5.9114737298490405e-05,
      "loss": 0.0704,
      "step": 13200
    },
    {
      "epoch": 4.717148430572797,
      "grad_norm": 1.3268001079559326,
      "learning_rate": 5.8720586496393525e-05,
      "loss": 0.0742,
      "step": 13300
    },
    {
      "epoch": 4.7526157120056745,
      "grad_norm": 0.9057412147521973,
      "learning_rate": 5.8326435694296644e-05,
      "loss": 0.0738,
      "step": 13400
    },
    {
      "epoch": 4.788082993438553,
      "grad_norm": 0.9528725743293762,
      "learning_rate": 5.793228489219976e-05,
      "loss": 0.0751,
      "step": 13500
    },
    {
      "epoch": 4.823550274871431,
      "grad_norm": 1.0746736526489258,
      "learning_rate": 5.753813409010288e-05,
      "loss": 0.0727,
      "step": 13600
    },
    {
      "epoch": 4.859017556304309,
      "grad_norm": 0.723883867263794,
      "learning_rate": 5.7143983288005995e-05,
      "loss": 0.0681,
      "step": 13700
    },
    {
      "epoch": 4.8944848377371875,
      "grad_norm": 0.8420592546463013,
      "learning_rate": 5.6749832485909115e-05,
      "loss": 0.0668,
      "step": 13800
    },
    {
      "epoch": 4.929952119170066,
      "grad_norm": 0.7821084260940552,
      "learning_rate": 5.6355681683812234e-05,
      "loss": 0.067,
      "step": 13900
    },
    {
      "epoch": 4.9654194006029435,
      "grad_norm": 1.1916245222091675,
      "learning_rate": 5.596153088171535e-05,
      "loss": 0.0633,
      "step": 14000
    },
    {
      "epoch": 5.000886682035822,
      "grad_norm": 0.5859767198562622,
      "learning_rate": 5.556738007961847e-05,
      "loss": 0.0607,
      "step": 14100
    },
    {
      "epoch": 5.0363539634687005,
      "grad_norm": 1.0115450620651245,
      "learning_rate": 5.5173229277521585e-05,
      "loss": 0.0659,
      "step": 14200
    },
    {
      "epoch": 5.071821244901578,
      "grad_norm": 0.7259140610694885,
      "learning_rate": 5.4779078475424704e-05,
      "loss": 0.0603,
      "step": 14300
    },
    {
      "epoch": 5.1072885263344565,
      "grad_norm": 0.8058640360832214,
      "learning_rate": 5.438492767332781e-05,
      "loss": 0.0595,
      "step": 14400
    },
    {
      "epoch": 5.142755807767335,
      "grad_norm": 0.8231360912322998,
      "learning_rate": 5.399077687123093e-05,
      "loss": 0.0595,
      "step": 14500
    },
    {
      "epoch": 5.178223089200213,
      "grad_norm": 1.2854044437408447,
      "learning_rate": 5.359662606913405e-05,
      "loss": 0.0565,
      "step": 14600
    },
    {
      "epoch": 5.213690370633091,
      "grad_norm": 1.027238130569458,
      "learning_rate": 5.320247526703717e-05,
      "loss": 0.0619,
      "step": 14700
    },
    {
      "epoch": 5.2491576520659695,
      "grad_norm": 0.6712852716445923,
      "learning_rate": 5.280832446494029e-05,
      "loss": 0.0563,
      "step": 14800
    },
    {
      "epoch": 5.284624933498847,
      "grad_norm": 0.8273834586143494,
      "learning_rate": 5.24141736628434e-05,
      "loss": 0.0549,
      "step": 14900
    },
    {
      "epoch": 5.320092214931726,
      "grad_norm": 0.8139856457710266,
      "learning_rate": 5.202002286074652e-05,
      "loss": 0.0546,
      "step": 15000
    },
    {
      "epoch": 5.355559496364604,
      "grad_norm": 0.4247060716152191,
      "learning_rate": 5.162587205864964e-05,
      "loss": 0.0533,
      "step": 15100
    },
    {
      "epoch": 5.391026777797482,
      "grad_norm": 0.5742018818855286,
      "learning_rate": 5.123172125655276e-05,
      "loss": 0.0536,
      "step": 15200
    },
    {
      "epoch": 5.42649405923036,
      "grad_norm": 0.7311269640922546,
      "learning_rate": 5.083757045445588e-05,
      "loss": 0.0563,
      "step": 15300
    },
    {
      "epoch": 5.461961340663239,
      "grad_norm": 0.612815260887146,
      "learning_rate": 5.044341965235899e-05,
      "loss": 0.0513,
      "step": 15400
    },
    {
      "epoch": 5.497428622096116,
      "grad_norm": 0.7305078506469727,
      "learning_rate": 5.004926885026211e-05,
      "loss": 0.0517,
      "step": 15500
    },
    {
      "epoch": 5.532895903528995,
      "grad_norm": 0.7321407198905945,
      "learning_rate": 4.965511804816523e-05,
      "loss": 0.0505,
      "step": 15600
    },
    {
      "epoch": 5.568363184961873,
      "grad_norm": 0.5164580345153809,
      "learning_rate": 4.926096724606835e-05,
      "loss": 0.049,
      "step": 15700
    },
    {
      "epoch": 5.603830466394751,
      "grad_norm": 0.8281322717666626,
      "learning_rate": 4.886681644397147e-05,
      "loss": 0.0607,
      "step": 15800
    },
    {
      "epoch": 5.639297747827629,
      "grad_norm": 0.635249674320221,
      "learning_rate": 4.847266564187458e-05,
      "loss": 0.0574,
      "step": 15900
    },
    {
      "epoch": 5.674765029260508,
      "grad_norm": 0.765359103679657,
      "learning_rate": 4.80785148397777e-05,
      "loss": 0.0454,
      "step": 16000
    },
    {
      "epoch": 5.710232310693385,
      "grad_norm": 1.026167392730713,
      "learning_rate": 4.768436403768082e-05,
      "loss": 0.0465,
      "step": 16100
    },
    {
      "epoch": 5.745699592126264,
      "grad_norm": 0.675180971622467,
      "learning_rate": 4.729021323558394e-05,
      "loss": 0.0465,
      "step": 16200
    },
    {
      "epoch": 5.781166873559142,
      "grad_norm": 0.766716480255127,
      "learning_rate": 4.689606243348706e-05,
      "loss": 0.0465,
      "step": 16300
    },
    {
      "epoch": 5.81663415499202,
      "grad_norm": 0.5470580458641052,
      "learning_rate": 4.650191163139017e-05,
      "loss": 0.046,
      "step": 16400
    },
    {
      "epoch": 5.852101436424898,
      "grad_norm": 0.4967406988143921,
      "learning_rate": 4.610776082929329e-05,
      "loss": 0.0424,
      "step": 16500
    },
    {
      "epoch": 5.887568717857777,
      "grad_norm": 0.4861298203468323,
      "learning_rate": 4.571361002719641e-05,
      "loss": 0.0425,
      "step": 16600
    },
    {
      "epoch": 5.923035999290654,
      "grad_norm": 0.7342727780342102,
      "learning_rate": 4.531945922509953e-05,
      "loss": 0.0429,
      "step": 16700
    },
    {
      "epoch": 5.958503280723533,
      "grad_norm": 0.8155454397201538,
      "learning_rate": 4.492530842300265e-05,
      "loss": 0.0423,
      "step": 16800
    },
    {
      "epoch": 5.99397056215641,
      "grad_norm": 1.084876298904419,
      "learning_rate": 4.453115762090576e-05,
      "loss": 0.0384,
      "step": 16900
    },
    {
      "epoch": 6.029437843589289,
      "grad_norm": 0.9557426571846008,
      "learning_rate": 4.413700681880888e-05,
      "loss": 0.0399,
      "step": 17000
    },
    {
      "epoch": 6.064905125022167,
      "grad_norm": 0.7004719972610474,
      "learning_rate": 4.3742856016712e-05,
      "loss": 0.0385,
      "step": 17100
    },
    {
      "epoch": 6.100372406455045,
      "grad_norm": 0.5913845896720886,
      "learning_rate": 4.334870521461512e-05,
      "loss": 0.0367,
      "step": 17200
    },
    {
      "epoch": 6.135839687887923,
      "grad_norm": 0.671954870223999,
      "learning_rate": 4.295455441251823e-05,
      "loss": 0.0378,
      "step": 17300
    },
    {
      "epoch": 6.171306969320802,
      "grad_norm": 0.6883506774902344,
      "learning_rate": 4.256040361042135e-05,
      "loss": 0.0341,
      "step": 17400
    },
    {
      "epoch": 6.206774250753679,
      "grad_norm": 0.47083839774131775,
      "learning_rate": 4.216625280832447e-05,
      "loss": 0.0361,
      "step": 17500
    },
    {
      "epoch": 6.242241532186558,
      "grad_norm": 0.5986472964286804,
      "learning_rate": 4.177210200622759e-05,
      "loss": 0.0349,
      "step": 17600
    },
    {
      "epoch": 6.277708813619436,
      "grad_norm": 0.6889644861221313,
      "learning_rate": 4.137795120413071e-05,
      "loss": 0.0372,
      "step": 17700
    },
    {
      "epoch": 6.313176095052314,
      "grad_norm": 0.7968912124633789,
      "learning_rate": 4.098380040203382e-05,
      "loss": 0.0359,
      "step": 17800
    },
    {
      "epoch": 6.348643376485192,
      "grad_norm": 0.8126854300498962,
      "learning_rate": 4.058964959993693e-05,
      "loss": 0.0329,
      "step": 17900
    },
    {
      "epoch": 6.384110657918071,
      "grad_norm": 0.4617670178413391,
      "learning_rate": 4.019549879784005e-05,
      "loss": 0.0338,
      "step": 18000
    },
    {
      "epoch": 6.4195779393509484,
      "grad_norm": 0.38961589336395264,
      "learning_rate": 3.980134799574317e-05,
      "loss": 0.0332,
      "step": 18100
    },
    {
      "epoch": 6.455045220783827,
      "grad_norm": 1.6537158489227295,
      "learning_rate": 3.940719719364629e-05,
      "loss": 0.0326,
      "step": 18200
    },
    {
      "epoch": 6.490512502216705,
      "grad_norm": 0.43897050619125366,
      "learning_rate": 3.901304639154941e-05,
      "loss": 0.0333,
      "step": 18300
    },
    {
      "epoch": 6.525979783649583,
      "grad_norm": 0.5221980810165405,
      "learning_rate": 3.861889558945252e-05,
      "loss": 0.0322,
      "step": 18400
    },
    {
      "epoch": 6.5614470650824614,
      "grad_norm": 0.7342471480369568,
      "learning_rate": 3.822474478735564e-05,
      "loss": 0.0312,
      "step": 18500
    },
    {
      "epoch": 6.59691434651534,
      "grad_norm": 0.532427191734314,
      "learning_rate": 3.783059398525876e-05,
      "loss": 0.0344,
      "step": 18600
    },
    {
      "epoch": 6.6323816279482175,
      "grad_norm": 0.7682348489761353,
      "learning_rate": 3.743644318316188e-05,
      "loss": 0.037,
      "step": 18700
    },
    {
      "epoch": 6.667848909381096,
      "grad_norm": 0.40430665016174316,
      "learning_rate": 3.7042292381065e-05,
      "loss": 0.0292,
      "step": 18800
    },
    {
      "epoch": 6.7033161908139745,
      "grad_norm": 0.6487621068954468,
      "learning_rate": 3.664814157896811e-05,
      "loss": 0.0267,
      "step": 18900
    },
    {
      "epoch": 6.738783472246852,
      "grad_norm": 0.627409815788269,
      "learning_rate": 3.625399077687123e-05,
      "loss": 0.0297,
      "step": 19000
    },
    {
      "epoch": 6.7742507536797305,
      "grad_norm": 0.6303462982177734,
      "learning_rate": 3.585983997477435e-05,
      "loss": 0.0293,
      "step": 19100
    },
    {
      "epoch": 6.809718035112609,
      "grad_norm": 0.6835033893585205,
      "learning_rate": 3.546568917267747e-05,
      "loss": 0.027,
      "step": 19200
    },
    {
      "epoch": 6.845185316545487,
      "grad_norm": 0.4788939952850342,
      "learning_rate": 3.507153837058059e-05,
      "loss": 0.0279,
      "step": 19300
    },
    {
      "epoch": 6.880652597978365,
      "grad_norm": 0.6817094683647156,
      "learning_rate": 3.46773875684837e-05,
      "loss": 0.0261,
      "step": 19400
    },
    {
      "epoch": 6.9161198794112435,
      "grad_norm": 1.083030104637146,
      "learning_rate": 3.428323676638682e-05,
      "loss": 0.0261,
      "step": 19500
    },
    {
      "epoch": 6.951587160844121,
      "grad_norm": 0.909723699092865,
      "learning_rate": 3.388908596428994e-05,
      "loss": 0.0267,
      "step": 19600
    },
    {
      "epoch": 6.987054442277,
      "grad_norm": 0.4328685998916626,
      "learning_rate": 3.349493516219306e-05,
      "loss": 0.0245,
      "step": 19700
    },
    {
      "epoch": 7.022521723709878,
      "grad_norm": 0.48386290669441223,
      "learning_rate": 3.310078436009618e-05,
      "loss": 0.0252,
      "step": 19800
    },
    {
      "epoch": 7.057989005142756,
      "grad_norm": 1.4884607791900635,
      "learning_rate": 3.270663355799929e-05,
      "loss": 0.0225,
      "step": 19900
    },
    {
      "epoch": 7.093456286575634,
      "grad_norm": 0.6050064563751221,
      "learning_rate": 3.231248275590241e-05,
      "loss": 0.0235,
      "step": 20000
    },
    {
      "epoch": 7.128923568008513,
      "grad_norm": 0.4948764741420746,
      "learning_rate": 3.191833195380552e-05,
      "loss": 0.0221,
      "step": 20100
    },
    {
      "epoch": 7.16439084944139,
      "grad_norm": 0.6334826946258545,
      "learning_rate": 3.152418115170864e-05,
      "loss": 0.0204,
      "step": 20200
    },
    {
      "epoch": 7.199858130874269,
      "grad_norm": 0.23784297704696655,
      "learning_rate": 3.113003034961176e-05,
      "loss": 0.0221,
      "step": 20300
    },
    {
      "epoch": 7.235325412307146,
      "grad_norm": 0.43556538224220276,
      "learning_rate": 3.073587954751488e-05,
      "loss": 0.0215,
      "step": 20400
    },
    {
      "epoch": 7.270792693740025,
      "grad_norm": 0.5606489777565002,
      "learning_rate": 3.0341728745417997e-05,
      "loss": 0.0214,
      "step": 20500
    },
    {
      "epoch": 7.306259975172903,
      "grad_norm": 0.5822690725326538,
      "learning_rate": 2.9947577943321113e-05,
      "loss": 0.0223,
      "step": 20600
    },
    {
      "epoch": 7.341727256605781,
      "grad_norm": 0.5691213011741638,
      "learning_rate": 2.9553427141224232e-05,
      "loss": 0.0207,
      "step": 20700
    },
    {
      "epoch": 7.377194538038659,
      "grad_norm": 3.1134235858917236,
      "learning_rate": 2.9159276339127352e-05,
      "loss": 0.0211,
      "step": 20800
    },
    {
      "epoch": 7.412661819471538,
      "grad_norm": 0.5199248790740967,
      "learning_rate": 2.8765125537030468e-05,
      "loss": 0.0201,
      "step": 20900
    },
    {
      "epoch": 7.448129100904415,
      "grad_norm": 0.5437541007995605,
      "learning_rate": 2.8370974734933587e-05,
      "loss": 0.0223,
      "step": 21000
    },
    {
      "epoch": 7.483596382337294,
      "grad_norm": 0.3254770338535309,
      "learning_rate": 2.7976823932836703e-05,
      "loss": 0.0195,
      "step": 21100
    },
    {
      "epoch": 7.519063663770172,
      "grad_norm": 0.6272336840629578,
      "learning_rate": 2.7582673130739822e-05,
      "loss": 0.0188,
      "step": 21200
    },
    {
      "epoch": 7.55453094520305,
      "grad_norm": 0.4734961688518524,
      "learning_rate": 2.718852232864294e-05,
      "loss": 0.0191,
      "step": 21300
    },
    {
      "epoch": 7.589998226635928,
      "grad_norm": 0.3409107029438019,
      "learning_rate": 2.6794371526546057e-05,
      "loss": 0.0192,
      "step": 21400
    },
    {
      "epoch": 7.625465508068807,
      "grad_norm": 0.7333162426948547,
      "learning_rate": 2.6404162232470144e-05,
      "loss": 0.0207,
      "step": 21500
    },
    {
      "epoch": 7.660932789501684,
      "grad_norm": 0.6080375909805298,
      "learning_rate": 2.601001143037326e-05,
      "loss": 0.0184,
      "step": 21600
    },
    {
      "epoch": 7.696400070934563,
      "grad_norm": 0.5674252510070801,
      "learning_rate": 2.561586062827638e-05,
      "loss": 0.0157,
      "step": 21700
    },
    {
      "epoch": 7.731867352367441,
      "grad_norm": 0.5676995515823364,
      "learning_rate": 2.5221709826179495e-05,
      "loss": 0.0165,
      "step": 21800
    },
    {
      "epoch": 7.767334633800319,
      "grad_norm": 0.483508825302124,
      "learning_rate": 2.4827559024082614e-05,
      "loss": 0.0177,
      "step": 21900
    },
    {
      "epoch": 7.802801915233197,
      "grad_norm": 0.1798698902130127,
      "learning_rate": 2.4433408221985734e-05,
      "loss": 0.0162,
      "step": 22000
    },
    {
      "epoch": 7.838269196666076,
      "grad_norm": 0.3194769322872162,
      "learning_rate": 2.403925741988885e-05,
      "loss": 0.0151,
      "step": 22100
    },
    {
      "epoch": 7.873736478098953,
      "grad_norm": 0.24117021262645721,
      "learning_rate": 2.364510661779197e-05,
      "loss": 0.0153,
      "step": 22200
    },
    {
      "epoch": 7.909203759531832,
      "grad_norm": 0.51799076795578,
      "learning_rate": 2.3250955815695085e-05,
      "loss": 0.0164,
      "step": 22300
    },
    {
      "epoch": 7.94467104096471,
      "grad_norm": 0.40798109769821167,
      "learning_rate": 2.2856805013598204e-05,
      "loss": 0.0152,
      "step": 22400
    },
    {
      "epoch": 7.980138322397588,
      "grad_norm": 0.1852760761976242,
      "learning_rate": 2.2462654211501323e-05,
      "loss": 0.0141,
      "step": 22500
    },
    {
      "epoch": 8.015605603830467,
      "grad_norm": 0.28969836235046387,
      "learning_rate": 2.206850340940444e-05,
      "loss": 0.0144,
      "step": 22600
    },
    {
      "epoch": 8.051072885263345,
      "grad_norm": 0.3604482412338257,
      "learning_rate": 2.167435260730756e-05,
      "loss": 0.0127,
      "step": 22700
    },
    {
      "epoch": 8.086540166696222,
      "grad_norm": 0.3327074944972992,
      "learning_rate": 2.1280201805210675e-05,
      "loss": 0.0125,
      "step": 22800
    },
    {
      "epoch": 8.1220074481291,
      "grad_norm": 0.3128082752227783,
      "learning_rate": 2.0886051003113794e-05,
      "loss": 0.013,
      "step": 22900
    },
    {
      "epoch": 8.15747472956198,
      "grad_norm": 0.5814030766487122,
      "learning_rate": 2.049190020101691e-05,
      "loss": 0.0136,
      "step": 23000
    },
    {
      "epoch": 8.192942010994857,
      "grad_norm": 0.437690407037735,
      "learning_rate": 2.0097749398920026e-05,
      "loss": 0.0122,
      "step": 23100
    },
    {
      "epoch": 8.228409292427735,
      "grad_norm": 0.3171388804912567,
      "learning_rate": 1.9703598596823145e-05,
      "loss": 0.0116,
      "step": 23200
    },
    {
      "epoch": 8.263876573860614,
      "grad_norm": 0.4448626935482025,
      "learning_rate": 1.930944779472626e-05,
      "loss": 0.0116,
      "step": 23300
    },
    {
      "epoch": 8.299343855293492,
      "grad_norm": 0.2598377764225006,
      "learning_rate": 1.891529699262938e-05,
      "loss": 0.0127,
      "step": 23400
    },
    {
      "epoch": 8.334811136726369,
      "grad_norm": 0.16056151688098907,
      "learning_rate": 1.85211461905325e-05,
      "loss": 0.0104,
      "step": 23500
    },
    {
      "epoch": 8.370278418159248,
      "grad_norm": 0.3269256055355072,
      "learning_rate": 1.8126995388435616e-05,
      "loss": 0.0118,
      "step": 23600
    },
    {
      "epoch": 8.405745699592126,
      "grad_norm": 0.4142702519893646,
      "learning_rate": 1.7732844586338735e-05,
      "loss": 0.0105,
      "step": 23700
    },
    {
      "epoch": 8.441212981025004,
      "grad_norm": 0.32310691475868225,
      "learning_rate": 1.733869378424185e-05,
      "loss": 0.0117,
      "step": 23800
    },
    {
      "epoch": 8.476680262457883,
      "grad_norm": 0.3585638701915741,
      "learning_rate": 1.694454298214497e-05,
      "loss": 0.0102,
      "step": 23900
    },
    {
      "epoch": 8.51214754389076,
      "grad_norm": 0.4361192286014557,
      "learning_rate": 1.655039218004809e-05,
      "loss": 0.0103,
      "step": 24000
    },
    {
      "epoch": 8.547614825323638,
      "grad_norm": 0.4283641576766968,
      "learning_rate": 1.6156241377951205e-05,
      "loss": 0.0105,
      "step": 24100
    },
    {
      "epoch": 8.583082106756518,
      "grad_norm": 0.5136045813560486,
      "learning_rate": 1.576209057585432e-05,
      "loss": 0.0105,
      "step": 24200
    },
    {
      "epoch": 8.618549388189395,
      "grad_norm": 0.3392355740070343,
      "learning_rate": 1.536793977375744e-05,
      "loss": 0.01,
      "step": 24300
    },
    {
      "epoch": 8.654016669622273,
      "grad_norm": 0.2166924625635147,
      "learning_rate": 1.4973788971660557e-05,
      "loss": 0.0103,
      "step": 24400
    },
    {
      "epoch": 8.689483951055152,
      "grad_norm": 0.3039628863334656,
      "learning_rate": 1.4579638169563676e-05,
      "loss": 0.0077,
      "step": 24500
    },
    {
      "epoch": 8.72495123248803,
      "grad_norm": 0.3790707588195801,
      "learning_rate": 1.4185487367466793e-05,
      "loss": 0.0087,
      "step": 24600
    },
    {
      "epoch": 8.760418513920907,
      "grad_norm": 0.5515620708465576,
      "learning_rate": 1.3791336565369911e-05,
      "loss": 0.0088,
      "step": 24700
    },
    {
      "epoch": 8.795885795353787,
      "grad_norm": 0.1818406581878662,
      "learning_rate": 1.3397185763273029e-05,
      "loss": 0.0082,
      "step": 24800
    },
    {
      "epoch": 8.831353076786664,
      "grad_norm": 0.26624995470046997,
      "learning_rate": 1.3003034961176146e-05,
      "loss": 0.0078,
      "step": 24900
    },
    {
      "epoch": 8.866820358219542,
      "grad_norm": 0.18233326077461243,
      "learning_rate": 1.2608884159079266e-05,
      "loss": 0.0072,
      "step": 25000
    },
    {
      "epoch": 8.902287639652421,
      "grad_norm": 0.4694494605064392,
      "learning_rate": 1.2214733356982382e-05,
      "loss": 0.0084,
      "step": 25100
    },
    {
      "epoch": 8.937754921085299,
      "grad_norm": 0.2638952136039734,
      "learning_rate": 1.18205825548855e-05,
      "loss": 0.0076,
      "step": 25200
    },
    {
      "epoch": 8.973222202518176,
      "grad_norm": 0.1940479725599289,
      "learning_rate": 1.1426431752788617e-05,
      "loss": 0.0074,
      "step": 25300
    }
  ],
  "logging_steps": 100,
  "max_steps": 28190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.448059462173491e+21,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
