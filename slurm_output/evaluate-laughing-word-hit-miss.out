	Adding nVidia Cuda Toolkit 11.7
	Adding nVidia cuDNN 8.6 (.0.163)
	Adding nVidia TensorRT 8.6 (.0.12)
	Adding nvtop
Date              = Tue Nov 12 09:11:23 PM CET 2024
Hostname          = ctit086
Working Directory = /home/s2587130/SpeechLaughRecogniser
Name of nodes used          : ctit086
Gpu devices                 : 1
Starting worker: 
2024-11-12 21:13:11.959411: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-12 21:13:16.949069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-12 21:13:18.739653: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-12 21:13:19.470667: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-12 21:13:23.196824: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-12 21:13:50.801534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Evaluate Whisper Model - openai/whisper-small 

Loaded Token Dataset: 
Dataset({
    features: ['audio', 'sampling_rate', 'transcript'],
    num_rows: 255826
})
Loaded Word Dataset: 
Dataset({
    features: ['audio', 'sampling_rate', 'transcript'],
    num_rows: 255824
})
Filtered Laughter Dataset: 
Dataset({
    features: ['audio', 'sampling_rate', 'transcript'],
    num_rows: 26752
})
Example of Laughter Dataset: 
{'audio': {'path': 'sw02325A_186321625_188905625.wav', 'array': array([0.00119019, 0.0012207 , 0.00119019, ..., 0.00595093, 0.00500488,
       0.00497437]), 'sampling_rate': 16000}, 'sampling_rate': 16000, 'transcript': 'i do not either [LAUGHTER]'}
Filtered Laughing Words Dataset: 
Dataset({
    features: ['audio', 'sampling_rate', 'transcript'],
    num_rows: 26750
})
Example of Laughing Words Dataset: 
{'audio': {'path': 'sw02325A_186321625_188905625.wav', 'array': array([0.00119019, 0.0012207 , 0.00119019, ..., 0.00595093, 0.00500488,
       0.00497437]), 'sampling_rate': 16000}, 'sampling_rate': 16000, 'transcript': 'i do not either [LAUGHTER]'}
Total runtime: 10136.442705631256 seconds
