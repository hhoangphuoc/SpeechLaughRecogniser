{
  "best_metric": 0.17091864162071665,
  "best_model_checkpoint": "../checkpoints/whisper-batch16-6000steps-lr5/checkpoint-1500",
  "epoch": 8.284432171211598,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1380738695201933,
      "grad_norm": 2.391388177871704,
      "learning_rate": 9.800000000000001e-06,
      "loss": 1.6716,
      "step": 100
    },
    {
      "epoch": 0.2761477390403866,
      "grad_norm": 1.0206431150436401,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.1827,
      "step": 200
    },
    {
      "epoch": 0.41422160856057993,
      "grad_norm": 0.9093139171600342,
      "learning_rate": 2.98e-05,
      "loss": 0.1834,
      "step": 300
    },
    {
      "epoch": 0.5522954780807732,
      "grad_norm": 0.769759476184845,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.1869,
      "step": 400
    },
    {
      "epoch": 0.6903693476009665,
      "grad_norm": 0.8490528464317322,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.1925,
      "step": 500
    },
    {
      "epoch": 0.8284432171211599,
      "grad_norm": 1.074462652206421,
      "learning_rate": 5.9800000000000003e-05,
      "loss": 0.2022,
      "step": 600
    },
    {
      "epoch": 0.9665170866413532,
      "grad_norm": 0.8512539863586426,
      "learning_rate": 6.98e-05,
      "loss": 0.2102,
      "step": 700
    },
    {
      "epoch": 1.1045909561615463,
      "grad_norm": 0.7977840304374695,
      "learning_rate": 7.98e-05,
      "loss": 0.2129,
      "step": 800
    },
    {
      "epoch": 1.2426648256817396,
      "grad_norm": 1.0465747117996216,
      "learning_rate": 8.98e-05,
      "loss": 0.2014,
      "step": 900
    },
    {
      "epoch": 1.380738695201933,
      "grad_norm": 0.7996441721916199,
      "learning_rate": 9.98e-05,
      "loss": 0.1945,
      "step": 1000
    },
    {
      "epoch": 1.5188125647221264,
      "grad_norm": 0.8140670657157898,
      "learning_rate": 9.804e-05,
      "loss": 0.1849,
      "step": 1100
    },
    {
      "epoch": 1.6568864342423195,
      "grad_norm": 0.7830561995506287,
      "learning_rate": 9.604000000000001e-05,
      "loss": 0.1718,
      "step": 1200
    },
    {
      "epoch": 1.794960303762513,
      "grad_norm": 0.6395660638809204,
      "learning_rate": 9.404e-05,
      "loss": 0.1535,
      "step": 1300
    },
    {
      "epoch": 1.933034173282706,
      "grad_norm": 0.6505643129348755,
      "learning_rate": 9.204e-05,
      "loss": 0.1478,
      "step": 1400
    },
    {
      "epoch": 2.0711080428028996,
      "grad_norm": 0.6597594022750854,
      "learning_rate": 9.004e-05,
      "loss": 0.1417,
      "step": 1500
    },
    {
      "epoch": 2.2091819123230927,
      "grad_norm": 0.6059186458587646,
      "learning_rate": 8.804e-05,
      "loss": 0.129,
      "step": 1600
    },
    {
      "epoch": 2.347255781843286,
      "grad_norm": 0.6581311225891113,
      "learning_rate": 8.604000000000001e-05,
      "loss": 0.1161,
      "step": 1700
    },
    {
      "epoch": 2.4853296513634793,
      "grad_norm": 0.5844933390617371,
      "learning_rate": 8.404e-05,
      "loss": 0.1085,
      "step": 1800
    },
    {
      "epoch": 2.623403520883673,
      "grad_norm": 0.5885128378868103,
      "learning_rate": 8.204000000000001e-05,
      "loss": 0.1025,
      "step": 1900
    },
    {
      "epoch": 2.761477390403866,
      "grad_norm": 0.5072090029716492,
      "learning_rate": 8.004e-05,
      "loss": 0.0935,
      "step": 2000
    },
    {
      "epoch": 2.8995512599240594,
      "grad_norm": 0.5270977020263672,
      "learning_rate": 7.804e-05,
      "loss": 0.0919,
      "step": 2100
    },
    {
      "epoch": 3.037625129444253,
      "grad_norm": 0.5792059302330017,
      "learning_rate": 7.604e-05,
      "loss": 0.0866,
      "step": 2200
    },
    {
      "epoch": 3.175698998964446,
      "grad_norm": 0.4879016876220703,
      "learning_rate": 7.404e-05,
      "loss": 0.0806,
      "step": 2300
    },
    {
      "epoch": 3.313772868484639,
      "grad_norm": 0.4685279428958893,
      "learning_rate": 7.204000000000001e-05,
      "loss": 0.0723,
      "step": 2400
    },
    {
      "epoch": 3.4518467380048325,
      "grad_norm": 0.49131375551223755,
      "learning_rate": 7.004e-05,
      "loss": 0.0662,
      "step": 2500
    },
    {
      "epoch": 3.589920607525026,
      "grad_norm": 0.4354858994483948,
      "learning_rate": 6.804e-05,
      "loss": 0.0624,
      "step": 2600
    },
    {
      "epoch": 3.727994477045219,
      "grad_norm": 0.49017104506492615,
      "learning_rate": 6.604e-05,
      "loss": 0.0591,
      "step": 2700
    },
    {
      "epoch": 3.8660683465654127,
      "grad_norm": 1.0021116733551025,
      "learning_rate": 6.404e-05,
      "loss": 0.0585,
      "step": 2800
    },
    {
      "epoch": 4.004142216085606,
      "grad_norm": 0.4588888883590698,
      "learning_rate": 6.204e-05,
      "loss": 0.0556,
      "step": 2900
    },
    {
      "epoch": 4.142216085605799,
      "grad_norm": 0.39853253960609436,
      "learning_rate": 6.004000000000001e-05,
      "loss": 0.0535,
      "step": 3000
    },
    {
      "epoch": 4.280289955125992,
      "grad_norm": 2.1464860439300537,
      "learning_rate": 5.804000000000001e-05,
      "loss": 0.0457,
      "step": 3100
    },
    {
      "epoch": 4.418363824646185,
      "grad_norm": 0.4888297915458679,
      "learning_rate": 5.6040000000000006e-05,
      "loss": 0.0425,
      "step": 3200
    },
    {
      "epoch": 4.556437694166379,
      "grad_norm": 0.28734493255615234,
      "learning_rate": 5.4040000000000004e-05,
      "loss": 0.0398,
      "step": 3300
    },
    {
      "epoch": 4.694511563686572,
      "grad_norm": 0.4020119607448578,
      "learning_rate": 5.204e-05,
      "loss": 0.0373,
      "step": 3400
    },
    {
      "epoch": 4.8325854332067655,
      "grad_norm": 0.38171395659446716,
      "learning_rate": 5.0039999999999995e-05,
      "loss": 0.0359,
      "step": 3500
    },
    {
      "epoch": 4.9706593027269586,
      "grad_norm": 0.4817271828651428,
      "learning_rate": 4.804e-05,
      "loss": 0.0347,
      "step": 3600
    },
    {
      "epoch": 5.1087331722471525,
      "grad_norm": 0.44141343235969543,
      "learning_rate": 4.604e-05,
      "loss": 0.0319,
      "step": 3700
    },
    {
      "epoch": 5.246807041767346,
      "grad_norm": 0.480552613735199,
      "learning_rate": 4.4040000000000005e-05,
      "loss": 0.0275,
      "step": 3800
    },
    {
      "epoch": 5.384880911287539,
      "grad_norm": 0.3112877309322357,
      "learning_rate": 4.2040000000000004e-05,
      "loss": 0.027,
      "step": 3900
    },
    {
      "epoch": 5.522954780807732,
      "grad_norm": 0.290021151304245,
      "learning_rate": 4.004e-05,
      "loss": 0.0246,
      "step": 4000
    },
    {
      "epoch": 5.661028650327926,
      "grad_norm": 0.30392569303512573,
      "learning_rate": 3.804e-05,
      "loss": 0.0223,
      "step": 4100
    },
    {
      "epoch": 5.799102519848119,
      "grad_norm": 0.3751727044582367,
      "learning_rate": 3.604e-05,
      "loss": 0.0206,
      "step": 4200
    },
    {
      "epoch": 5.937176389368312,
      "grad_norm": 0.25975438952445984,
      "learning_rate": 3.404e-05,
      "loss": 0.0198,
      "step": 4300
    },
    {
      "epoch": 6.075250258888506,
      "grad_norm": 0.16564127802848816,
      "learning_rate": 3.2040000000000005e-05,
      "loss": 0.0185,
      "step": 4400
    },
    {
      "epoch": 6.213324128408699,
      "grad_norm": 0.23278073966503143,
      "learning_rate": 3.004e-05,
      "loss": 0.0156,
      "step": 4500
    },
    {
      "epoch": 6.351397997928892,
      "grad_norm": 0.2620650827884674,
      "learning_rate": 2.804e-05,
      "loss": 0.0143,
      "step": 4600
    },
    {
      "epoch": 6.489471867449085,
      "grad_norm": 0.19472573697566986,
      "learning_rate": 2.6040000000000005e-05,
      "loss": 0.0128,
      "step": 4700
    },
    {
      "epoch": 6.627545736969278,
      "grad_norm": 0.23765137791633606,
      "learning_rate": 2.404e-05,
      "loss": 0.0119,
      "step": 4800
    },
    {
      "epoch": 6.765619606489472,
      "grad_norm": 0.1941007375717163,
      "learning_rate": 2.2040000000000002e-05,
      "loss": 0.011,
      "step": 4900
    },
    {
      "epoch": 6.903693476009665,
      "grad_norm": 0.11828970164060593,
      "learning_rate": 2.004e-05,
      "loss": 0.0095,
      "step": 5000
    },
    {
      "epoch": 7.041767345529858,
      "grad_norm": 0.27438539266586304,
      "learning_rate": 1.804e-05,
      "loss": 0.0096,
      "step": 5100
    },
    {
      "epoch": 7.179841215050052,
      "grad_norm": 0.09317442774772644,
      "learning_rate": 1.604e-05,
      "loss": 0.0079,
      "step": 5200
    },
    {
      "epoch": 7.317915084570245,
      "grad_norm": 0.15455910563468933,
      "learning_rate": 1.4040000000000001e-05,
      "loss": 0.0073,
      "step": 5300
    },
    {
      "epoch": 7.455988954090438,
      "grad_norm": 0.19135472178459167,
      "learning_rate": 1.204e-05,
      "loss": 0.0067,
      "step": 5400
    },
    {
      "epoch": 7.594062823610631,
      "grad_norm": 0.13623353838920593,
      "learning_rate": 1.004e-05,
      "loss": 0.0058,
      "step": 5500
    },
    {
      "epoch": 7.732136693130825,
      "grad_norm": 0.09608476608991623,
      "learning_rate": 8.040000000000001e-06,
      "loss": 0.005,
      "step": 5600
    },
    {
      "epoch": 7.870210562651018,
      "grad_norm": 0.19600124657154083,
      "learning_rate": 6.040000000000001e-06,
      "loss": 0.0047,
      "step": 5700
    },
    {
      "epoch": 8.008284432171212,
      "grad_norm": 0.06651196628808975,
      "learning_rate": 4.04e-06,
      "loss": 0.0046,
      "step": 5800
    },
    {
      "epoch": 8.146358301691405,
      "grad_norm": 0.29232117533683777,
      "learning_rate": 2.0400000000000004e-06,
      "loss": 0.0041,
      "step": 5900
    },
    {
      "epoch": 8.284432171211598,
      "grad_norm": 0.07477915287017822,
      "learning_rate": 4e-08,
      "loss": 0.0036,
      "step": 6000
    }
  ],
  "logging_steps": 100,
  "max_steps": 6000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.2610887757398016e+21,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
