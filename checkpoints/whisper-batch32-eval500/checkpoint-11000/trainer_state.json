{
  "best_metric": 0.1495230927550033,
  "best_model_checkpoint": "../checkpoints/whisper-batch16-eval100/whisper-batch32-eval500/checkpoint-1000",
  "epoch": 3.7970314118053157,
  "eval_steps": 500,
  "global_step": 11000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03451846738004832,
      "grad_norm": 3.320855140686035,
      "learning_rate": 6.125e-06,
      "loss": 2.0378,
      "step": 100
    },
    {
      "epoch": 0.06903693476009665,
      "grad_norm": 2.1870172023773193,
      "learning_rate": 1.2375000000000001e-05,
      "loss": 0.2095,
      "step": 200
    },
    {
      "epoch": 0.10355540214014498,
      "grad_norm": 1.7602341175079346,
      "learning_rate": 1.8625000000000002e-05,
      "loss": 0.2056,
      "step": 300
    },
    {
      "epoch": 0.1380738695201933,
      "grad_norm": 2.3793084621429443,
      "learning_rate": 2.4875e-05,
      "loss": 0.214,
      "step": 400
    },
    {
      "epoch": 0.17259233690024162,
      "grad_norm": 3.264246702194214,
      "learning_rate": 3.1125000000000004e-05,
      "loss": 0.2188,
      "step": 500
    },
    {
      "epoch": 0.20711080428028997,
      "grad_norm": 1.6276133060455322,
      "learning_rate": 3.737500000000001e-05,
      "loss": 0.2323,
      "step": 600
    },
    {
      "epoch": 0.2416292716603383,
      "grad_norm": 1.6751103401184082,
      "learning_rate": 4.3625e-05,
      "loss": 0.2489,
      "step": 700
    },
    {
      "epoch": 0.2761477390403866,
      "grad_norm": 1.5971848964691162,
      "learning_rate": 4.9875000000000006e-05,
      "loss": 0.2485,
      "step": 800
    },
    {
      "epoch": 0.3106662064204349,
      "grad_norm": 2.6102049350738525,
      "learning_rate": 4.974479166666667e-05,
      "loss": 0.2607,
      "step": 900
    },
    {
      "epoch": 0.34518467380048323,
      "grad_norm": 1.648750901222229,
      "learning_rate": 4.9484375e-05,
      "loss": 0.2633,
      "step": 1000
    },
    {
      "epoch": 0.3797031411805316,
      "grad_norm": 1.5576984882354736,
      "learning_rate": 4.922395833333334e-05,
      "loss": 0.2684,
      "step": 1100
    },
    {
      "epoch": 0.41422160856057993,
      "grad_norm": 1.7566832304000854,
      "learning_rate": 4.8963541666666665e-05,
      "loss": 0.2606,
      "step": 1200
    },
    {
      "epoch": 0.44874007594062826,
      "grad_norm": 1.623228907585144,
      "learning_rate": 4.8703125000000006e-05,
      "loss": 0.2568,
      "step": 1300
    },
    {
      "epoch": 0.4832585433206766,
      "grad_norm": 1.8411612510681152,
      "learning_rate": 4.844791666666667e-05,
      "loss": 0.2683,
      "step": 1400
    },
    {
      "epoch": 0.5177770107007249,
      "grad_norm": 1.59712815284729,
      "learning_rate": 4.81875e-05,
      "loss": 0.2737,
      "step": 1500
    },
    {
      "epoch": 0.5522954780807732,
      "grad_norm": 1.4943729639053345,
      "learning_rate": 4.7927083333333334e-05,
      "loss": 0.2568,
      "step": 1600
    },
    {
      "epoch": 0.5868139454608216,
      "grad_norm": 2.194849967956543,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.2544,
      "step": 1700
    },
    {
      "epoch": 0.6213324128408698,
      "grad_norm": 1.5813184976577759,
      "learning_rate": 4.7406250000000004e-05,
      "loss": 3.2045,
      "step": 1800
    },
    {
      "epoch": 0.6558508802209182,
      "grad_norm": 1.628429651260376,
      "learning_rate": 4.714583333333333e-05,
      "loss": 0.2527,
      "step": 1900
    },
    {
      "epoch": 0.6903693476009665,
      "grad_norm": 1.7312068939208984,
      "learning_rate": 4.6885416666666674e-05,
      "loss": 0.2468,
      "step": 2000
    },
    {
      "epoch": 0.7248878149810148,
      "grad_norm": 2.299806594848633,
      "learning_rate": 4.6625e-05,
      "loss": 0.2517,
      "step": 2100
    },
    {
      "epoch": 0.7594062823610632,
      "grad_norm": 1.6720917224884033,
      "learning_rate": 4.6364583333333337e-05,
      "loss": 0.2488,
      "step": 2200
    },
    {
      "epoch": 0.7939247497411115,
      "grad_norm": 1.4435981512069702,
      "learning_rate": 4.610416666666667e-05,
      "loss": 0.2444,
      "step": 2300
    },
    {
      "epoch": 0.8284432171211599,
      "grad_norm": 1.557829737663269,
      "learning_rate": 4.584375e-05,
      "loss": 0.2485,
      "step": 2400
    },
    {
      "epoch": 0.8629616845012081,
      "grad_norm": 1.5332801342010498,
      "learning_rate": 4.5583333333333335e-05,
      "loss": 0.2407,
      "step": 2500
    },
    {
      "epoch": 0.8974801518812565,
      "grad_norm": 1.5446515083312988,
      "learning_rate": 4.532291666666667e-05,
      "loss": 0.2392,
      "step": 2600
    },
    {
      "epoch": 0.9319986192613048,
      "grad_norm": 1.770094871520996,
      "learning_rate": 4.5062500000000004e-05,
      "loss": 0.2424,
      "step": 2700
    },
    {
      "epoch": 0.9665170866413532,
      "grad_norm": 1.5940402746200562,
      "learning_rate": 4.480208333333333e-05,
      "loss": 0.2436,
      "step": 2800
    },
    {
      "epoch": 1.0010355540214015,
      "grad_norm": 1.3417888879776,
      "learning_rate": 4.454166666666667e-05,
      "loss": 0.2334,
      "step": 2900
    },
    {
      "epoch": 1.0355540214014498,
      "grad_norm": 1.1583093404769897,
      "learning_rate": 4.428125e-05,
      "loss": 0.2332,
      "step": 3000
    },
    {
      "epoch": 1.070072488781498,
      "grad_norm": 1.3811677694320679,
      "learning_rate": 4.402083333333333e-05,
      "loss": 0.2142,
      "step": 3100
    },
    {
      "epoch": 1.1045909561615463,
      "grad_norm": 1.587578535079956,
      "learning_rate": 4.376041666666667e-05,
      "loss": 0.1987,
      "step": 3200
    },
    {
      "epoch": 1.1391094235415948,
      "grad_norm": 1.1920264959335327,
      "learning_rate": 4.35e-05,
      "loss": 0.1878,
      "step": 3300
    },
    {
      "epoch": 1.173627890921643,
      "grad_norm": 1.2273807525634766,
      "learning_rate": 4.3239583333333335e-05,
      "loss": 0.1727,
      "step": 3400
    },
    {
      "epoch": 1.2081463583016914,
      "grad_norm": 1.1936527490615845,
      "learning_rate": 4.297916666666667e-05,
      "loss": 0.1614,
      "step": 3500
    },
    {
      "epoch": 1.2426648256817396,
      "grad_norm": 0.9765265583992004,
      "learning_rate": 4.2718750000000005e-05,
      "loss": 0.1555,
      "step": 3600
    },
    {
      "epoch": 1.2771832930617881,
      "grad_norm": 1.0710374116897583,
      "learning_rate": 4.245833333333333e-05,
      "loss": 0.148,
      "step": 3700
    },
    {
      "epoch": 1.3117017604418364,
      "grad_norm": 1.2795295715332031,
      "learning_rate": 4.219791666666667e-05,
      "loss": 0.1483,
      "step": 3800
    },
    {
      "epoch": 1.3462202278218847,
      "grad_norm": 1.563706398010254,
      "learning_rate": 4.19375e-05,
      "loss": 0.1496,
      "step": 3900
    },
    {
      "epoch": 1.380738695201933,
      "grad_norm": 1.126268982887268,
      "learning_rate": 4.167708333333333e-05,
      "loss": 0.1478,
      "step": 4000
    },
    {
      "epoch": 1.4152571625819814,
      "grad_norm": 1.1077800989151,
      "learning_rate": 4.141666666666667e-05,
      "loss": 0.1405,
      "step": 4100
    },
    {
      "epoch": 1.4497756299620297,
      "grad_norm": 1.0499820709228516,
      "learning_rate": 4.115625e-05,
      "loss": 0.1453,
      "step": 4200
    },
    {
      "epoch": 1.484294097342078,
      "grad_norm": 0.9260734915733337,
      "learning_rate": 4.0895833333333336e-05,
      "loss": 0.1449,
      "step": 4300
    },
    {
      "epoch": 1.5188125647221264,
      "grad_norm": 0.7689826488494873,
      "learning_rate": 4.063541666666667e-05,
      "loss": 0.1524,
      "step": 4400
    },
    {
      "epoch": 1.5533310321021747,
      "grad_norm": 0.9377577900886536,
      "learning_rate": 4.0375e-05,
      "loss": 0.1403,
      "step": 4500
    },
    {
      "epoch": 1.587849499482223,
      "grad_norm": 1.3503479957580566,
      "learning_rate": 4.0114583333333334e-05,
      "loss": 0.1401,
      "step": 4600
    },
    {
      "epoch": 1.6223679668622712,
      "grad_norm": 0.9401369094848633,
      "learning_rate": 3.985416666666667e-05,
      "loss": 0.1897,
      "step": 4700
    },
    {
      "epoch": 1.6568864342423195,
      "grad_norm": 0.7104499936103821,
      "learning_rate": 3.9593750000000004e-05,
      "loss": 0.135,
      "step": 4800
    },
    {
      "epoch": 1.691404901622368,
      "grad_norm": 0.9628833532333374,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.1334,
      "step": 4900
    },
    {
      "epoch": 1.7259233690024163,
      "grad_norm": 0.9395302534103394,
      "learning_rate": 3.907291666666667e-05,
      "loss": 0.1325,
      "step": 5000
    },
    {
      "epoch": 1.7604418363824648,
      "grad_norm": 0.8820216059684753,
      "learning_rate": 3.88125e-05,
      "loss": 0.1371,
      "step": 5100
    },
    {
      "epoch": 1.794960303762513,
      "grad_norm": 0.9641322493553162,
      "learning_rate": 3.8552083333333336e-05,
      "loss": 0.1318,
      "step": 5200
    },
    {
      "epoch": 1.8294787711425613,
      "grad_norm": 0.8822882175445557,
      "learning_rate": 3.829166666666667e-05,
      "loss": 0.1335,
      "step": 5300
    },
    {
      "epoch": 1.8639972385226096,
      "grad_norm": 0.9593062996864319,
      "learning_rate": 3.803125e-05,
      "loss": 0.1285,
      "step": 5400
    },
    {
      "epoch": 1.8985157059026578,
      "grad_norm": 0.9123969674110413,
      "learning_rate": 3.7770833333333334e-05,
      "loss": 0.1319,
      "step": 5500
    },
    {
      "epoch": 1.933034173282706,
      "grad_norm": 1.0847429037094116,
      "learning_rate": 3.751041666666667e-05,
      "loss": 0.1292,
      "step": 5600
    },
    {
      "epoch": 1.9675526406627546,
      "grad_norm": 0.898697018623352,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.1292,
      "step": 5700
    },
    {
      "epoch": 2.002071108042803,
      "grad_norm": 1.20499849319458,
      "learning_rate": 3.698958333333333e-05,
      "loss": 0.1267,
      "step": 5800
    },
    {
      "epoch": 2.0365895754228514,
      "grad_norm": 0.932196855545044,
      "learning_rate": 3.672916666666667e-05,
      "loss": 0.1248,
      "step": 5900
    },
    {
      "epoch": 2.0711080428028996,
      "grad_norm": 1.095960021018982,
      "learning_rate": 3.646875e-05,
      "loss": 0.1194,
      "step": 6000
    },
    {
      "epoch": 2.105626510182948,
      "grad_norm": 1.0317456722259521,
      "learning_rate": 3.620833333333333e-05,
      "loss": 0.1131,
      "step": 6100
    },
    {
      "epoch": 2.140144977562996,
      "grad_norm": 1.220065951347351,
      "learning_rate": 3.594791666666667e-05,
      "loss": 0.1073,
      "step": 6200
    },
    {
      "epoch": 2.1746634449430444,
      "grad_norm": 0.9683087468147278,
      "learning_rate": 3.56875e-05,
      "loss": 0.1014,
      "step": 6300
    },
    {
      "epoch": 2.2091819123230927,
      "grad_norm": 0.9133686423301697,
      "learning_rate": 3.5427083333333335e-05,
      "loss": 0.096,
      "step": 6400
    },
    {
      "epoch": 2.2437003797031414,
      "grad_norm": 1.0217348337173462,
      "learning_rate": 3.516666666666667e-05,
      "loss": 0.0915,
      "step": 6500
    },
    {
      "epoch": 2.2782188470831897,
      "grad_norm": 0.950636625289917,
      "learning_rate": 3.4906250000000005e-05,
      "loss": 0.0871,
      "step": 6600
    },
    {
      "epoch": 2.312737314463238,
      "grad_norm": 0.8395228981971741,
      "learning_rate": 3.464583333333333e-05,
      "loss": 0.0888,
      "step": 6700
    },
    {
      "epoch": 2.347255781843286,
      "grad_norm": 1.4029314517974854,
      "learning_rate": 3.438541666666667e-05,
      "loss": 0.0895,
      "step": 6800
    },
    {
      "epoch": 2.3817742492233345,
      "grad_norm": 1.1300544738769531,
      "learning_rate": 3.4125e-05,
      "loss": 0.0865,
      "step": 6900
    },
    {
      "epoch": 2.4162927166033827,
      "grad_norm": 0.9444778561592102,
      "learning_rate": 3.386458333333333e-05,
      "loss": 0.0823,
      "step": 7000
    },
    {
      "epoch": 2.450811183983431,
      "grad_norm": 1.0318132638931274,
      "learning_rate": 3.360416666666667e-05,
      "loss": 0.0842,
      "step": 7100
    },
    {
      "epoch": 2.4853296513634793,
      "grad_norm": 0.8855425119400024,
      "learning_rate": 3.334375e-05,
      "loss": 0.0846,
      "step": 7200
    },
    {
      "epoch": 2.5198481187435275,
      "grad_norm": 1.0063508749008179,
      "learning_rate": 3.3083333333333336e-05,
      "loss": 0.0871,
      "step": 7300
    },
    {
      "epoch": 2.5543665861235763,
      "grad_norm": 1.03705632686615,
      "learning_rate": 3.282291666666667e-05,
      "loss": 0.081,
      "step": 7400
    },
    {
      "epoch": 2.5888850535036245,
      "grad_norm": 0.9063752293586731,
      "learning_rate": 3.25625e-05,
      "loss": 0.08,
      "step": 7500
    },
    {
      "epoch": 2.623403520883673,
      "grad_norm": 0.9737015962600708,
      "learning_rate": 3.2302083333333334e-05,
      "loss": 0.1011,
      "step": 7600
    },
    {
      "epoch": 2.657921988263721,
      "grad_norm": 1.157616138458252,
      "learning_rate": 3.204166666666667e-05,
      "loss": 0.079,
      "step": 7700
    },
    {
      "epoch": 2.6924404556437693,
      "grad_norm": 0.8755310773849487,
      "learning_rate": 3.1781250000000003e-05,
      "loss": 0.0749,
      "step": 7800
    },
    {
      "epoch": 2.7269589230238176,
      "grad_norm": 0.9382185935974121,
      "learning_rate": 3.152083333333333e-05,
      "loss": 0.0765,
      "step": 7900
    },
    {
      "epoch": 2.761477390403866,
      "grad_norm": 0.8320749402046204,
      "learning_rate": 3.1260416666666666e-05,
      "loss": 0.0786,
      "step": 8000
    },
    {
      "epoch": 2.7959958577839146,
      "grad_norm": 1.0487291812896729,
      "learning_rate": 3.1e-05,
      "loss": 0.0752,
      "step": 8100
    },
    {
      "epoch": 2.830514325163963,
      "grad_norm": 1.1342612504959106,
      "learning_rate": 3.073958333333333e-05,
      "loss": 0.0745,
      "step": 8200
    },
    {
      "epoch": 2.865032792544011,
      "grad_norm": 0.8944520950317383,
      "learning_rate": 3.047916666666667e-05,
      "loss": 0.0731,
      "step": 8300
    },
    {
      "epoch": 2.8995512599240594,
      "grad_norm": 1.3483531475067139,
      "learning_rate": 3.0218750000000003e-05,
      "loss": 0.0745,
      "step": 8400
    },
    {
      "epoch": 2.9340697273041076,
      "grad_norm": 0.7948160171508789,
      "learning_rate": 2.9958333333333334e-05,
      "loss": 0.0737,
      "step": 8500
    },
    {
      "epoch": 2.968588194684156,
      "grad_norm": 0.8718352913856506,
      "learning_rate": 2.969791666666667e-05,
      "loss": 0.0727,
      "step": 8600
    },
    {
      "epoch": 3.003106662064204,
      "grad_norm": 0.691440224647522,
      "learning_rate": 2.94375e-05,
      "loss": 0.0691,
      "step": 8700
    },
    {
      "epoch": 3.037625129444253,
      "grad_norm": 0.7712539434432983,
      "learning_rate": 2.9177083333333332e-05,
      "loss": 0.0701,
      "step": 8800
    },
    {
      "epoch": 3.072143596824301,
      "grad_norm": 0.8728411197662354,
      "learning_rate": 2.891666666666667e-05,
      "loss": 0.0692,
      "step": 8900
    },
    {
      "epoch": 3.1066620642043494,
      "grad_norm": 0.7378185987472534,
      "learning_rate": 2.8656250000000002e-05,
      "loss": 0.0652,
      "step": 9000
    },
    {
      "epoch": 3.1411805315843977,
      "grad_norm": 0.9022600650787354,
      "learning_rate": 2.8395833333333333e-05,
      "loss": 0.0603,
      "step": 9100
    },
    {
      "epoch": 3.175698998964446,
      "grad_norm": 0.7345051169395447,
      "learning_rate": 2.813541666666667e-05,
      "loss": 0.0578,
      "step": 9200
    },
    {
      "epoch": 3.2102174663444942,
      "grad_norm": 0.9268474578857422,
      "learning_rate": 2.7875e-05,
      "loss": 0.0567,
      "step": 9300
    },
    {
      "epoch": 3.2447359337245425,
      "grad_norm": 1.1091772317886353,
      "learning_rate": 2.761458333333333e-05,
      "loss": 0.0524,
      "step": 9400
    },
    {
      "epoch": 3.2792544011045908,
      "grad_norm": 0.8707956671714783,
      "learning_rate": 2.735416666666667e-05,
      "loss": 0.0525,
      "step": 9500
    },
    {
      "epoch": 3.313772868484639,
      "grad_norm": 0.7471140623092651,
      "learning_rate": 2.709375e-05,
      "loss": 0.0514,
      "step": 9600
    },
    {
      "epoch": 3.3482913358646877,
      "grad_norm": 1.6841061115264893,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 0.0502,
      "step": 9700
    },
    {
      "epoch": 3.382809803244736,
      "grad_norm": 0.8101677298545837,
      "learning_rate": 2.657291666666667e-05,
      "loss": 0.0501,
      "step": 9800
    },
    {
      "epoch": 3.4173282706247843,
      "grad_norm": 0.8214847445487976,
      "learning_rate": 2.6312500000000003e-05,
      "loss": 0.0485,
      "step": 9900
    },
    {
      "epoch": 3.4518467380048325,
      "grad_norm": 1.0522942543029785,
      "learning_rate": 2.6052083333333334e-05,
      "loss": 0.0494,
      "step": 10000
    },
    {
      "epoch": 3.486365205384881,
      "grad_norm": 0.8221210241317749,
      "learning_rate": 2.579166666666667e-05,
      "loss": 0.049,
      "step": 10100
    },
    {
      "epoch": 3.520883672764929,
      "grad_norm": 0.8612304329872131,
      "learning_rate": 2.553125e-05,
      "loss": 0.0492,
      "step": 10200
    },
    {
      "epoch": 3.5554021401449774,
      "grad_norm": 0.7969996929168701,
      "learning_rate": 2.5270833333333332e-05,
      "loss": 0.0451,
      "step": 10300
    },
    {
      "epoch": 3.589920607525026,
      "grad_norm": 0.8061138391494751,
      "learning_rate": 2.501041666666667e-05,
      "loss": 0.0443,
      "step": 10400
    },
    {
      "epoch": 3.6244390749050743,
      "grad_norm": 0.7332197427749634,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.0547,
      "step": 10500
    },
    {
      "epoch": 3.6589575422851226,
      "grad_norm": 0.7362383604049683,
      "learning_rate": 2.4489583333333337e-05,
      "loss": 0.0445,
      "step": 10600
    },
    {
      "epoch": 3.693476009665171,
      "grad_norm": 0.7443714141845703,
      "learning_rate": 2.422916666666667e-05,
      "loss": 0.0417,
      "step": 10700
    },
    {
      "epoch": 3.727994477045219,
      "grad_norm": 0.5422382354736328,
      "learning_rate": 2.396875e-05,
      "loss": 0.0421,
      "step": 10800
    },
    {
      "epoch": 3.7625129444252674,
      "grad_norm": 0.7512903809547424,
      "learning_rate": 2.3708333333333335e-05,
      "loss": 0.0463,
      "step": 10900
    },
    {
      "epoch": 3.7970314118053157,
      "grad_norm": 0.7703170776367188,
      "learning_rate": 2.3447916666666666e-05,
      "loss": 0.0433,
      "step": 11000
    }
  ],
  "logging_steps": 100,
  "max_steps": 20000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 7,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4946741815648256e+21,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
