{
  "best_metric": 16.787749397146236,
  "best_model_checkpoint": "../fine-tuned/speechlaugh-whisper-large-v2/checkpoint-1500",
  "epoch": 1.3807684839593537,
  "eval_steps": 500,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01725960604949192,
      "grad_norm": 4.637730598449707,
      "learning_rate": 6.0625e-06,
      "loss": 2.5462,
      "step": 100
    },
    {
      "epoch": 0.03451921209898384,
      "grad_norm": 3.2548561096191406,
      "learning_rate": 1.2312500000000001e-05,
      "loss": 0.2536,
      "step": 200
    },
    {
      "epoch": 0.051778818148475764,
      "grad_norm": 2.191505193710327,
      "learning_rate": 1.85625e-05,
      "loss": 0.2457,
      "step": 300
    },
    {
      "epoch": 0.06903842419796768,
      "grad_norm": 3.936305284500122,
      "learning_rate": 2.4812500000000003e-05,
      "loss": 0.2391,
      "step": 400
    },
    {
      "epoch": 0.0862980302474596,
      "grad_norm": 3.4436891078948975,
      "learning_rate": 3.10625e-05,
      "loss": 0.2528,
      "step": 500
    },
    {
      "epoch": 0.10355763629695153,
      "grad_norm": 3.175534725189209,
      "learning_rate": 3.73125e-05,
      "loss": 0.2863,
      "step": 600
    },
    {
      "epoch": 0.12081724234644345,
      "grad_norm": 3.5704617500305176,
      "learning_rate": 4.35625e-05,
      "loss": 0.2976,
      "step": 700
    },
    {
      "epoch": 0.13807684839593537,
      "grad_norm": 3.5495376586914062,
      "learning_rate": 4.98125e-05,
      "loss": 0.3317,
      "step": 800
    },
    {
      "epoch": 0.1553364544454273,
      "grad_norm": 5.7765212059021,
      "learning_rate": 4.9326388888888894e-05,
      "loss": 0.3352,
      "step": 900
    },
    {
      "epoch": 0.1725960604949192,
      "grad_norm": 2.3604536056518555,
      "learning_rate": 4.863194444444445e-05,
      "loss": 0.3136,
      "step": 1000
    },
    {
      "epoch": 0.18985566654441113,
      "grad_norm": 2.7648491859436035,
      "learning_rate": 4.79375e-05,
      "loss": 0.3289,
      "step": 1100
    },
    {
      "epoch": 0.20711527259390305,
      "grad_norm": 20.068906784057617,
      "learning_rate": 4.724305555555556e-05,
      "loss": 0.3681,
      "step": 1200
    },
    {
      "epoch": 0.22437487864339498,
      "grad_norm": 3.716804265975952,
      "learning_rate": 4.654861111111111e-05,
      "loss": 0.3382,
      "step": 1300
    },
    {
      "epoch": 0.2416344846928869,
      "grad_norm": 3.505953550338745,
      "learning_rate": 4.585416666666667e-05,
      "loss": 0.3385,
      "step": 1400
    },
    {
      "epoch": 0.2588940907423788,
      "grad_norm": 2.7684497833251953,
      "learning_rate": 4.5159722222222225e-05,
      "loss": 0.3083,
      "step": 1500
    },
    {
      "epoch": 0.27615369679187074,
      "grad_norm": 2.9160945415496826,
      "learning_rate": 4.446527777777778e-05,
      "loss": 0.3002,
      "step": 1600
    },
    {
      "epoch": 0.29341330284136263,
      "grad_norm": 2.9870543479919434,
      "learning_rate": 4.377083333333333e-05,
      "loss": 0.3057,
      "step": 1700
    },
    {
      "epoch": 0.3106729088908546,
      "grad_norm": 3.1911816596984863,
      "learning_rate": 4.307638888888889e-05,
      "loss": 0.2991,
      "step": 1800
    },
    {
      "epoch": 0.3279325149403465,
      "grad_norm": 3.6237101554870605,
      "learning_rate": 4.238194444444445e-05,
      "loss": 0.3029,
      "step": 1900
    },
    {
      "epoch": 0.3451921209898384,
      "grad_norm": 1.8936268091201782,
      "learning_rate": 4.1687500000000004e-05,
      "loss": 0.2967,
      "step": 2000
    },
    {
      "epoch": 0.3624517270393303,
      "grad_norm": 2.6264662742614746,
      "learning_rate": 4.099305555555556e-05,
      "loss": 0.3132,
      "step": 2100
    },
    {
      "epoch": 0.37971133308882227,
      "grad_norm": 2.6725049018859863,
      "learning_rate": 4.029861111111111e-05,
      "loss": 0.2907,
      "step": 2200
    },
    {
      "epoch": 0.39697093913831416,
      "grad_norm": 2.7291204929351807,
      "learning_rate": 3.960416666666667e-05,
      "loss": 0.2885,
      "step": 2300
    },
    {
      "epoch": 0.4142305451878061,
      "grad_norm": 2.6085126399993896,
      "learning_rate": 3.890972222222222e-05,
      "loss": 0.2942,
      "step": 2400
    },
    {
      "epoch": 0.431490151237298,
      "grad_norm": 2.9268949031829834,
      "learning_rate": 3.821527777777778e-05,
      "loss": 0.274,
      "step": 2500
    },
    {
      "epoch": 0.44874975728678995,
      "grad_norm": 1.9787893295288086,
      "learning_rate": 3.7520833333333335e-05,
      "loss": 0.2736,
      "step": 2600
    },
    {
      "epoch": 0.46600936333628185,
      "grad_norm": 1.9685094356536865,
      "learning_rate": 3.682638888888889e-05,
      "loss": 0.2779,
      "step": 2700
    },
    {
      "epoch": 0.4832689693857738,
      "grad_norm": 1.6404417753219604,
      "learning_rate": 3.613194444444445e-05,
      "loss": 0.2672,
      "step": 2800
    },
    {
      "epoch": 0.5005285754352657,
      "grad_norm": 2.2349135875701904,
      "learning_rate": 3.54375e-05,
      "loss": 0.2818,
      "step": 2900
    },
    {
      "epoch": 0.5177881814847576,
      "grad_norm": 2.418163537979126,
      "learning_rate": 3.474305555555556e-05,
      "loss": 0.2722,
      "step": 3000
    },
    {
      "epoch": 0.5350477875342495,
      "grad_norm": 2.497055768966675,
      "learning_rate": 3.4048611111111114e-05,
      "loss": 0.2777,
      "step": 3100
    },
    {
      "epoch": 0.5523073935837415,
      "grad_norm": 1.9276713132858276,
      "learning_rate": 3.3354166666666667e-05,
      "loss": 0.2562,
      "step": 3200
    },
    {
      "epoch": 0.5695669996332333,
      "grad_norm": 1.8236234188079834,
      "learning_rate": 3.265972222222222e-05,
      "loss": 0.2547,
      "step": 3300
    },
    {
      "epoch": 0.5868266056827253,
      "grad_norm": 2.1427037715911865,
      "learning_rate": 3.196527777777778e-05,
      "loss": 0.2615,
      "step": 3400
    },
    {
      "epoch": 0.6040862117322172,
      "grad_norm": 5.02942419052124,
      "learning_rate": 3.127083333333333e-05,
      "loss": 0.2587,
      "step": 3500
    },
    {
      "epoch": 0.6213458177817092,
      "grad_norm": 2.078652858734131,
      "learning_rate": 3.057638888888889e-05,
      "loss": 0.2473,
      "step": 3600
    },
    {
      "epoch": 0.638605423831201,
      "grad_norm": 1.6239781379699707,
      "learning_rate": 2.988194444444445e-05,
      "loss": 0.2532,
      "step": 3700
    },
    {
      "epoch": 0.655865029880693,
      "grad_norm": 2.753049612045288,
      "learning_rate": 2.91875e-05,
      "loss": 0.2434,
      "step": 3800
    },
    {
      "epoch": 0.6731246359301849,
      "grad_norm": 1.697260856628418,
      "learning_rate": 2.8493055555555558e-05,
      "loss": 0.2414,
      "step": 3900
    },
    {
      "epoch": 0.6903842419796768,
      "grad_norm": 4.711200714111328,
      "learning_rate": 2.779861111111111e-05,
      "loss": 0.2351,
      "step": 4000
    },
    {
      "epoch": 0.7076438480291687,
      "grad_norm": 1.6837409734725952,
      "learning_rate": 2.710416666666667e-05,
      "loss": 0.2522,
      "step": 4100
    },
    {
      "epoch": 0.7249034540786606,
      "grad_norm": 1.4674609899520874,
      "learning_rate": 2.6409722222222223e-05,
      "loss": 0.2348,
      "step": 4200
    },
    {
      "epoch": 0.7421630601281526,
      "grad_norm": 1.7897930145263672,
      "learning_rate": 2.571527777777778e-05,
      "loss": 0.2375,
      "step": 4300
    },
    {
      "epoch": 0.7594226661776445,
      "grad_norm": 2.629936456680298,
      "learning_rate": 2.5020833333333333e-05,
      "loss": 0.2278,
      "step": 4400
    },
    {
      "epoch": 0.7766822722271364,
      "grad_norm": 1.5742340087890625,
      "learning_rate": 2.432638888888889e-05,
      "loss": 0.2439,
      "step": 4500
    },
    {
      "epoch": 0.7939418782766283,
      "grad_norm": 3.635479211807251,
      "learning_rate": 2.3631944444444446e-05,
      "loss": 0.2279,
      "step": 4600
    },
    {
      "epoch": 0.8112014843261203,
      "grad_norm": 1.6627088785171509,
      "learning_rate": 2.2937500000000002e-05,
      "loss": 0.2291,
      "step": 4700
    },
    {
      "epoch": 0.8284610903756122,
      "grad_norm": 1.9720983505249023,
      "learning_rate": 2.2243055555555555e-05,
      "loss": 0.231,
      "step": 4800
    },
    {
      "epoch": 0.8457206964251041,
      "grad_norm": 2.0553252696990967,
      "learning_rate": 2.154861111111111e-05,
      "loss": 0.2208,
      "step": 4900
    },
    {
      "epoch": 0.862980302474596,
      "grad_norm": 3.197796583175659,
      "learning_rate": 2.0854166666666668e-05,
      "loss": 0.2225,
      "step": 5000
    },
    {
      "epoch": 0.880239908524088,
      "grad_norm": 1.8684355020523071,
      "learning_rate": 2.0159722222222224e-05,
      "loss": 0.2207,
      "step": 5100
    },
    {
      "epoch": 0.8974995145735799,
      "grad_norm": 1.3667787313461304,
      "learning_rate": 1.946527777777778e-05,
      "loss": 0.2133,
      "step": 5200
    },
    {
      "epoch": 0.9147591206230717,
      "grad_norm": 1.6907380819320679,
      "learning_rate": 1.8770833333333333e-05,
      "loss": 0.2186,
      "step": 5300
    },
    {
      "epoch": 0.9320187266725637,
      "grad_norm": 2.4099488258361816,
      "learning_rate": 1.807638888888889e-05,
      "loss": 0.2117,
      "step": 5400
    },
    {
      "epoch": 0.9492783327220556,
      "grad_norm": 1.5732520818710327,
      "learning_rate": 1.7381944444444446e-05,
      "loss": 0.2181,
      "step": 5500
    },
    {
      "epoch": 0.9665379387715476,
      "grad_norm": 2.557965040206909,
      "learning_rate": 1.66875e-05,
      "loss": 0.2062,
      "step": 5600
    },
    {
      "epoch": 0.9837975448210394,
      "grad_norm": 2.4390716552734375,
      "learning_rate": 1.5993055555555555e-05,
      "loss": 0.1965,
      "step": 5700
    },
    {
      "epoch": 1.0010571508705315,
      "grad_norm": 1.6804862022399902,
      "learning_rate": 1.5298611111111112e-05,
      "loss": 0.2017,
      "step": 5800
    },
    {
      "epoch": 1.0183167569200233,
      "grad_norm": 1.9688812494277954,
      "learning_rate": 1.4604166666666666e-05,
      "loss": 0.205,
      "step": 5900
    },
    {
      "epoch": 1.0355763629695152,
      "grad_norm": 1.660875678062439,
      "learning_rate": 1.3909722222222225e-05,
      "loss": 0.1695,
      "step": 6000
    },
    {
      "epoch": 1.0528359690190072,
      "grad_norm": 1.792632818222046,
      "learning_rate": 1.321527777777778e-05,
      "loss": 0.1572,
      "step": 6100
    },
    {
      "epoch": 1.070095575068499,
      "grad_norm": 1.341719627380371,
      "learning_rate": 1.2520833333333334e-05,
      "loss": 0.1422,
      "step": 6200
    },
    {
      "epoch": 1.087355181117991,
      "grad_norm": 2.189462184906006,
      "learning_rate": 1.182638888888889e-05,
      "loss": 0.1293,
      "step": 6300
    },
    {
      "epoch": 1.104614787167483,
      "grad_norm": 1.8638803958892822,
      "learning_rate": 1.1131944444444445e-05,
      "loss": 0.1263,
      "step": 6400
    },
    {
      "epoch": 1.1218743932169748,
      "grad_norm": 1.5216566324234009,
      "learning_rate": 1.04375e-05,
      "loss": 0.1209,
      "step": 6500
    },
    {
      "epoch": 1.1391339992664666,
      "grad_norm": 1.5216431617736816,
      "learning_rate": 9.743055555555556e-06,
      "loss": 0.1263,
      "step": 6600
    },
    {
      "epoch": 1.1563936053159587,
      "grad_norm": 1.6114089488983154,
      "learning_rate": 9.048611111111112e-06,
      "loss": 0.1184,
      "step": 6700
    },
    {
      "epoch": 1.1736532113654505,
      "grad_norm": 1.1547915935516357,
      "learning_rate": 8.354166666666667e-06,
      "loss": 0.1095,
      "step": 6800
    },
    {
      "epoch": 1.1909128174149426,
      "grad_norm": 1.60653817653656,
      "learning_rate": 7.659722222222222e-06,
      "loss": 0.109,
      "step": 6900
    },
    {
      "epoch": 1.2081724234644344,
      "grad_norm": 1.2703273296356201,
      "learning_rate": 6.965277777777777e-06,
      "loss": 0.1156,
      "step": 7000
    },
    {
      "epoch": 1.2254320295139263,
      "grad_norm": 1.0045329332351685,
      "learning_rate": 6.270833333333334e-06,
      "loss": 0.1102,
      "step": 7100
    },
    {
      "epoch": 1.2426916355634183,
      "grad_norm": 1.0901542901992798,
      "learning_rate": 5.576388888888889e-06,
      "loss": 0.1134,
      "step": 7200
    },
    {
      "epoch": 1.2599512416129102,
      "grad_norm": 1.2042514085769653,
      "learning_rate": 4.881944444444445e-06,
      "loss": 0.1053,
      "step": 7300
    },
    {
      "epoch": 1.2772108476624022,
      "grad_norm": 1.4351383447647095,
      "learning_rate": 4.1875e-06,
      "loss": 0.102,
      "step": 7400
    },
    {
      "epoch": 1.294470453711894,
      "grad_norm": 0.8025763630867004,
      "learning_rate": 3.4930555555555557e-06,
      "loss": 0.0976,
      "step": 7500
    },
    {
      "epoch": 1.311730059761386,
      "grad_norm": 1.1999183893203735,
      "learning_rate": 2.798611111111111e-06,
      "loss": 0.0952,
      "step": 7600
    },
    {
      "epoch": 1.328989665810878,
      "grad_norm": 1.2386870384216309,
      "learning_rate": 2.1041666666666667e-06,
      "loss": 0.0969,
      "step": 7700
    },
    {
      "epoch": 1.3462492718603698,
      "grad_norm": 1.1571041345596313,
      "learning_rate": 1.4097222222222224e-06,
      "loss": 0.0963,
      "step": 7800
    },
    {
      "epoch": 1.3635088779098616,
      "grad_norm": 1.0073320865631104,
      "learning_rate": 7.152777777777779e-07,
      "loss": 0.1065,
      "step": 7900
    },
    {
      "epoch": 1.3807684839593537,
      "grad_norm": 1.621455192565918,
      "learning_rate": 2.0833333333333335e-08,
      "loss": 0.0954,
      "step": 8000
    }
  ],
  "logging_steps": 100,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.435275349827584e+20,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
