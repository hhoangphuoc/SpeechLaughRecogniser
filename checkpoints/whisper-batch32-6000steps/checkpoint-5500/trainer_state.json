{
  "best_metric": 0.16951326278280368,
  "best_model_checkpoint": "../checkpoints/whisper-batch32-6000steps/checkpoint-1500",
  "epoch": 1.8985157059026578,
  "eval_steps": 500,
  "global_step": 5500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03451846738004832,
      "grad_norm": 2.5743868350982666,
      "learning_rate": 6e-06,
      "loss": 2.1536,
      "step": 100
    },
    {
      "epoch": 0.06903693476009665,
      "grad_norm": 2.110031843185425,
      "learning_rate": 1.225e-05,
      "loss": 0.2098,
      "step": 200
    },
    {
      "epoch": 0.10355540214014498,
      "grad_norm": 1.608992576599121,
      "learning_rate": 1.85e-05,
      "loss": 0.2052,
      "step": 300
    },
    {
      "epoch": 0.1380738695201933,
      "grad_norm": 1.8342584371566772,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.2135,
      "step": 400
    },
    {
      "epoch": 0.17259233690024162,
      "grad_norm": 2.705549955368042,
      "learning_rate": 3.1e-05,
      "loss": 0.2185,
      "step": 500
    },
    {
      "epoch": 0.20711080428028997,
      "grad_norm": 1.629492163658142,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.2302,
      "step": 600
    },
    {
      "epoch": 0.2416292716603383,
      "grad_norm": 1.6918648481369019,
      "learning_rate": 4.35e-05,
      "loss": 0.2483,
      "step": 700
    },
    {
      "epoch": 0.2761477390403866,
      "grad_norm": 2.0234973430633545,
      "learning_rate": 4.975e-05,
      "loss": 0.2484,
      "step": 800
    },
    {
      "epoch": 0.3106662064204349,
      "grad_norm": 2.507228136062622,
      "learning_rate": 4.907692307692308e-05,
      "loss": 0.2605,
      "step": 900
    },
    {
      "epoch": 0.34518467380048323,
      "grad_norm": 1.511030673980713,
      "learning_rate": 4.8115384615384615e-05,
      "loss": 0.2584,
      "step": 1000
    },
    {
      "epoch": 0.3797031411805316,
      "grad_norm": 1.221958041191101,
      "learning_rate": 4.7153846153846155e-05,
      "loss": 0.2583,
      "step": 1100
    },
    {
      "epoch": 0.41422160856057993,
      "grad_norm": 1.7782516479492188,
      "learning_rate": 4.6192307692307696e-05,
      "loss": 0.2545,
      "step": 1200
    },
    {
      "epoch": 0.44874007594062826,
      "grad_norm": 2.3451573848724365,
      "learning_rate": 4.523076923076923e-05,
      "loss": 0.2471,
      "step": 1300
    },
    {
      "epoch": 0.4832585433206766,
      "grad_norm": 1.8684217929840088,
      "learning_rate": 4.426923076923078e-05,
      "loss": 0.2415,
      "step": 1400
    },
    {
      "epoch": 0.5177770107007249,
      "grad_norm": 1.54874849319458,
      "learning_rate": 4.330769230769231e-05,
      "loss": 0.252,
      "step": 1500
    },
    {
      "epoch": 0.5522954780807732,
      "grad_norm": 1.398486852645874,
      "learning_rate": 4.2346153846153845e-05,
      "loss": 0.2462,
      "step": 1600
    },
    {
      "epoch": 0.5868139454608216,
      "grad_norm": 1.6529643535614014,
      "learning_rate": 4.1384615384615386e-05,
      "loss": 0.2395,
      "step": 1700
    },
    {
      "epoch": 0.6213324128408698,
      "grad_norm": 1.378963589668274,
      "learning_rate": 4.0423076923076926e-05,
      "loss": 0.2343,
      "step": 1800
    },
    {
      "epoch": 0.6558508802209182,
      "grad_norm": 1.5553760528564453,
      "learning_rate": 3.946153846153846e-05,
      "loss": 0.2323,
      "step": 1900
    },
    {
      "epoch": 0.6903693476009665,
      "grad_norm": 1.5038799047470093,
      "learning_rate": 3.85e-05,
      "loss": 0.2264,
      "step": 2000
    },
    {
      "epoch": 0.7248878149810148,
      "grad_norm": 1.3994282484054565,
      "learning_rate": 3.753846153846154e-05,
      "loss": 0.2286,
      "step": 2100
    },
    {
      "epoch": 0.7594062823610632,
      "grad_norm": 1.4176756143569946,
      "learning_rate": 3.657692307692308e-05,
      "loss": 0.2279,
      "step": 2200
    },
    {
      "epoch": 0.7939247497411115,
      "grad_norm": 1.3050110340118408,
      "learning_rate": 3.5615384615384616e-05,
      "loss": 0.2255,
      "step": 2300
    },
    {
      "epoch": 0.8284432171211599,
      "grad_norm": 1.4603703022003174,
      "learning_rate": 3.4653846153846156e-05,
      "loss": 0.2255,
      "step": 2400
    },
    {
      "epoch": 0.8629616845012081,
      "grad_norm": 1.2169369459152222,
      "learning_rate": 3.36923076923077e-05,
      "loss": 0.218,
      "step": 2500
    },
    {
      "epoch": 0.8974801518812565,
      "grad_norm": 1.3849509954452515,
      "learning_rate": 3.273076923076923e-05,
      "loss": 0.2174,
      "step": 2600
    },
    {
      "epoch": 0.9319986192613048,
      "grad_norm": 1.5467993021011353,
      "learning_rate": 3.176923076923077e-05,
      "loss": 0.2152,
      "step": 2700
    },
    {
      "epoch": 0.9665170866413532,
      "grad_norm": 1.2722877264022827,
      "learning_rate": 3.080769230769231e-05,
      "loss": 0.2157,
      "step": 2800
    },
    {
      "epoch": 1.0010355540214015,
      "grad_norm": 1.2330670356750488,
      "learning_rate": 2.9846153846153846e-05,
      "loss": 0.2051,
      "step": 2900
    },
    {
      "epoch": 1.0355540214014498,
      "grad_norm": 1.2105422019958496,
      "learning_rate": 2.8884615384615387e-05,
      "loss": 0.2031,
      "step": 3000
    },
    {
      "epoch": 1.070072488781498,
      "grad_norm": 1.4594160318374634,
      "learning_rate": 2.7923076923076924e-05,
      "loss": 0.181,
      "step": 3100
    },
    {
      "epoch": 1.1045909561615463,
      "grad_norm": 1.2272857427597046,
      "learning_rate": 2.696153846153846e-05,
      "loss": 0.1634,
      "step": 3200
    },
    {
      "epoch": 1.1391094235415948,
      "grad_norm": 1.0714088678359985,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.1532,
      "step": 3300
    },
    {
      "epoch": 1.173627890921643,
      "grad_norm": 1.1330043077468872,
      "learning_rate": 2.503846153846154e-05,
      "loss": 0.1391,
      "step": 3400
    },
    {
      "epoch": 1.2081463583016914,
      "grad_norm": 1.0115348100662231,
      "learning_rate": 2.4076923076923076e-05,
      "loss": 0.1308,
      "step": 3500
    },
    {
      "epoch": 1.2426648256817396,
      "grad_norm": 0.7866087555885315,
      "learning_rate": 2.3115384615384617e-05,
      "loss": 0.1219,
      "step": 3600
    },
    {
      "epoch": 1.2771832930617881,
      "grad_norm": 0.8968396186828613,
      "learning_rate": 2.2153846153846154e-05,
      "loss": 0.1161,
      "step": 3700
    },
    {
      "epoch": 1.3117017604418364,
      "grad_norm": 0.998329222202301,
      "learning_rate": 2.1192307692307695e-05,
      "loss": 0.1133,
      "step": 3800
    },
    {
      "epoch": 1.3462202278218847,
      "grad_norm": 0.9511522054672241,
      "learning_rate": 2.0230769230769232e-05,
      "loss": 0.1115,
      "step": 3900
    },
    {
      "epoch": 1.380738695201933,
      "grad_norm": 0.8928653597831726,
      "learning_rate": 1.926923076923077e-05,
      "loss": 0.1119,
      "step": 4000
    },
    {
      "epoch": 1.4152571625819814,
      "grad_norm": 0.9201973676681519,
      "learning_rate": 1.830769230769231e-05,
      "loss": 0.106,
      "step": 4100
    },
    {
      "epoch": 1.4497756299620297,
      "grad_norm": 0.9495989084243774,
      "learning_rate": 1.7346153846153847e-05,
      "loss": 0.107,
      "step": 4200
    },
    {
      "epoch": 1.484294097342078,
      "grad_norm": 0.7613958716392517,
      "learning_rate": 1.6384615384615384e-05,
      "loss": 0.1014,
      "step": 4300
    },
    {
      "epoch": 1.5188125647221264,
      "grad_norm": 0.7141531705856323,
      "learning_rate": 1.5423076923076925e-05,
      "loss": 0.1068,
      "step": 4400
    },
    {
      "epoch": 1.5533310321021747,
      "grad_norm": 0.8428189158439636,
      "learning_rate": 1.4461538461538462e-05,
      "loss": 0.1003,
      "step": 4500
    },
    {
      "epoch": 1.587849499482223,
      "grad_norm": 1.1461315155029297,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0993,
      "step": 4600
    },
    {
      "epoch": 1.6223679668622712,
      "grad_norm": 0.9790162444114685,
      "learning_rate": 1.2538461538461538e-05,
      "loss": 0.0913,
      "step": 4700
    },
    {
      "epoch": 1.6568864342423195,
      "grad_norm": 0.67188560962677,
      "learning_rate": 1.1576923076923077e-05,
      "loss": 0.0926,
      "step": 4800
    },
    {
      "epoch": 1.691404901622368,
      "grad_norm": 0.6974127888679504,
      "learning_rate": 1.0615384615384616e-05,
      "loss": 0.0898,
      "step": 4900
    },
    {
      "epoch": 1.7259233690024163,
      "grad_norm": 0.6334595680236816,
      "learning_rate": 9.653846153846155e-06,
      "loss": 0.089,
      "step": 5000
    },
    {
      "epoch": 1.7604418363824648,
      "grad_norm": 0.9779647588729858,
      "learning_rate": 8.692307692307692e-06,
      "loss": 0.0894,
      "step": 5100
    },
    {
      "epoch": 1.794960303762513,
      "grad_norm": 0.7252787947654724,
      "learning_rate": 7.730769230769231e-06,
      "loss": 0.0888,
      "step": 5200
    },
    {
      "epoch": 1.8294787711425613,
      "grad_norm": 0.6900699138641357,
      "learning_rate": 6.7692307692307695e-06,
      "loss": 0.0893,
      "step": 5300
    },
    {
      "epoch": 1.8639972385226096,
      "grad_norm": 0.7137700915336609,
      "learning_rate": 5.807692307692308e-06,
      "loss": 0.0879,
      "step": 5400
    },
    {
      "epoch": 1.8985157059026578,
      "grad_norm": 0.7830414772033691,
      "learning_rate": 4.846153846153846e-06,
      "loss": 0.0883,
      "step": 5500
    }
  ],
  "logging_steps": 100,
  "max_steps": 6000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.473434602954752e+20,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
