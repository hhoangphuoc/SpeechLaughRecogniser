{
  "best_metric": 0.19367349132965733,
  "best_model_checkpoint": "../checkpoints/whisper-train16-eval8-6000steps-lr5/checkpoint-1000",
  "epoch": 4.142216085605799,
  "eval_steps": 1000,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06903693476009665,
      "grad_norm": 2.0645041465759277,
      "learning_rate": 4.800000000000001e-06,
      "loss": 2.2629,
      "step": 100
    },
    {
      "epoch": 0.1380738695201933,
      "grad_norm": 1.3836926221847534,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.1986,
      "step": 200
    },
    {
      "epoch": 0.20711080428028997,
      "grad_norm": 1.1851500272750854,
      "learning_rate": 1.48e-05,
      "loss": 0.1876,
      "step": 300
    },
    {
      "epoch": 0.2761477390403866,
      "grad_norm": 1.1789189577102661,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.1889,
      "step": 400
    },
    {
      "epoch": 0.34518467380048323,
      "grad_norm": 2.7897682189941406,
      "learning_rate": 2.48e-05,
      "loss": 0.19,
      "step": 500
    },
    {
      "epoch": 0.41422160856057993,
      "grad_norm": 1.2780295610427856,
      "learning_rate": 2.98e-05,
      "loss": 0.1979,
      "step": 600
    },
    {
      "epoch": 0.4832585433206766,
      "grad_norm": 1.2842440605163574,
      "learning_rate": 3.48e-05,
      "loss": 0.1956,
      "step": 700
    },
    {
      "epoch": 0.5522954780807732,
      "grad_norm": 1.2031543254852295,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.2088,
      "step": 800
    },
    {
      "epoch": 0.6213324128408698,
      "grad_norm": 1.2100837230682373,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.21,
      "step": 900
    },
    {
      "epoch": 0.6903693476009665,
      "grad_norm": 1.1325011253356934,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.2132,
      "step": 1000
    },
    {
      "epoch": 0.7594062823610632,
      "grad_norm": 1.2611006498336792,
      "learning_rate": 4.9040000000000005e-05,
      "loss": 0.2208,
      "step": 1100
    },
    {
      "epoch": 0.8284432171211599,
      "grad_norm": 1.155889868736267,
      "learning_rate": 4.804e-05,
      "loss": 0.2196,
      "step": 1200
    },
    {
      "epoch": 0.8974801518812565,
      "grad_norm": 1.3043482303619385,
      "learning_rate": 4.7040000000000004e-05,
      "loss": 0.2174,
      "step": 1300
    },
    {
      "epoch": 0.9665170866413532,
      "grad_norm": 1.0833169221878052,
      "learning_rate": 4.604e-05,
      "loss": 0.2165,
      "step": 1400
    },
    {
      "epoch": 1.0355540214014498,
      "grad_norm": 0.9483165144920349,
      "learning_rate": 4.504e-05,
      "loss": 0.2109,
      "step": 1500
    },
    {
      "epoch": 1.1045909561615463,
      "grad_norm": 1.0166641473770142,
      "learning_rate": 4.4040000000000005e-05,
      "loss": 0.1977,
      "step": 1600
    },
    {
      "epoch": 1.173627890921643,
      "grad_norm": 1.017189860343933,
      "learning_rate": 4.304e-05,
      "loss": 0.184,
      "step": 1700
    },
    {
      "epoch": 1.2426648256817396,
      "grad_norm": 0.8093430399894714,
      "learning_rate": 4.2040000000000004e-05,
      "loss": 0.1694,
      "step": 1800
    },
    {
      "epoch": 1.3117017604418364,
      "grad_norm": 0.9088922739028931,
      "learning_rate": 4.104e-05,
      "loss": 0.1547,
      "step": 1900
    },
    {
      "epoch": 1.380738695201933,
      "grad_norm": 1.122426152229309,
      "learning_rate": 4.004e-05,
      "loss": 0.1446,
      "step": 2000
    },
    {
      "epoch": 1.4497756299620297,
      "grad_norm": 0.9207291603088379,
      "learning_rate": 3.9040000000000006e-05,
      "loss": 0.1341,
      "step": 2100
    },
    {
      "epoch": 1.5188125647221264,
      "grad_norm": 0.9114145040512085,
      "learning_rate": 3.804e-05,
      "loss": 0.1288,
      "step": 2200
    },
    {
      "epoch": 1.587849499482223,
      "grad_norm": 0.9968510866165161,
      "learning_rate": 3.7040000000000005e-05,
      "loss": 0.121,
      "step": 2300
    },
    {
      "epoch": 1.6568864342423195,
      "grad_norm": 0.7197475433349609,
      "learning_rate": 3.604e-05,
      "loss": 0.1145,
      "step": 2400
    },
    {
      "epoch": 1.7259233690024163,
      "grad_norm": 0.784116268157959,
      "learning_rate": 3.504e-05,
      "loss": 0.1101,
      "step": 2500
    },
    {
      "epoch": 1.794960303762513,
      "grad_norm": 0.7010970711708069,
      "learning_rate": 3.404e-05,
      "loss": 0.1099,
      "step": 2600
    },
    {
      "epoch": 1.8639972385226096,
      "grad_norm": 0.7470280528068542,
      "learning_rate": 3.304e-05,
      "loss": 0.1098,
      "step": 2700
    },
    {
      "epoch": 1.933034173282706,
      "grad_norm": 0.6367002725601196,
      "learning_rate": 3.2040000000000005e-05,
      "loss": 0.1071,
      "step": 2800
    },
    {
      "epoch": 2.002071108042803,
      "grad_norm": 0.8918009996414185,
      "learning_rate": 3.104e-05,
      "loss": 0.1051,
      "step": 2900
    },
    {
      "epoch": 2.0711080428028996,
      "grad_norm": 0.8463010787963867,
      "learning_rate": 3.004e-05,
      "loss": 0.1041,
      "step": 3000
    },
    {
      "epoch": 2.140144977562996,
      "grad_norm": 0.7038804292678833,
      "learning_rate": 2.904e-05,
      "loss": 0.0951,
      "step": 3100
    },
    {
      "epoch": 2.2091819123230927,
      "grad_norm": 0.6538951992988586,
      "learning_rate": 2.804e-05,
      "loss": 0.0862,
      "step": 3200
    },
    {
      "epoch": 2.2782188470831897,
      "grad_norm": 0.684779942035675,
      "learning_rate": 2.704e-05,
      "loss": 0.0812,
      "step": 3300
    },
    {
      "epoch": 2.347255781843286,
      "grad_norm": 0.6743175387382507,
      "learning_rate": 2.6040000000000005e-05,
      "loss": 0.0757,
      "step": 3400
    },
    {
      "epoch": 2.4162927166033827,
      "grad_norm": 0.7858531475067139,
      "learning_rate": 2.504e-05,
      "loss": 0.0719,
      "step": 3500
    },
    {
      "epoch": 2.4853296513634793,
      "grad_norm": 1.114006519317627,
      "learning_rate": 2.404e-05,
      "loss": 0.0689,
      "step": 3600
    },
    {
      "epoch": 2.5543665861235763,
      "grad_norm": 0.639069139957428,
      "learning_rate": 2.304e-05,
      "loss": 0.0675,
      "step": 3700
    },
    {
      "epoch": 2.623403520883673,
      "grad_norm": 0.6717188954353333,
      "learning_rate": 2.2040000000000002e-05,
      "loss": 0.0592,
      "step": 3800
    },
    {
      "epoch": 2.6924404556437693,
      "grad_norm": 0.5587978363037109,
      "learning_rate": 2.1040000000000002e-05,
      "loss": 0.0555,
      "step": 3900
    },
    {
      "epoch": 2.761477390403866,
      "grad_norm": 0.664663553237915,
      "learning_rate": 2.004e-05,
      "loss": 0.0559,
      "step": 4000
    },
    {
      "epoch": 2.830514325163963,
      "grad_norm": 0.5419431924819946,
      "learning_rate": 1.904e-05,
      "loss": 0.0548,
      "step": 4100
    },
    {
      "epoch": 2.8995512599240594,
      "grad_norm": 0.6738277673721313,
      "learning_rate": 1.804e-05,
      "loss": 0.0546,
      "step": 4200
    },
    {
      "epoch": 2.968588194684156,
      "grad_norm": 0.6247120499610901,
      "learning_rate": 1.704e-05,
      "loss": 0.0531,
      "step": 4300
    },
    {
      "epoch": 3.037625129444253,
      "grad_norm": 0.5363003611564636,
      "learning_rate": 1.604e-05,
      "loss": 0.0504,
      "step": 4400
    },
    {
      "epoch": 3.1066620642043494,
      "grad_norm": 0.6076511740684509,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 0.0482,
      "step": 4500
    },
    {
      "epoch": 3.175698998964446,
      "grad_norm": 0.4347473084926605,
      "learning_rate": 1.4040000000000001e-05,
      "loss": 0.0434,
      "step": 4600
    },
    {
      "epoch": 3.2447359337245425,
      "grad_norm": 0.6465114951133728,
      "learning_rate": 1.3039999999999999e-05,
      "loss": 0.0399,
      "step": 4700
    },
    {
      "epoch": 3.313772868484639,
      "grad_norm": 0.6493310928344727,
      "learning_rate": 1.204e-05,
      "loss": 0.0362,
      "step": 4800
    },
    {
      "epoch": 3.382809803244736,
      "grad_norm": 0.5057406425476074,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.0341,
      "step": 4900
    },
    {
      "epoch": 3.4518467380048325,
      "grad_norm": 0.6191712021827698,
      "learning_rate": 1.004e-05,
      "loss": 0.0324,
      "step": 5000
    },
    {
      "epoch": 3.520883672764929,
      "grad_norm": 0.5152069330215454,
      "learning_rate": 9.04e-06,
      "loss": 0.0307,
      "step": 5100
    },
    {
      "epoch": 3.589920607525026,
      "grad_norm": 0.3998388648033142,
      "learning_rate": 8.040000000000001e-06,
      "loss": 0.0273,
      "step": 5200
    },
    {
      "epoch": 3.6589575422851226,
      "grad_norm": 0.42051589488983154,
      "learning_rate": 7.04e-06,
      "loss": 0.0259,
      "step": 5300
    },
    {
      "epoch": 3.727994477045219,
      "grad_norm": 0.43987008929252625,
      "learning_rate": 6.040000000000001e-06,
      "loss": 0.0241,
      "step": 5400
    },
    {
      "epoch": 3.7970314118053157,
      "grad_norm": 0.38180744647979736,
      "learning_rate": 5.04e-06,
      "loss": 0.0249,
      "step": 5500
    },
    {
      "epoch": 3.8660683465654127,
      "grad_norm": 0.3922935426235199,
      "learning_rate": 4.04e-06,
      "loss": 0.0226,
      "step": 5600
    },
    {
      "epoch": 3.935105281325509,
      "grad_norm": 0.3698864281177521,
      "learning_rate": 3.04e-06,
      "loss": 0.0238,
      "step": 5700
    },
    {
      "epoch": 4.004142216085606,
      "grad_norm": 0.3865646719932556,
      "learning_rate": 2.0400000000000004e-06,
      "loss": 0.0222,
      "step": 5800
    },
    {
      "epoch": 4.073179150845703,
      "grad_norm": 0.3002200126647949,
      "learning_rate": 1.04e-06,
      "loss": 0.0216,
      "step": 5900
    },
    {
      "epoch": 4.142216085605799,
      "grad_norm": 0.2812363803386688,
      "learning_rate": 4e-08,
      "loss": 0.0193,
      "step": 6000
    }
  ],
  "logging_steps": 100,
  "max_steps": 6000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6305443878699008e+21,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
