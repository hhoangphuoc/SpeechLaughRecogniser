{
  "best_metric": 0.29422247409820557,
  "best_model_checkpoint": "../checkpoints/wav2vec2-batch32-nolaugh/checkpoint-18900",
  "epoch": 6.7033161908139745,
  "eval_steps": 100,
  "global_step": 18900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017733640716439084,
      "grad_norm": 23.95083999633789,
      "learning_rate": 1.667257892869812e-06,
      "loss": 27.9539,
      "step": 50
    },
    {
      "epoch": 0.03546728143287817,
      "grad_norm": 24.666011810302734,
      "learning_rate": 3.4409365023057827e-06,
      "loss": 27.9724,
      "step": 100
    },
    {
      "epoch": 0.03546728143287817,
      "eval_loss": 28.43083953857422,
      "eval_runtime": 783.8575,
      "eval_samples_per_second": 25.512,
      "eval_steps_per_second": 3.189,
      "eval_wer": 1.0014772819558904,
      "step": 100
    },
    {
      "epoch": 0.05320092214931726,
      "grad_norm": 37.37860107421875,
      "learning_rate": 5.214615111741752e-06,
      "loss": 27.1685,
      "step": 150
    },
    {
      "epoch": 0.07093456286575633,
      "grad_norm": 36.913665771484375,
      "learning_rate": 6.988293721177723e-06,
      "loss": 23.9494,
      "step": 200
    },
    {
      "epoch": 0.07093456286575633,
      "eval_loss": 22.34526252746582,
      "eval_runtime": 761.556,
      "eval_samples_per_second": 26.259,
      "eval_steps_per_second": 3.283,
      "eval_wer": 1.0,
      "step": 200
    },
    {
      "epoch": 0.08866820358219542,
      "grad_norm": 54.335906982421875,
      "learning_rate": 8.726498758424974e-06,
      "loss": 20.6307,
      "step": 250
    },
    {
      "epoch": 0.10640184429863452,
      "grad_norm": 66.89305877685547,
      "learning_rate": 1.0500177367860944e-05,
      "loss": 16.5225,
      "step": 300
    },
    {
      "epoch": 0.10640184429863452,
      "eval_loss": 13.945759773254395,
      "eval_runtime": 767.2619,
      "eval_samples_per_second": 26.064,
      "eval_steps_per_second": 3.258,
      "eval_wer": 1.0,
      "step": 300
    },
    {
      "epoch": 0.1241354850150736,
      "grad_norm": 79.86573028564453,
      "learning_rate": 1.2238382405108195e-05,
      "loss": 14.0005,
      "step": 350
    },
    {
      "epoch": 0.14186912573151267,
      "grad_norm": 79.004150390625,
      "learning_rate": 1.4012061014544165e-05,
      "loss": 11.6738,
      "step": 400
    },
    {
      "epoch": 0.14186912573151267,
      "eval_loss": 9.464426040649414,
      "eval_runtime": 767.2608,
      "eval_samples_per_second": 26.064,
      "eval_steps_per_second": 3.258,
      "eval_wer": 1.0,
      "step": 400
    },
    {
      "epoch": 0.15960276644795177,
      "grad_norm": 67.80107879638672,
      "learning_rate": 1.5785739623980136e-05,
      "loss": 9.7046,
      "step": 450
    },
    {
      "epoch": 0.17733640716439084,
      "grad_norm": 62.342472076416016,
      "learning_rate": 1.7559418233416106e-05,
      "loss": 8.4093,
      "step": 500
    },
    {
      "epoch": 0.17733640716439084,
      "eval_loss": 6.848560810089111,
      "eval_runtime": 782.3342,
      "eval_samples_per_second": 25.562,
      "eval_steps_per_second": 3.196,
      "eval_wer": 1.0,
      "step": 500
    },
    {
      "epoch": 0.19507004788082993,
      "grad_norm": 47.58521270751953,
      "learning_rate": 1.9333096842852076e-05,
      "loss": 7.0326,
      "step": 550
    },
    {
      "epoch": 0.21280368859726903,
      "grad_norm": 42.3264274597168,
      "learning_rate": 2.1106775452288046e-05,
      "loss": 6.104,
      "step": 600
    },
    {
      "epoch": 0.21280368859726903,
      "eval_loss": 5.183044910430908,
      "eval_runtime": 785.0656,
      "eval_samples_per_second": 25.473,
      "eval_steps_per_second": 3.184,
      "eval_wer": 1.0,
      "step": 600
    },
    {
      "epoch": 0.2305373293137081,
      "grad_norm": 35.20352554321289,
      "learning_rate": 2.2880454061724016e-05,
      "loss": 5.1235,
      "step": 650
    },
    {
      "epoch": 0.2482709700301472,
      "grad_norm": 25.26593589782715,
      "learning_rate": 2.465413267115999e-05,
      "loss": 4.7345,
      "step": 700
    },
    {
      "epoch": 0.2482709700301472,
      "eval_loss": 4.18607234954834,
      "eval_runtime": 762.2133,
      "eval_samples_per_second": 26.237,
      "eval_steps_per_second": 3.28,
      "eval_wer": 1.0,
      "step": 700
    },
    {
      "epoch": 0.26600461074658627,
      "grad_norm": 18.205894470214844,
      "learning_rate": 2.642781128059596e-05,
      "loss": 4.2797,
      "step": 750
    },
    {
      "epoch": 0.28373825146302534,
      "grad_norm": 15.449374198913574,
      "learning_rate": 2.820148989003193e-05,
      "loss": 3.9925,
      "step": 800
    },
    {
      "epoch": 0.28373825146302534,
      "eval_loss": 3.7530510425567627,
      "eval_runtime": 752.0811,
      "eval_samples_per_second": 26.59,
      "eval_steps_per_second": 3.324,
      "eval_wer": 1.0,
      "step": 800
    },
    {
      "epoch": 0.30147189217946446,
      "grad_norm": 11.167086601257324,
      "learning_rate": 2.99751684994679e-05,
      "loss": 3.8059,
      "step": 850
    },
    {
      "epoch": 0.31920553289590353,
      "grad_norm": 7.454020023345947,
      "learning_rate": 3.1748847108903865e-05,
      "loss": 3.6692,
      "step": 900
    },
    {
      "epoch": 0.31920553289590353,
      "eval_loss": 3.500732898712158,
      "eval_runtime": 767.2194,
      "eval_samples_per_second": 26.066,
      "eval_steps_per_second": 3.259,
      "eval_wer": 1.0,
      "step": 900
    },
    {
      "epoch": 0.3369391736123426,
      "grad_norm": 5.70574426651001,
      "learning_rate": 3.3522525718339835e-05,
      "loss": 3.4669,
      "step": 950
    },
    {
      "epoch": 0.35467281432878167,
      "grad_norm": 5.552155017852783,
      "learning_rate": 3.529620432777581e-05,
      "loss": 3.3054,
      "step": 1000
    },
    {
      "epoch": 0.35467281432878167,
      "eval_loss": 3.2087552547454834,
      "eval_runtime": 751.6202,
      "eval_samples_per_second": 26.607,
      "eval_steps_per_second": 3.326,
      "eval_wer": 1.0,
      "step": 1000
    },
    {
      "epoch": 0.3724064550452208,
      "grad_norm": 2.708219528198242,
      "learning_rate": 3.706988293721178e-05,
      "loss": 3.1797,
      "step": 1050
    },
    {
      "epoch": 0.39014009576165987,
      "grad_norm": 2.2048916816711426,
      "learning_rate": 3.884356154664775e-05,
      "loss": 3.1039,
      "step": 1100
    },
    {
      "epoch": 0.39014009576165987,
      "eval_loss": 3.104886293411255,
      "eval_runtime": 769.5913,
      "eval_samples_per_second": 25.985,
      "eval_steps_per_second": 3.248,
      "eval_wer": 1.0,
      "step": 1100
    },
    {
      "epoch": 0.40787373647809894,
      "grad_norm": 3.8514297008514404,
      "learning_rate": 4.061724015608372e-05,
      "loss": 3.0271,
      "step": 1150
    },
    {
      "epoch": 0.42560737719453806,
      "grad_norm": 3.766035795211792,
      "learning_rate": 4.239091876551969e-05,
      "loss": 2.9737,
      "step": 1200
    },
    {
      "epoch": 0.42560737719453806,
      "eval_loss": 3.0301640033721924,
      "eval_runtime": 771.0927,
      "eval_samples_per_second": 25.935,
      "eval_steps_per_second": 3.242,
      "eval_wer": 1.0,
      "step": 1200
    },
    {
      "epoch": 0.44334101791097713,
      "grad_norm": 2.5911362171173096,
      "learning_rate": 4.416459737495566e-05,
      "loss": 2.996,
      "step": 1250
    },
    {
      "epoch": 0.4610746586274162,
      "grad_norm": 3.0152359008789062,
      "learning_rate": 4.593827598439163e-05,
      "loss": 2.952,
      "step": 1300
    },
    {
      "epoch": 0.4610746586274162,
      "eval_loss": 2.9361765384674072,
      "eval_runtime": 766.8071,
      "eval_samples_per_second": 26.08,
      "eval_steps_per_second": 3.26,
      "eval_wer": 1.0,
      "step": 1300
    },
    {
      "epoch": 0.47880829934385527,
      "grad_norm": 2.292222261428833,
      "learning_rate": 4.77119545938276e-05,
      "loss": 2.9024,
      "step": 1350
    },
    {
      "epoch": 0.4965419400602944,
      "grad_norm": 4.335400581359863,
      "learning_rate": 4.948563320326357e-05,
      "loss": 2.9089,
      "step": 1400
    },
    {
      "epoch": 0.4965419400602944,
      "eval_loss": 2.896233320236206,
      "eval_runtime": 771.3573,
      "eval_samples_per_second": 25.926,
      "eval_steps_per_second": 3.241,
      "eval_wer": 1.0,
      "step": 1400
    },
    {
      "epoch": 0.5142755807767334,
      "grad_norm": 2.0899696350097656,
      "learning_rate": 5.125931181269954e-05,
      "loss": 2.8745,
      "step": 1450
    },
    {
      "epoch": 0.5320092214931725,
      "grad_norm": 3.3657801151275635,
      "learning_rate": 5.303299042213551e-05,
      "loss": 2.8725,
      "step": 1500
    },
    {
      "epoch": 0.5320092214931725,
      "eval_loss": 2.843520402908325,
      "eval_runtime": 767.3799,
      "eval_samples_per_second": 26.06,
      "eval_steps_per_second": 3.258,
      "eval_wer": 1.0,
      "step": 1500
    },
    {
      "epoch": 0.5497428622096117,
      "grad_norm": 3.0383477210998535,
      "learning_rate": 5.480666903157148e-05,
      "loss": 2.8263,
      "step": 1550
    },
    {
      "epoch": 0.5674765029260507,
      "grad_norm": 2.8370449542999268,
      "learning_rate": 5.658034764100745e-05,
      "loss": 2.8321,
      "step": 1600
    },
    {
      "epoch": 0.5674765029260507,
      "eval_loss": 2.786288022994995,
      "eval_runtime": 759.5509,
      "eval_samples_per_second": 26.329,
      "eval_steps_per_second": 3.291,
      "eval_wer": 1.0,
      "step": 1600
    },
    {
      "epoch": 0.5852101436424898,
      "grad_norm": 2.323523759841919,
      "learning_rate": 5.8354026250443426e-05,
      "loss": 2.7712,
      "step": 1650
    },
    {
      "epoch": 0.6029437843589289,
      "grad_norm": 2.525583505630493,
      "learning_rate": 6.0127704859879396e-05,
      "loss": 2.7391,
      "step": 1700
    },
    {
      "epoch": 0.6029437843589289,
      "eval_loss": 2.6644701957702637,
      "eval_runtime": 761.4823,
      "eval_samples_per_second": 26.262,
      "eval_steps_per_second": 3.283,
      "eval_wer": 1.0,
      "step": 1700
    },
    {
      "epoch": 0.6206774250753679,
      "grad_norm": 3.4621825218200684,
      "learning_rate": 6.190138346931537e-05,
      "loss": 2.7101,
      "step": 1750
    },
    {
      "epoch": 0.6384110657918071,
      "grad_norm": 2.641437292098999,
      "learning_rate": 6.367506207875134e-05,
      "loss": 2.6326,
      "step": 1800
    },
    {
      "epoch": 0.6384110657918071,
      "eval_loss": 2.419157028198242,
      "eval_runtime": 769.2639,
      "eval_samples_per_second": 25.996,
      "eval_steps_per_second": 3.25,
      "eval_wer": 1.0,
      "step": 1800
    },
    {
      "epoch": 0.6561447065082462,
      "grad_norm": 2.5013365745544434,
      "learning_rate": 6.54487406881873e-05,
      "loss": 2.4983,
      "step": 1850
    },
    {
      "epoch": 0.6738783472246852,
      "grad_norm": 2.355877161026001,
      "learning_rate": 6.722241929762328e-05,
      "loss": 2.3615,
      "step": 1900
    },
    {
      "epoch": 0.6738783472246852,
      "eval_loss": 2.1085152626037598,
      "eval_runtime": 768.9152,
      "eval_samples_per_second": 26.008,
      "eval_steps_per_second": 3.251,
      "eval_wer": 0.9926754659045645,
      "step": 1900
    },
    {
      "epoch": 0.6916119879411243,
      "grad_norm": 4.6956048011779785,
      "learning_rate": 6.899609790705924e-05,
      "loss": 2.2001,
      "step": 1950
    },
    {
      "epoch": 0.7093456286575633,
      "grad_norm": 2.6020219326019287,
      "learning_rate": 7.076977651649521e-05,
      "loss": 2.0557,
      "step": 2000
    },
    {
      "epoch": 0.7093456286575633,
      "eval_loss": 1.6471420526504517,
      "eval_runtime": 778.9242,
      "eval_samples_per_second": 25.674,
      "eval_steps_per_second": 3.21,
      "eval_wer": 0.9317859256022244,
      "step": 2000
    },
    {
      "epoch": 0.7270792693740025,
      "grad_norm": 4.032384872436523,
      "learning_rate": 7.254345512593118e-05,
      "loss": 1.9091,
      "step": 2050
    },
    {
      "epoch": 0.7448129100904416,
      "grad_norm": 3.0931143760681152,
      "learning_rate": 7.431713373536715e-05,
      "loss": 1.8,
      "step": 2100
    },
    {
      "epoch": 0.7448129100904416,
      "eval_loss": 1.3849599361419678,
      "eval_runtime": 777.8698,
      "eval_samples_per_second": 25.709,
      "eval_steps_per_second": 3.214,
      "eval_wer": 0.7735117931186505,
      "step": 2100
    },
    {
      "epoch": 0.7625465508068806,
      "grad_norm": 2.8559439182281494,
      "learning_rate": 7.609081234480313e-05,
      "loss": 1.7009,
      "step": 2150
    },
    {
      "epoch": 0.7802801915233197,
      "grad_norm": 3.0699572563171387,
      "learning_rate": 7.78644909542391e-05,
      "loss": 1.6012,
      "step": 2200
    },
    {
      "epoch": 0.7802801915233197,
      "eval_loss": 1.1632423400878906,
      "eval_runtime": 775.7916,
      "eval_samples_per_second": 25.778,
      "eval_steps_per_second": 3.223,
      "eval_wer": 0.6524636190314135,
      "step": 2200
    },
    {
      "epoch": 0.7980138322397589,
      "grad_norm": 2.365253210067749,
      "learning_rate": 7.963816956367507e-05,
      "loss": 1.4897,
      "step": 2250
    },
    {
      "epoch": 0.8157474729561979,
      "grad_norm": 4.052362442016602,
      "learning_rate": 8.141184817311103e-05,
      "loss": 1.4402,
      "step": 2300
    },
    {
      "epoch": 0.8157474729561979,
      "eval_loss": 0.9562524557113647,
      "eval_runtime": 774.8415,
      "eval_samples_per_second": 25.809,
      "eval_steps_per_second": 3.226,
      "eval_wer": 0.5115417486841749,
      "step": 2300
    },
    {
      "epoch": 0.833481113672637,
      "grad_norm": 3.5383827686309814,
      "learning_rate": 8.318552678254701e-05,
      "loss": 1.3457,
      "step": 2350
    },
    {
      "epoch": 0.8512147543890761,
      "grad_norm": 5.25838565826416,
      "learning_rate": 8.495920539198297e-05,
      "loss": 1.315,
      "step": 2400
    },
    {
      "epoch": 0.8512147543890761,
      "eval_loss": 0.8331112265586853,
      "eval_runtime": 773.0093,
      "eval_samples_per_second": 25.87,
      "eval_steps_per_second": 3.234,
      "eval_wer": 0.43078237935208424,
      "step": 2400
    },
    {
      "epoch": 0.8689483951055151,
      "grad_norm": 2.5319254398345947,
      "learning_rate": 8.673288400141895e-05,
      "loss": 1.2453,
      "step": 2450
    },
    {
      "epoch": 0.8866820358219543,
      "grad_norm": 2.9524552822113037,
      "learning_rate": 8.850656261085491e-05,
      "loss": 1.2402,
      "step": 2500
    },
    {
      "epoch": 0.8866820358219543,
      "eval_loss": 0.8306432366371155,
      "eval_runtime": 779.4047,
      "eval_samples_per_second": 25.658,
      "eval_steps_per_second": 3.208,
      "eval_wer": 0.38809975907155536,
      "step": 2500
    },
    {
      "epoch": 0.9044156765383934,
      "grad_norm": 3.250450611114502,
      "learning_rate": 9.028024122029089e-05,
      "loss": 1.2433,
      "step": 2550
    },
    {
      "epoch": 0.9221493172548324,
      "grad_norm": 2.472975969314575,
      "learning_rate": 9.205391982972685e-05,
      "loss": 1.2042,
      "step": 2600
    },
    {
      "epoch": 0.9221493172548324,
      "eval_loss": 0.7418017983436584,
      "eval_runtime": 782.4668,
      "eval_samples_per_second": 25.558,
      "eval_steps_per_second": 3.195,
      "eval_wer": 0.3540487967113074,
      "step": 2600
    },
    {
      "epoch": 0.9398829579712715,
      "grad_norm": 2.6259076595306396,
      "learning_rate": 9.382759843916282e-05,
      "loss": 1.1193,
      "step": 2650
    },
    {
      "epoch": 0.9576165986877105,
      "grad_norm": 3.148144245147705,
      "learning_rate": 9.56012770485988e-05,
      "loss": 1.1229,
      "step": 2700
    },
    {
      "epoch": 0.9576165986877105,
      "eval_loss": 0.6974246501922607,
      "eval_runtime": 781.8339,
      "eval_samples_per_second": 25.578,
      "eval_steps_per_second": 3.198,
      "eval_wer": 0.3290819582107099,
      "step": 2700
    },
    {
      "epoch": 0.9753502394041497,
      "grad_norm": 3.642313241958618,
      "learning_rate": 9.737495565803477e-05,
      "loss": 1.0963,
      "step": 2750
    },
    {
      "epoch": 0.9930838801205888,
      "grad_norm": 2.739187240600586,
      "learning_rate": 9.911316069528202e-05,
      "loss": 1.0637,
      "step": 2800
    },
    {
      "epoch": 0.9930838801205888,
      "eval_loss": 0.720339298248291,
      "eval_runtime": 770.9621,
      "eval_samples_per_second": 25.939,
      "eval_steps_per_second": 3.243,
      "eval_wer": 0.3125650178085953,
      "step": 2800
    },
    {
      "epoch": 1.0108175208370278,
      "grad_norm": 1.9232628345489502,
      "learning_rate": 9.990146229947578e-05,
      "loss": 1.0429,
      "step": 2850
    },
    {
      "epoch": 1.0285511615534668,
      "grad_norm": 2.018702507019043,
      "learning_rate": 9.970438689842734e-05,
      "loss": 1.0329,
      "step": 2900
    },
    {
      "epoch": 1.0285511615534668,
      "eval_loss": 0.653114914894104,
      "eval_runtime": 757.4662,
      "eval_samples_per_second": 26.401,
      "eval_steps_per_second": 3.3,
      "eval_wer": 0.2755092175433033,
      "step": 2900
    },
    {
      "epoch": 1.046284802269906,
      "grad_norm": 1.5767022371292114,
      "learning_rate": 9.95073114973789e-05,
      "loss": 1.0486,
      "step": 2950
    },
    {
      "epoch": 1.064018442986345,
      "grad_norm": 3.1512088775634766,
      "learning_rate": 9.931023609633046e-05,
      "loss": 1.0073,
      "step": 3000
    },
    {
      "epoch": 1.064018442986345,
      "eval_loss": 0.7461804151535034,
      "eval_runtime": 772.0895,
      "eval_samples_per_second": 25.901,
      "eval_steps_per_second": 3.238,
      "eval_wer": 0.26638255415089157,
      "step": 3000
    },
    {
      "epoch": 1.081752083702784,
      "grad_norm": 2.893968105316162,
      "learning_rate": 9.911316069528202e-05,
      "loss": 0.9746,
      "step": 3050
    },
    {
      "epoch": 1.0994857244192233,
      "grad_norm": 2.1359283924102783,
      "learning_rate": 9.891608529423358e-05,
      "loss": 1.0389,
      "step": 3100
    },
    {
      "epoch": 1.0994857244192233,
      "eval_loss": 0.6457895636558533,
      "eval_runtime": 767.4618,
      "eval_samples_per_second": 26.057,
      "eval_steps_per_second": 3.257,
      "eval_wer": 0.251455045381947,
      "step": 3100
    },
    {
      "epoch": 1.1172193651356623,
      "grad_norm": 1.9769588708877563,
      "learning_rate": 9.871900989318514e-05,
      "loss": 0.9605,
      "step": 3150
    },
    {
      "epoch": 1.1349530058521013,
      "grad_norm": 2.6982192993164062,
      "learning_rate": 9.85219344921367e-05,
      "loss": 0.9469,
      "step": 3200
    },
    {
      "epoch": 1.1349530058521013,
      "eval_loss": 0.6529061794281006,
      "eval_runtime": 773.3875,
      "eval_samples_per_second": 25.858,
      "eval_steps_per_second": 3.233,
      "eval_wer": 0.23741313234048642,
      "step": 3200
    },
    {
      "epoch": 1.1526866465685406,
      "grad_norm": 2.169027328491211,
      "learning_rate": 9.832485909108826e-05,
      "loss": 0.9068,
      "step": 3250
    },
    {
      "epoch": 1.1704202872849796,
      "grad_norm": 1.4945694208145142,
      "learning_rate": 9.812778369003981e-05,
      "loss": 0.9375,
      "step": 3300
    },
    {
      "epoch": 1.1704202872849796,
      "eval_loss": 0.6547734141349792,
      "eval_runtime": 751.7876,
      "eval_samples_per_second": 26.601,
      "eval_steps_per_second": 3.325,
      "eval_wer": 0.23225037995537215,
      "step": 3300
    },
    {
      "epoch": 1.1881539280014186,
      "grad_norm": 2.924323797225952,
      "learning_rate": 9.793070828899137e-05,
      "loss": 0.9321,
      "step": 3350
    },
    {
      "epoch": 1.2058875687178578,
      "grad_norm": 2.2980690002441406,
      "learning_rate": 9.773363288794293e-05,
      "loss": 0.9567,
      "step": 3400
    },
    {
      "epoch": 1.2058875687178578,
      "eval_loss": 0.6667674779891968,
      "eval_runtime": 761.9768,
      "eval_samples_per_second": 26.245,
      "eval_steps_per_second": 3.281,
      "eval_wer": 0.2191791417069181,
      "step": 3400
    },
    {
      "epoch": 1.2236212094342969,
      "grad_norm": 2.3124594688415527,
      "learning_rate": 9.753655748689448e-05,
      "loss": 0.8942,
      "step": 3450
    },
    {
      "epoch": 1.2413548501507359,
      "grad_norm": 2.3389317989349365,
      "learning_rate": 9.733948208584604e-05,
      "loss": 0.9072,
      "step": 3500
    },
    {
      "epoch": 1.2413548501507359,
      "eval_loss": 0.6449213624000549,
      "eval_runtime": 783.0052,
      "eval_samples_per_second": 25.54,
      "eval_steps_per_second": 3.193,
      "eval_wer": 0.20791389998569124,
      "step": 3500
    },
    {
      "epoch": 1.2590884908671751,
      "grad_norm": 2.254241466522217,
      "learning_rate": 9.71424066847976e-05,
      "loss": 0.8955,
      "step": 3550
    },
    {
      "epoch": 1.2768221315836141,
      "grad_norm": 2.251499891281128,
      "learning_rate": 9.694533128374916e-05,
      "loss": 0.8739,
      "step": 3600
    },
    {
      "epoch": 1.2768221315836141,
      "eval_loss": 0.6093307733535767,
      "eval_runtime": 779.8311,
      "eval_samples_per_second": 25.644,
      "eval_steps_per_second": 3.206,
      "eval_wer": 0.20639794572729064,
      "step": 3600
    },
    {
      "epoch": 1.2945557723000531,
      "grad_norm": 2.0713796615600586,
      "learning_rate": 9.674825588270072e-05,
      "loss": 0.8935,
      "step": 3650
    },
    {
      "epoch": 1.3122894130164924,
      "grad_norm": 1.8775347471237183,
      "learning_rate": 9.655118048165228e-05,
      "loss": 0.8765,
      "step": 3700
    },
    {
      "epoch": 1.3122894130164924,
      "eval_loss": 0.58052659034729,
      "eval_runtime": 796.9393,
      "eval_samples_per_second": 25.094,
      "eval_steps_per_second": 3.137,
      "eval_wer": 0.1952525881438455,
      "step": 3700
    },
    {
      "epoch": 1.3300230537329314,
      "grad_norm": 1.9529900550842285,
      "learning_rate": 9.635410508060384e-05,
      "loss": 0.8675,
      "step": 3750
    },
    {
      "epoch": 1.3477566944493704,
      "grad_norm": 2.091379165649414,
      "learning_rate": 9.61570296795554e-05,
      "loss": 0.9,
      "step": 3800
    },
    {
      "epoch": 1.3477566944493704,
      "eval_loss": 0.5215333104133606,
      "eval_runtime": 768.7883,
      "eval_samples_per_second": 26.012,
      "eval_steps_per_second": 3.252,
      "eval_wer": 0.18421551300742894,
      "step": 3800
    },
    {
      "epoch": 1.3654903351658096,
      "grad_norm": 3.3893790245056152,
      "learning_rate": 9.595995427850696e-05,
      "loss": 0.8721,
      "step": 3850
    },
    {
      "epoch": 1.3832239758822487,
      "grad_norm": 1.7500779628753662,
      "learning_rate": 9.57668203854795e-05,
      "loss": 0.8575,
      "step": 3900
    },
    {
      "epoch": 1.3832239758822487,
      "eval_loss": 0.5487980246543884,
      "eval_runtime": 765.8835,
      "eval_samples_per_second": 26.111,
      "eval_steps_per_second": 3.264,
      "eval_wer": 0.18375917983780837,
      "step": 3900
    },
    {
      "epoch": 1.4009576165986877,
      "grad_norm": 2.020519256591797,
      "learning_rate": 9.556974498443106e-05,
      "loss": 0.8566,
      "step": 3950
    },
    {
      "epoch": 1.418691257315127,
      "grad_norm": 1.8049991130828857,
      "learning_rate": 9.537266958338262e-05,
      "loss": 0.8459,
      "step": 4000
    },
    {
      "epoch": 1.418691257315127,
      "eval_loss": 0.5733304619789124,
      "eval_runtime": 773.871,
      "eval_samples_per_second": 25.842,
      "eval_steps_per_second": 3.231,
      "eval_wer": 0.1815084518317136,
      "step": 4000
    },
    {
      "epoch": 1.436424898031566,
      "grad_norm": 1.9722708463668823,
      "learning_rate": 9.517559418233416e-05,
      "loss": 0.8773,
      "step": 4050
    },
    {
      "epoch": 1.454158538748005,
      "grad_norm": 1.8244234323501587,
      "learning_rate": 9.497851878128572e-05,
      "loss": 0.8122,
      "step": 4100
    },
    {
      "epoch": 1.454158538748005,
      "eval_loss": 0.5772178769111633,
      "eval_runtime": 752.4309,
      "eval_samples_per_second": 26.578,
      "eval_steps_per_second": 3.323,
      "eval_wer": 0.18129188693765638,
      "step": 4100
    },
    {
      "epoch": 1.4718921794644442,
      "grad_norm": 2.294011116027832,
      "learning_rate": 9.478144338023728e-05,
      "loss": 0.8567,
      "step": 4150
    },
    {
      "epoch": 1.4896258201808832,
      "grad_norm": 1.7284284830093384,
      "learning_rate": 9.458436797918884e-05,
      "loss": 0.8136,
      "step": 4200
    },
    {
      "epoch": 1.4896258201808832,
      "eval_loss": 0.5448747277259827,
      "eval_runtime": 780.5449,
      "eval_samples_per_second": 25.621,
      "eval_steps_per_second": 3.203,
      "eval_wer": 0.17527060943681527,
      "step": 4200
    },
    {
      "epoch": 1.5073594608973222,
      "grad_norm": 1.794292688369751,
      "learning_rate": 9.43872925781404e-05,
      "loss": 0.8539,
      "step": 4250
    },
    {
      "epoch": 1.5250931016137614,
      "grad_norm": 1.8994709253311157,
      "learning_rate": 9.419021717709196e-05,
      "loss": 0.8596,
      "step": 4300
    },
    {
      "epoch": 1.5250931016137614,
      "eval_loss": 0.498043954372406,
      "eval_runtime": 774.8117,
      "eval_samples_per_second": 25.81,
      "eval_steps_per_second": 3.227,
      "eval_wer": 0.17131056565976882,
      "step": 4300
    },
    {
      "epoch": 1.5428267423302002,
      "grad_norm": 2.1409783363342285,
      "learning_rate": 9.399314177604351e-05,
      "loss": 0.7794,
      "step": 4350
    },
    {
      "epoch": 1.5605603830466395,
      "grad_norm": 1.6548287868499756,
      "learning_rate": 9.379606637499507e-05,
      "loss": 0.8465,
      "step": 4400
    },
    {
      "epoch": 1.5605603830466395,
      "eval_loss": 0.5101613402366638,
      "eval_runtime": 753.2478,
      "eval_samples_per_second": 26.549,
      "eval_steps_per_second": 3.319,
      "eval_wer": 0.1701426621239602,
      "step": 4400
    },
    {
      "epoch": 1.5782940237630787,
      "grad_norm": 2.38645601272583,
      "learning_rate": 9.359899097394663e-05,
      "loss": 0.8045,
      "step": 4450
    },
    {
      "epoch": 1.5960276644795175,
      "grad_norm": 2.3903021812438965,
      "learning_rate": 9.340191557289819e-05,
      "loss": 0.8089,
      "step": 4500
    },
    {
      "epoch": 1.5960276644795175,
      "eval_loss": 0.5257870554924011,
      "eval_runtime": 765.7976,
      "eval_samples_per_second": 26.114,
      "eval_steps_per_second": 3.265,
      "eval_wer": 0.1630153567713268,
      "step": 4500
    },
    {
      "epoch": 1.6137613051959567,
      "grad_norm": 1.9491029977798462,
      "learning_rate": 9.320484017184975e-05,
      "loss": 0.7915,
      "step": 4550
    },
    {
      "epoch": 1.631494945912396,
      "grad_norm": 2.503726005554199,
      "learning_rate": 9.30077647708013e-05,
      "loss": 0.8193,
      "step": 4600
    },
    {
      "epoch": 1.631494945912396,
      "eval_loss": 0.45157092809677124,
      "eval_runtime": 773.9382,
      "eval_samples_per_second": 25.839,
      "eval_steps_per_second": 3.23,
      "eval_wer": 0.1627987918772696,
      "step": 4600
    },
    {
      "epoch": 1.6492285866288348,
      "grad_norm": 1.5113377571105957,
      "learning_rate": 9.281068936975287e-05,
      "loss": 0.924,
      "step": 4650
    },
    {
      "epoch": 1.666962227345274,
      "grad_norm": 1.6853818893432617,
      "learning_rate": 9.261361396870443e-05,
      "loss": 0.7641,
      "step": 4700
    },
    {
      "epoch": 1.666962227345274,
      "eval_loss": 0.45241573452949524,
      "eval_runtime": 756.711,
      "eval_samples_per_second": 26.428,
      "eval_steps_per_second": 3.304,
      "eval_wer": 0.1616927640254773,
      "step": 4700
    },
    {
      "epoch": 1.6846958680617132,
      "grad_norm": 2.6745073795318604,
      "learning_rate": 9.241653856765598e-05,
      "loss": 0.7776,
      "step": 4750
    },
    {
      "epoch": 1.702429508778152,
      "grad_norm": 2.449249505996704,
      "learning_rate": 9.221946316660754e-05,
      "loss": 0.7957,
      "step": 4800
    },
    {
      "epoch": 1.702429508778152,
      "eval_loss": 0.5210429430007935,
      "eval_runtime": 771.1968,
      "eval_samples_per_second": 25.931,
      "eval_steps_per_second": 3.242,
      "eval_wer": 0.16050552433841359,
      "step": 4800
    },
    {
      "epoch": 1.7201631494945913,
      "grad_norm": 1.886351466178894,
      "learning_rate": 9.20223877655591e-05,
      "loss": 0.7531,
      "step": 4850
    },
    {
      "epoch": 1.7378967902110303,
      "grad_norm": 2.029285192489624,
      "learning_rate": 9.182531236451066e-05,
      "loss": 0.7582,
      "step": 4900
    },
    {
      "epoch": 1.7378967902110303,
      "eval_loss": 0.4924737215042114,
      "eval_runtime": 772.1558,
      "eval_samples_per_second": 25.899,
      "eval_steps_per_second": 3.238,
      "eval_wer": 0.15741174013759604,
      "step": 4900
    },
    {
      "epoch": 1.7556304309274693,
      "grad_norm": 1.9566529989242554,
      "learning_rate": 9.162823696346222e-05,
      "loss": 0.7857,
      "step": 4950
    },
    {
      "epoch": 1.7733640716439085,
      "grad_norm": 2.9861326217651367,
      "learning_rate": 9.143116156241378e-05,
      "loss": 0.7722,
      "step": 5000
    },
    {
      "epoch": 1.7733640716439085,
      "eval_loss": 0.515448272228241,
      "eval_runtime": 766.0501,
      "eval_samples_per_second": 26.105,
      "eval_steps_per_second": 3.263,
      "eval_wer": 0.15791834730047993,
      "step": 5000
    },
    {
      "epoch": 1.7910977123603475,
      "grad_norm": 5.96873140335083,
      "learning_rate": 9.123408616136534e-05,
      "loss": 0.756,
      "step": 5050
    },
    {
      "epoch": 1.8088313530767866,
      "grad_norm": 1.6006238460540771,
      "learning_rate": 9.10370107603169e-05,
      "loss": 0.7543,
      "step": 5100
    },
    {
      "epoch": 1.8088313530767866,
      "eval_loss": 0.4699094891548157,
      "eval_runtime": 775.297,
      "eval_samples_per_second": 25.794,
      "eval_steps_per_second": 3.225,
      "eval_wer": 0.1541903373384948,
      "step": 5100
    },
    {
      "epoch": 1.8265649937932258,
      "grad_norm": 1.7898225784301758,
      "learning_rate": 9.083993535926846e-05,
      "loss": 0.7577,
      "step": 5150
    },
    {
      "epoch": 1.8442986345096648,
      "grad_norm": 2.286766767501831,
      "learning_rate": 9.064285995822002e-05,
      "loss": 0.7593,
      "step": 5200
    },
    {
      "epoch": 1.8442986345096648,
      "eval_loss": 0.5014985799789429,
      "eval_runtime": 778.322,
      "eval_samples_per_second": 25.694,
      "eval_steps_per_second": 3.212,
      "eval_wer": 0.15579137066241788,
      "step": 5200
    },
    {
      "epoch": 1.8620322752261038,
      "grad_norm": 2.5513839721679688,
      "learning_rate": 9.044578455717158e-05,
      "loss": 0.7655,
      "step": 5250
    },
    {
      "epoch": 1.879765915942543,
      "grad_norm": 1.7896547317504883,
      "learning_rate": 9.024870915612314e-05,
      "loss": 0.7336,
      "step": 5300
    },
    {
      "epoch": 1.879765915942543,
      "eval_loss": 0.45709365606307983,
      "eval_runtime": 770.9158,
      "eval_samples_per_second": 25.941,
      "eval_steps_per_second": 3.243,
      "eval_wer": 0.1490739917163928,
      "step": 5300
    },
    {
      "epoch": 1.897499556658982,
      "grad_norm": 2.5123813152313232,
      "learning_rate": 9.005163375507469e-05,
      "loss": 0.7662,
      "step": 5350
    },
    {
      "epoch": 1.915233197375421,
      "grad_norm": 2.4920504093170166,
      "learning_rate": 8.985455835402625e-05,
      "loss": 0.7873,
      "step": 5400
    },
    {
      "epoch": 1.915233197375421,
      "eval_loss": 0.47459545731544495,
      "eval_runtime": 768.7725,
      "eval_samples_per_second": 26.013,
      "eval_steps_per_second": 3.252,
      "eval_wer": 0.1507523696453363,
      "step": 5400
    },
    {
      "epoch": 1.9329668380918603,
      "grad_norm": 3.0792768001556396,
      "learning_rate": 8.96574829529778e-05,
      "loss": 0.7498,
      "step": 5450
    },
    {
      "epoch": 1.9507004788082993,
      "grad_norm": 1.5807667970657349,
      "learning_rate": 8.946040755192937e-05,
      "loss": 0.7453,
      "step": 5500
    },
    {
      "epoch": 1.9507004788082993,
      "eval_loss": 0.45629778504371643,
      "eval_runtime": 761.317,
      "eval_samples_per_second": 26.268,
      "eval_steps_per_second": 3.284,
      "eval_wer": 0.14734147256393498,
      "step": 5500
    },
    {
      "epoch": 1.9684341195247383,
      "grad_norm": 2.298283338546753,
      "learning_rate": 8.926333215088093e-05,
      "loss": 0.7599,
      "step": 5550
    },
    {
      "epoch": 1.9861677602411776,
      "grad_norm": 2.2591969966888428,
      "learning_rate": 8.906625674983249e-05,
      "loss": 0.7846,
      "step": 5600
    },
    {
      "epoch": 1.9861677602411776,
      "eval_loss": 0.4458216726779938,
      "eval_runtime": 770.734,
      "eval_samples_per_second": 25.947,
      "eval_steps_per_second": 3.244,
      "eval_wer": 0.1470127579925981,
      "step": 5600
    },
    {
      "epoch": 2.003901400957617,
      "grad_norm": 0.6850934028625488,
      "learning_rate": 8.886918134878405e-05,
      "loss": 0.7653,
      "step": 5650
    },
    {
      "epoch": 2.0216350416740556,
      "grad_norm": 0.681761622428894,
      "learning_rate": 8.86721059477356e-05,
      "loss": 0.718,
      "step": 5700
    },
    {
      "epoch": 2.0216350416740556,
      "eval_loss": 0.42717328667640686,
      "eval_runtime": 769.6166,
      "eval_samples_per_second": 25.984,
      "eval_steps_per_second": 3.248,
      "eval_wer": 0.14412393699508474,
      "step": 5700
    },
    {
      "epoch": 2.039368682390495,
      "grad_norm": 0.794064998626709,
      "learning_rate": 8.847503054668716e-05,
      "loss": 0.7139,
      "step": 5750
    },
    {
      "epoch": 2.0571023231069336,
      "grad_norm": 0.7759293913841248,
      "learning_rate": 8.827795514563872e-05,
      "loss": 0.7,
      "step": 5800
    },
    {
      "epoch": 2.0571023231069336,
      "eval_loss": 0.45484015345573425,
      "eval_runtime": 772.8961,
      "eval_samples_per_second": 25.874,
      "eval_steps_per_second": 3.235,
      "eval_wer": 0.14601114535758344,
      "step": 5800
    },
    {
      "epoch": 2.074835963823373,
      "grad_norm": 0.678194522857666,
      "learning_rate": 8.808087974459028e-05,
      "loss": 0.6865,
      "step": 5850
    },
    {
      "epoch": 2.092569604539812,
      "grad_norm": 17.66790008544922,
      "learning_rate": 8.788380434354184e-05,
      "loss": 0.7314,
      "step": 5900
    },
    {
      "epoch": 2.092569604539812,
      "eval_loss": 0.5031664371490479,
      "eval_runtime": 760.485,
      "eval_samples_per_second": 26.296,
      "eval_steps_per_second": 3.287,
      "eval_wer": 0.14306431590630475,
      "step": 5900
    },
    {
      "epoch": 2.110303245256251,
      "grad_norm": 0.7212561368942261,
      "learning_rate": 8.76867289424934e-05,
      "loss": 0.6915,
      "step": 5950
    },
    {
      "epoch": 2.12803688597269,
      "grad_norm": 0.7579920291900635,
      "learning_rate": 8.748965354144496e-05,
      "loss": 0.7175,
      "step": 6000
    },
    {
      "epoch": 2.12803688597269,
      "eval_loss": 0.4553031921386719,
      "eval_runtime": 759.333,
      "eval_samples_per_second": 26.336,
      "eval_steps_per_second": 3.292,
      "eval_wer": 0.1424571607568943,
      "step": 6000
    },
    {
      "epoch": 2.1457705266891294,
      "grad_norm": 0.7462003827095032,
      "learning_rate": 8.729257814039652e-05,
      "loss": 0.7035,
      "step": 6050
    },
    {
      "epoch": 2.163504167405568,
      "grad_norm": 0.7328625917434692,
      "learning_rate": 8.709550273934808e-05,
      "loss": 0.7085,
      "step": 6100
    },
    {
      "epoch": 2.163504167405568,
      "eval_loss": 0.47007009387016296,
      "eval_runtime": 777.0582,
      "eval_samples_per_second": 25.736,
      "eval_steps_per_second": 3.217,
      "eval_wer": 0.13933243871406858,
      "step": 6100
    },
    {
      "epoch": 2.1812378081220074,
      "grad_norm": 0.7422387003898621,
      "learning_rate": 8.689842733829964e-05,
      "loss": 0.6947,
      "step": 6150
    },
    {
      "epoch": 2.1989714488384466,
      "grad_norm": 0.7855895757675171,
      "learning_rate": 8.67013519372512e-05,
      "loss": 0.726,
      "step": 6200
    },
    {
      "epoch": 2.1989714488384466,
      "eval_loss": 0.44129374623298645,
      "eval_runtime": 767.2226,
      "eval_samples_per_second": 26.065,
      "eval_steps_per_second": 3.259,
      "eval_wer": 0.13872528356465816,
      "step": 6200
    },
    {
      "epoch": 2.2167050895548854,
      "grad_norm": 0.7453720569610596,
      "learning_rate": 8.650427653620276e-05,
      "loss": 0.7048,
      "step": 6250
    },
    {
      "epoch": 2.2344387302713247,
      "grad_norm": 0.7427273988723755,
      "learning_rate": 8.630720113515432e-05,
      "loss": 0.7945,
      "step": 6300
    },
    {
      "epoch": 2.2344387302713247,
      "eval_loss": 0.4352671504020691,
      "eval_runtime": 763.6356,
      "eval_samples_per_second": 26.188,
      "eval_steps_per_second": 3.274,
      "eval_wer": 0.14013295537603013,
      "step": 6300
    },
    {
      "epoch": 2.252172370987764,
      "grad_norm": 0.659891664981842,
      "learning_rate": 8.611012573410587e-05,
      "loss": 0.6934,
      "step": 6350
    },
    {
      "epoch": 2.2699060117042027,
      "grad_norm": 0.6559414267539978,
      "learning_rate": 8.591305033305743e-05,
      "loss": 0.7249,
      "step": 6400
    },
    {
      "epoch": 2.2699060117042027,
      "eval_loss": 0.4561610519886017,
      "eval_runtime": 768.6088,
      "eval_samples_per_second": 26.018,
      "eval_steps_per_second": 3.253,
      "eval_wer": 0.13837336561181515,
      "step": 6400
    },
    {
      "epoch": 2.287639652420642,
      "grad_norm": 0.9412517547607422,
      "learning_rate": 8.571597493200899e-05,
      "loss": 0.7392,
      "step": 6450
    },
    {
      "epoch": 2.305373293137081,
      "grad_norm": 0.903921365737915,
      "learning_rate": 8.551889953096055e-05,
      "loss": 0.7027,
      "step": 6500
    },
    {
      "epoch": 2.305373293137081,
      "eval_loss": 0.4200664758682251,
      "eval_runtime": 763.989,
      "eval_samples_per_second": 26.176,
      "eval_steps_per_second": 3.272,
      "eval_wer": 0.13782808614642106,
      "step": 6500
    },
    {
      "epoch": 2.32310693385352,
      "grad_norm": 1.3143798112869263,
      "learning_rate": 8.53218241299121e-05,
      "loss": 0.6935,
      "step": 6550
    },
    {
      "epoch": 2.340840574569959,
      "grad_norm": 0.7523880004882812,
      "learning_rate": 8.512474872886367e-05,
      "loss": 0.7016,
      "step": 6600
    },
    {
      "epoch": 2.340840574569959,
      "eval_loss": 0.43713369965553284,
      "eval_runtime": 759.652,
      "eval_samples_per_second": 26.325,
      "eval_steps_per_second": 3.291,
      "eval_wer": 0.13646682109806135,
      "step": 6600
    },
    {
      "epoch": 2.3585742152863984,
      "grad_norm": 0.8837945461273193,
      "learning_rate": 8.492767332781522e-05,
      "loss": 0.7232,
      "step": 6650
    },
    {
      "epoch": 2.3763078560028372,
      "grad_norm": 1.0651077032089233,
      "learning_rate": 8.473059792676678e-05,
      "loss": 0.7077,
      "step": 6700
    },
    {
      "epoch": 2.3763078560028372,
      "eval_loss": 0.461868017911911,
      "eval_runtime": 769.8542,
      "eval_samples_per_second": 25.976,
      "eval_steps_per_second": 3.247,
      "eval_wer": 0.1348348499321301,
      "step": 6700
    },
    {
      "epoch": 2.3940414967192765,
      "grad_norm": 0.7488678693771362,
      "learning_rate": 8.453352252571834e-05,
      "loss": 0.6921,
      "step": 6750
    },
    {
      "epoch": 2.4117751374357157,
      "grad_norm": 0.6956681609153748,
      "learning_rate": 8.43364471246699e-05,
      "loss": 0.6542,
      "step": 6800
    },
    {
      "epoch": 2.4117751374357157,
      "eval_loss": 0.42893972992897034,
      "eval_runtime": 755.7187,
      "eval_samples_per_second": 26.462,
      "eval_steps_per_second": 3.308,
      "eval_wer": 0.13491606176740156,
      "step": 6800
    },
    {
      "epoch": 2.4295087781521545,
      "grad_norm": 0.7388433218002319,
      "learning_rate": 8.413937172362146e-05,
      "loss": 0.7113,
      "step": 6850
    },
    {
      "epoch": 2.4472424188685937,
      "grad_norm": 0.7262057065963745,
      "learning_rate": 8.394623783059399e-05,
      "loss": 0.6714,
      "step": 6900
    },
    {
      "epoch": 2.4472424188685937,
      "eval_loss": 0.41253381967544556,
      "eval_runtime": 769.3895,
      "eval_samples_per_second": 25.992,
      "eval_steps_per_second": 3.249,
      "eval_wer": 0.13383323729711544,
      "step": 6900
    },
    {
      "epoch": 2.464976059585033,
      "grad_norm": 0.7727527618408203,
      "learning_rate": 8.374916242954555e-05,
      "loss": 0.7045,
      "step": 6950
    },
    {
      "epoch": 2.4827097003014718,
      "grad_norm": 0.7882379293441772,
      "learning_rate": 8.355208702849711e-05,
      "loss": 0.6887,
      "step": 7000
    },
    {
      "epoch": 2.4827097003014718,
      "eval_loss": 0.407286137342453,
      "eval_runtime": 755.627,
      "eval_samples_per_second": 26.465,
      "eval_steps_per_second": 3.309,
      "eval_wer": 0.13302498617465186,
      "step": 7000
    },
    {
      "epoch": 2.500443341017911,
      "grad_norm": 0.7597631812095642,
      "learning_rate": 8.335501162744867e-05,
      "loss": 0.6882,
      "step": 7050
    },
    {
      "epoch": 2.5181769817343502,
      "grad_norm": 0.7475250959396362,
      "learning_rate": 8.315793622640023e-05,
      "loss": 0.6462,
      "step": 7100
    },
    {
      "epoch": 2.5181769817343502,
      "eval_loss": 0.4061707854270935,
      "eval_runtime": 772.309,
      "eval_samples_per_second": 25.894,
      "eval_steps_per_second": 3.237,
      "eval_wer": 0.13160957990277783,
      "step": 7100
    },
    {
      "epoch": 2.535910622450789,
      "grad_norm": 0.8162370920181274,
      "learning_rate": 8.296086082535179e-05,
      "loss": 0.6989,
      "step": 7150
    },
    {
      "epoch": 2.5536442631672283,
      "grad_norm": 0.7338137626647949,
      "learning_rate": 8.276378542430335e-05,
      "loss": 0.6821,
      "step": 7200
    },
    {
      "epoch": 2.5536442631672283,
      "eval_loss": 0.43621256947517395,
      "eval_runtime": 770.2494,
      "eval_samples_per_second": 25.963,
      "eval_steps_per_second": 3.246,
      "eval_wer": 0.13315260477293558,
      "step": 7200
    },
    {
      "epoch": 2.5713779038836675,
      "grad_norm": 0.6703426241874695,
      "learning_rate": 8.25667100232549e-05,
      "loss": 0.6655,
      "step": 7250
    },
    {
      "epoch": 2.5891115446001063,
      "grad_norm": 0.9007191061973572,
      "learning_rate": 8.236963462220645e-05,
      "loss": 0.6757,
      "step": 7300
    },
    {
      "epoch": 2.5891115446001063,
      "eval_loss": 0.40207043290138245,
      "eval_runtime": 766.9209,
      "eval_samples_per_second": 26.076,
      "eval_steps_per_second": 3.26,
      "eval_wer": 0.13127699810118995,
      "step": 7300
    },
    {
      "epoch": 2.6068451853165455,
      "grad_norm": 0.6435734629631042,
      "learning_rate": 8.217255922115801e-05,
      "loss": 0.6695,
      "step": 7350
    },
    {
      "epoch": 2.6245788260329848,
      "grad_norm": 0.9057005643844604,
      "learning_rate": 8.197548382010957e-05,
      "loss": 0.6794,
      "step": 7400
    },
    {
      "epoch": 2.6245788260329848,
      "eval_loss": 0.3860498070716858,
      "eval_runtime": 769.3358,
      "eval_samples_per_second": 25.994,
      "eval_steps_per_second": 3.25,
      "eval_wer": 0.1296102218629995,
      "step": 7400
    },
    {
      "epoch": 2.6423124667494235,
      "grad_norm": 0.686604917049408,
      "learning_rate": 8.177840841906113e-05,
      "loss": 0.6956,
      "step": 7450
    },
    {
      "epoch": 2.660046107465863,
      "grad_norm": 0.7657003402709961,
      "learning_rate": 8.158133301801269e-05,
      "loss": 0.6983,
      "step": 7500
    },
    {
      "epoch": 2.660046107465863,
      "eval_loss": 0.405062198638916,
      "eval_runtime": 768.9605,
      "eval_samples_per_second": 26.007,
      "eval_steps_per_second": 3.251,
      "eval_wer": 0.12885997919430126,
      "step": 7500
    },
    {
      "epoch": 2.677779748182302,
      "grad_norm": 0.813349187374115,
      "learning_rate": 8.138425761696425e-05,
      "loss": 0.657,
      "step": 7550
    },
    {
      "epoch": 2.695513388898741,
      "grad_norm": 0.6849279999732971,
      "learning_rate": 8.118718221591581e-05,
      "loss": 0.7073,
      "step": 7600
    },
    {
      "epoch": 2.695513388898741,
      "eval_loss": 0.38221269845962524,
      "eval_runtime": 761.7841,
      "eval_samples_per_second": 26.252,
      "eval_steps_per_second": 3.282,
      "eval_wer": 0.12823735512388673,
      "step": 7600
    },
    {
      "epoch": 2.71324702961518,
      "grad_norm": 0.707168698310852,
      "learning_rate": 8.099010681486737e-05,
      "loss": 0.6584,
      "step": 7650
    },
    {
      "epoch": 2.7309806703316193,
      "grad_norm": 0.9913771748542786,
      "learning_rate": 8.079303141381893e-05,
      "loss": 0.6863,
      "step": 7700
    },
    {
      "epoch": 2.7309806703316193,
      "eval_loss": 0.3724343478679657,
      "eval_runtime": 775.6454,
      "eval_samples_per_second": 25.782,
      "eval_steps_per_second": 3.223,
      "eval_wer": 0.1305615605047509,
      "step": 7700
    },
    {
      "epoch": 2.748714311048058,
      "grad_norm": 0.6653972268104553,
      "learning_rate": 8.059595601277049e-05,
      "loss": 0.6707,
      "step": 7750
    },
    {
      "epoch": 2.7664479517644973,
      "grad_norm": 0.7445628643035889,
      "learning_rate": 8.039888061172205e-05,
      "loss": 0.6646,
      "step": 7800
    },
    {
      "epoch": 2.7664479517644973,
      "eval_loss": 0.3953510522842407,
      "eval_runtime": 770.2899,
      "eval_samples_per_second": 25.962,
      "eval_steps_per_second": 3.246,
      "eval_wer": 0.12866661768175017,
      "step": 7800
    },
    {
      "epoch": 2.7841815924809366,
      "grad_norm": 0.8393126130104065,
      "learning_rate": 8.020180521067361e-05,
      "loss": 0.676,
      "step": 7850
    },
    {
      "epoch": 2.8019152331973753,
      "grad_norm": 0.5939632058143616,
      "learning_rate": 8.000472980962517e-05,
      "loss": 0.6514,
      "step": 7900
    },
    {
      "epoch": 2.8019152331973753,
      "eval_loss": 0.3679158687591553,
      "eval_runtime": 771.5777,
      "eval_samples_per_second": 25.918,
      "eval_steps_per_second": 3.24,
      "eval_wer": 0.12708492050908218,
      "step": 7900
    },
    {
      "epoch": 2.8196488739138146,
      "grad_norm": 0.7970430254936218,
      "learning_rate": 7.980765440857673e-05,
      "loss": 0.6602,
      "step": 7950
    },
    {
      "epoch": 2.837382514630254,
      "grad_norm": 0.774412214756012,
      "learning_rate": 7.961057900752829e-05,
      "loss": 0.655,
      "step": 8000
    },
    {
      "epoch": 2.837382514630254,
      "eval_loss": 0.36881136894226074,
      "eval_runtime": 771.8468,
      "eval_samples_per_second": 25.909,
      "eval_steps_per_second": 3.239,
      "eval_wer": 0.12936658635718512,
      "step": 8000
    },
    {
      "epoch": 2.8551161553466926,
      "grad_norm": 0.6088500618934631,
      "learning_rate": 7.941350360647985e-05,
      "loss": 0.657,
      "step": 8050
    },
    {
      "epoch": 2.872849796063132,
      "grad_norm": 0.9027181267738342,
      "learning_rate": 7.921642820543141e-05,
      "loss": 0.6564,
      "step": 8100
    },
    {
      "epoch": 2.872849796063132,
      "eval_loss": 0.41935932636260986,
      "eval_runtime": 772.1057,
      "eval_samples_per_second": 25.901,
      "eval_steps_per_second": 3.238,
      "eval_wer": 0.12812133821635607,
      "step": 8100
    },
    {
      "epoch": 2.890583436779571,
      "grad_norm": 0.6385467052459717,
      "learning_rate": 7.901935280438297e-05,
      "loss": 0.6608,
      "step": 8150
    },
    {
      "epoch": 2.90831707749601,
      "grad_norm": 0.6746819615364075,
      "learning_rate": 7.882227740333453e-05,
      "loss": 0.6211,
      "step": 8200
    },
    {
      "epoch": 2.90831707749601,
      "eval_loss": 0.36684685945510864,
      "eval_runtime": 758.6148,
      "eval_samples_per_second": 26.361,
      "eval_steps_per_second": 3.295,
      "eval_wer": 0.12785836655928656,
      "step": 8200
    },
    {
      "epoch": 2.926050718212449,
      "grad_norm": 0.6484570503234863,
      "learning_rate": 7.862520200228607e-05,
      "loss": 0.6274,
      "step": 8250
    },
    {
      "epoch": 2.9437843589288883,
      "grad_norm": 7.094153881072998,
      "learning_rate": 7.842812660123763e-05,
      "loss": 0.6744,
      "step": 8300
    },
    {
      "epoch": 2.9437843589288883,
      "eval_loss": 0.42872685194015503,
      "eval_runtime": 773.6275,
      "eval_samples_per_second": 25.85,
      "eval_steps_per_second": 3.232,
      "eval_wer": 0.1281290726768581,
      "step": 8300
    },
    {
      "epoch": 2.961517999645327,
      "grad_norm": 0.871685266494751,
      "learning_rate": 7.823105120018919e-05,
      "loss": 0.6777,
      "step": 8350
    },
    {
      "epoch": 2.9792516403617664,
      "grad_norm": 0.6488704681396484,
      "learning_rate": 7.803397579914075e-05,
      "loss": 0.6398,
      "step": 8400
    },
    {
      "epoch": 2.9792516403617664,
      "eval_loss": 0.41552314162254333,
      "eval_runtime": 769.8206,
      "eval_samples_per_second": 25.977,
      "eval_steps_per_second": 3.248,
      "eval_wer": 0.12610651125557365,
      "step": 8400
    },
    {
      "epoch": 2.9969852810782056,
      "grad_norm": 1.9888101816177368,
      "learning_rate": 7.783690039809231e-05,
      "loss": 0.6904,
      "step": 8450
    },
    {
      "epoch": 3.0147189217946444,
      "grad_norm": 5.5512847900390625,
      "learning_rate": 7.763982499704387e-05,
      "loss": 0.613,
      "step": 8500
    },
    {
      "epoch": 3.0147189217946444,
      "eval_loss": 0.3883318305015564,
      "eval_runtime": 755.6306,
      "eval_samples_per_second": 26.465,
      "eval_steps_per_second": 3.308,
      "eval_wer": 0.12414195828805451,
      "step": 8500
    },
    {
      "epoch": 3.0324525625110836,
      "grad_norm": 5.532830715179443,
      "learning_rate": 7.744274959599543e-05,
      "loss": 0.6253,
      "step": 8550
    },
    {
      "epoch": 3.0501862032275224,
      "grad_norm": 1.6750024557113647,
      "learning_rate": 7.724567419494699e-05,
      "loss": 0.6291,
      "step": 8600
    },
    {
      "epoch": 3.0501862032275224,
      "eval_loss": 0.3824734389781952,
      "eval_runtime": 768.3601,
      "eval_samples_per_second": 26.027,
      "eval_steps_per_second": 3.254,
      "eval_wer": 0.12679101101000453,
      "step": 8600
    },
    {
      "epoch": 3.0679198439439617,
      "grad_norm": 2.813063144683838,
      "learning_rate": 7.704859879389855e-05,
      "loss": 0.6579,
      "step": 8650
    },
    {
      "epoch": 3.085653484660401,
      "grad_norm": 2.5478451251983643,
      "learning_rate": 7.685152339285011e-05,
      "loss": 0.6376,
      "step": 8700
    },
    {
      "epoch": 3.085653484660401,
      "eval_loss": 0.38950759172439575,
      "eval_runtime": 759.7048,
      "eval_samples_per_second": 26.323,
      "eval_steps_per_second": 3.291,
      "eval_wer": 0.1260407683413063,
      "step": 8700
    },
    {
      "epoch": 3.1033871253768397,
      "grad_norm": 2.8862476348876953,
      "learning_rate": 7.665444799180167e-05,
      "loss": 0.6512,
      "step": 8750
    },
    {
      "epoch": 3.121120766093279,
      "grad_norm": 2.43863844871521,
      "learning_rate": 7.645737259075323e-05,
      "loss": 0.6479,
      "step": 8800
    },
    {
      "epoch": 3.121120766093279,
      "eval_loss": 0.4087097644805908,
      "eval_runtime": 770.5914,
      "eval_samples_per_second": 25.951,
      "eval_steps_per_second": 3.244,
      "eval_wer": 0.1245634863854159,
      "step": 8800
    },
    {
      "epoch": 3.138854406809718,
      "grad_norm": 2.1964991092681885,
      "learning_rate": 7.626029718970479e-05,
      "loss": 0.6368,
      "step": 8850
    },
    {
      "epoch": 3.156588047526157,
      "grad_norm": 2.4772324562072754,
      "learning_rate": 7.606322178865635e-05,
      "loss": 0.612,
      "step": 8900
    },
    {
      "epoch": 3.156588047526157,
      "eval_loss": 0.3808661997318268,
      "eval_runtime": 771.6964,
      "eval_samples_per_second": 25.914,
      "eval_steps_per_second": 3.24,
      "eval_wer": 0.1257120537699694,
      "step": 8900
    },
    {
      "epoch": 3.174321688242596,
      "grad_norm": 5.6676249504089355,
      "learning_rate": 7.586614638760791e-05,
      "loss": 0.6433,
      "step": 8950
    },
    {
      "epoch": 3.1920553289590354,
      "grad_norm": 3.8578004837036133,
      "learning_rate": 7.566907098655947e-05,
      "loss": 0.6199,
      "step": 9000
    },
    {
      "epoch": 3.1920553289590354,
      "eval_loss": 0.38752231001853943,
      "eval_runtime": 771.1229,
      "eval_samples_per_second": 25.934,
      "eval_steps_per_second": 3.242,
      "eval_wer": 0.1246872377534486,
      "step": 9000
    },
    {
      "epoch": 3.2097889696754742,
      "grad_norm": 1.9251832962036133,
      "learning_rate": 7.547199558551103e-05,
      "loss": 0.6382,
      "step": 9050
    },
    {
      "epoch": 3.2275226103919135,
      "grad_norm": 3.07368803024292,
      "learning_rate": 7.527492018446259e-05,
      "loss": 0.6153,
      "step": 9100
    },
    {
      "epoch": 3.2275226103919135,
      "eval_loss": 0.3814842998981476,
      "eval_runtime": 754.0856,
      "eval_samples_per_second": 26.52,
      "eval_steps_per_second": 3.315,
      "eval_wer": 0.12432371810985254,
      "step": 9100
    },
    {
      "epoch": 3.2452562511083527,
      "grad_norm": 3.433093786239624,
      "learning_rate": 7.507784478341415e-05,
      "loss": 0.6451,
      "step": 9150
    },
    {
      "epoch": 3.2629898918247915,
      "grad_norm": 1.5765049457550049,
      "learning_rate": 7.488076938236571e-05,
      "loss": 0.637,
      "step": 9200
    },
    {
      "epoch": 3.2629898918247915,
      "eval_loss": 0.3724323809146881,
      "eval_runtime": 770.7817,
      "eval_samples_per_second": 25.945,
      "eval_steps_per_second": 3.243,
      "eval_wer": 0.12557670071118365,
      "step": 9200
    },
    {
      "epoch": 3.2807235325412307,
      "grad_norm": 2.7174606323242188,
      "learning_rate": 7.468369398131725e-05,
      "loss": 0.6229,
      "step": 9250
    },
    {
      "epoch": 3.29845717325767,
      "grad_norm": 11.779010772705078,
      "learning_rate": 7.448661858026881e-05,
      "loss": 0.6387,
      "step": 9300
    },
    {
      "epoch": 3.29845717325767,
      "eval_loss": 0.34621870517730713,
      "eval_runtime": 772.0086,
      "eval_samples_per_second": 25.904,
      "eval_steps_per_second": 3.238,
      "eval_wer": 0.12264920741116005,
      "step": 9300
    },
    {
      "epoch": 3.3161908139741088,
      "grad_norm": 1.6432034969329834,
      "learning_rate": 7.428954317922037e-05,
      "loss": 0.624,
      "step": 9350
    },
    {
      "epoch": 3.333924454690548,
      "grad_norm": 2.9582712650299072,
      "learning_rate": 7.409246777817193e-05,
      "loss": 0.6415,
      "step": 9400
    },
    {
      "epoch": 3.333924454690548,
      "eval_loss": 0.3517763912677765,
      "eval_runtime": 771.4994,
      "eval_samples_per_second": 25.921,
      "eval_steps_per_second": 3.24,
      "eval_wer": 0.12288897568672341,
      "step": 9400
    },
    {
      "epoch": 3.3516580954069872,
      "grad_norm": 1.9628928899765015,
      "learning_rate": 7.389539237712349e-05,
      "loss": 0.6423,
      "step": 9450
    },
    {
      "epoch": 3.369391736123426,
      "grad_norm": 1.6184821128845215,
      "learning_rate": 7.369831697607505e-05,
      "loss": 0.6449,
      "step": 9500
    },
    {
      "epoch": 3.369391736123426,
      "eval_loss": 0.33670997619628906,
      "eval_runtime": 769.5478,
      "eval_samples_per_second": 25.987,
      "eval_steps_per_second": 3.249,
      "eval_wer": 0.12303979766651327,
      "step": 9500
    },
    {
      "epoch": 3.3871253768398653,
      "grad_norm": 2.360145330429077,
      "learning_rate": 7.350124157502661e-05,
      "loss": 0.6227,
      "step": 9550
    },
    {
      "epoch": 3.4048590175563045,
      "grad_norm": 2.0541915893554688,
      "learning_rate": 7.330416617397817e-05,
      "loss": 0.6053,
      "step": 9600
    },
    {
      "epoch": 3.4048590175563045,
      "eval_loss": 0.3594585359096527,
      "eval_runtime": 755.2989,
      "eval_samples_per_second": 26.477,
      "eval_steps_per_second": 3.31,
      "eval_wer": 0.12025152465552646,
      "step": 9600
    },
    {
      "epoch": 3.4225926582727433,
      "grad_norm": 4.341418266296387,
      "learning_rate": 7.310709077292973e-05,
      "loss": 0.6784,
      "step": 9650
    },
    {
      "epoch": 3.4403262989891825,
      "grad_norm": 1.712680697441101,
      "learning_rate": 7.291001537188129e-05,
      "loss": 0.6165,
      "step": 9700
    },
    {
      "epoch": 3.4403262989891825,
      "eval_loss": 0.35724276304244995,
      "eval_runtime": 774.2911,
      "eval_samples_per_second": 25.827,
      "eval_steps_per_second": 3.229,
      "eval_wer": 0.12088961764694509,
      "step": 9700
    },
    {
      "epoch": 3.4580599397056218,
      "grad_norm": 2.548985481262207,
      "learning_rate": 7.271293997083285e-05,
      "loss": 0.6147,
      "step": 9750
    },
    {
      "epoch": 3.4757935804220605,
      "grad_norm": 4.113430023193359,
      "learning_rate": 7.25158645697844e-05,
      "loss": 0.609,
      "step": 9800
    },
    {
      "epoch": 3.4757935804220605,
      "eval_loss": 0.40108048915863037,
      "eval_runtime": 757.4496,
      "eval_samples_per_second": 26.402,
      "eval_steps_per_second": 3.301,
      "eval_wer": 0.122111662406268,
      "step": 9800
    },
    {
      "epoch": 3.4935272211385,
      "grad_norm": 2.0763466358184814,
      "learning_rate": 7.231878916873596e-05,
      "loss": 0.6429,
      "step": 9850
    },
    {
      "epoch": 3.5112608618549386,
      "grad_norm": 2.007676124572754,
      "learning_rate": 7.212171376768752e-05,
      "loss": 0.6233,
      "step": 9900
    },
    {
      "epoch": 3.5112608618549386,
      "eval_loss": 0.34761106967926025,
      "eval_runtime": 760.4472,
      "eval_samples_per_second": 26.298,
      "eval_steps_per_second": 3.288,
      "eval_wer": 0.12091282102845122,
      "step": 9900
    },
    {
      "epoch": 3.528994502571378,
      "grad_norm": 1.7267560958862305,
      "learning_rate": 7.192463836663907e-05,
      "loss": 0.5894,
      "step": 9950
    },
    {
      "epoch": 3.546728143287817,
      "grad_norm": 3.721310615539551,
      "learning_rate": 7.172756296559063e-05,
      "loss": 0.6146,
      "step": 10000
    },
    {
      "epoch": 3.546728143287817,
      "eval_loss": 0.36491432785987854,
      "eval_runtime": 757.4306,
      "eval_samples_per_second": 26.402,
      "eval_steps_per_second": 3.301,
      "eval_wer": 0.12291217906822954,
      "step": 10000
    },
    {
      "epoch": 3.564461784004256,
      "grad_norm": 2.472227096557617,
      "learning_rate": 7.15304875645422e-05,
      "loss": 0.639,
      "step": 10050
    },
    {
      "epoch": 3.582195424720695,
      "grad_norm": 1.2337642908096313,
      "learning_rate": 7.133341216349375e-05,
      "loss": 0.6303,
      "step": 10100
    },
    {
      "epoch": 3.582195424720695,
      "eval_loss": 0.3624981939792633,
      "eval_runtime": 772.1765,
      "eval_samples_per_second": 25.898,
      "eval_steps_per_second": 3.238,
      "eval_wer": 0.12090508656794917,
      "step": 10100
    },
    {
      "epoch": 3.5999290654371343,
      "grad_norm": 2.2062442302703857,
      "learning_rate": 7.113633676244531e-05,
      "loss": 0.6267,
      "step": 10150
    },
    {
      "epoch": 3.617662706153573,
      "grad_norm": 2.359124183654785,
      "learning_rate": 7.093926136139687e-05,
      "loss": 0.5789,
      "step": 10200
    },
    {
      "epoch": 3.617662706153573,
      "eval_loss": 0.38642436265945435,
      "eval_runtime": 772.3793,
      "eval_samples_per_second": 25.891,
      "eval_steps_per_second": 3.237,
      "eval_wer": 0.11980292594640793,
      "step": 10200
    },
    {
      "epoch": 3.6353963468700123,
      "grad_norm": 3.3120296001434326,
      "learning_rate": 7.074218596034843e-05,
      "loss": 0.6304,
      "step": 10250
    },
    {
      "epoch": 3.6531299875864516,
      "grad_norm": 2.131023645401001,
      "learning_rate": 7.054511055929999e-05,
      "loss": 0.645,
      "step": 10300
    },
    {
      "epoch": 3.6531299875864516,
      "eval_loss": 0.32013753056526184,
      "eval_runtime": 772.0434,
      "eval_samples_per_second": 25.903,
      "eval_steps_per_second": 3.238,
      "eval_wer": 0.12080067135117158,
      "step": 10300
    },
    {
      "epoch": 3.6708636283028904,
      "grad_norm": 1.853286623954773,
      "learning_rate": 7.034803515825155e-05,
      "loss": 0.6132,
      "step": 10350
    },
    {
      "epoch": 3.6885972690193296,
      "grad_norm": 10.040000915527344,
      "learning_rate": 7.015095975720311e-05,
      "loss": 0.6028,
      "step": 10400
    },
    {
      "epoch": 3.6885972690193296,
      "eval_loss": 0.3791225850582123,
      "eval_runtime": 776.0968,
      "eval_samples_per_second": 25.767,
      "eval_steps_per_second": 3.221,
      "eval_wer": 0.11930018601377508,
      "step": 10400
    },
    {
      "epoch": 3.706330909735769,
      "grad_norm": 2.6832833290100098,
      "learning_rate": 6.995388435615466e-05,
      "loss": 0.6068,
      "step": 10450
    },
    {
      "epoch": 3.7240645504522076,
      "grad_norm": 1.808996558189392,
      "learning_rate": 6.975680895510622e-05,
      "loss": 0.6011,
      "step": 10500
    },
    {
      "epoch": 3.7240645504522076,
      "eval_loss": 0.3594004511833191,
      "eval_runtime": 771.4982,
      "eval_samples_per_second": 25.921,
      "eval_steps_per_second": 3.24,
      "eval_wer": 0.1206653182923858,
      "step": 10500
    },
    {
      "epoch": 3.741798191168647,
      "grad_norm": 7.430970668792725,
      "learning_rate": 6.955973355405778e-05,
      "loss": 0.5928,
      "step": 10550
    },
    {
      "epoch": 3.759531831885086,
      "grad_norm": 2.2405381202697754,
      "learning_rate": 6.936265815300934e-05,
      "loss": 0.6273,
      "step": 10600
    },
    {
      "epoch": 3.759531831885086,
      "eval_loss": 0.34593793749809265,
      "eval_runtime": 755.9336,
      "eval_samples_per_second": 26.455,
      "eval_steps_per_second": 3.307,
      "eval_wer": 0.11907201942896478,
      "step": 10600
    },
    {
      "epoch": 3.777265472601525,
      "grad_norm": 5.143616676330566,
      "learning_rate": 6.91655827519609e-05,
      "loss": 0.6251,
      "step": 10650
    },
    {
      "epoch": 3.794999113317964,
      "grad_norm": 1.7944732904434204,
      "learning_rate": 6.896850735091246e-05,
      "loss": 0.6091,
      "step": 10700
    },
    {
      "epoch": 3.794999113317964,
      "eval_loss": 0.4087007939815521,
      "eval_runtime": 773.057,
      "eval_samples_per_second": 25.869,
      "eval_steps_per_second": 3.234,
      "eval_wer": 0.12139622480982895,
      "step": 10700
    },
    {
      "epoch": 3.8127327540344034,
      "grad_norm": 2.9578089714050293,
      "learning_rate": 6.877143194986402e-05,
      "loss": 0.5984,
      "step": 10750
    },
    {
      "epoch": 3.830466394750842,
      "grad_norm": 2.1894783973693848,
      "learning_rate": 6.857435654881558e-05,
      "loss": 0.6244,
      "step": 10800
    },
    {
      "epoch": 3.830466394750842,
      "eval_loss": 0.350054532289505,
      "eval_runtime": 771.2589,
      "eval_samples_per_second": 25.929,
      "eval_steps_per_second": 3.241,
      "eval_wer": 0.11749805671679886,
      "step": 10800
    },
    {
      "epoch": 3.8482000354672814,
      "grad_norm": 2.807634115219116,
      "learning_rate": 6.837728114776714e-05,
      "loss": 0.5779,
      "step": 10850
    },
    {
      "epoch": 3.8659336761837206,
      "grad_norm": 2.323232889175415,
      "learning_rate": 6.81802057467187e-05,
      "loss": 0.6207,
      "step": 10900
    },
    {
      "epoch": 3.8659336761837206,
      "eval_loss": 0.3595346212387085,
      "eval_runtime": 761.0193,
      "eval_samples_per_second": 26.278,
      "eval_steps_per_second": 3.285,
      "eval_wer": 0.118402988595538,
      "step": 10900
    },
    {
      "epoch": 3.8836673169001594,
      "grad_norm": 2.973292589187622,
      "learning_rate": 6.798313034567025e-05,
      "loss": 0.6101,
      "step": 10950
    },
    {
      "epoch": 3.9014009576165987,
      "grad_norm": 4.437737464904785,
      "learning_rate": 6.778605494462181e-05,
      "loss": 0.5854,
      "step": 11000
    },
    {
      "epoch": 3.9014009576165987,
      "eval_loss": 0.36007532477378845,
      "eval_runtime": 771.3701,
      "eval_samples_per_second": 25.925,
      "eval_steps_per_second": 3.241,
      "eval_wer": 0.11965983842712011,
      "step": 11000
    },
    {
      "epoch": 3.919134598333038,
      "grad_norm": 2.5953428745269775,
      "learning_rate": 6.758897954357337e-05,
      "loss": 0.5968,
      "step": 11050
    },
    {
      "epoch": 3.9368682390494767,
      "grad_norm": 2.0663208961486816,
      "learning_rate": 6.739190414252493e-05,
      "loss": 0.6197,
      "step": 11100
    },
    {
      "epoch": 3.9368682390494767,
      "eval_loss": 0.39314836263656616,
      "eval_runtime": 765.5713,
      "eval_samples_per_second": 26.122,
      "eval_steps_per_second": 3.266,
      "eval_wer": 0.1208586798049369,
      "step": 11100
    },
    {
      "epoch": 3.954601879765916,
      "grad_norm": 4.221939563751221,
      "learning_rate": 6.71948287414765e-05,
      "loss": 0.6157,
      "step": 11150
    },
    {
      "epoch": 3.972335520482355,
      "grad_norm": 1.1599817276000977,
      "learning_rate": 6.699775334042805e-05,
      "loss": 0.6006,
      "step": 11200
    },
    {
      "epoch": 3.972335520482355,
      "eval_loss": 0.37960806488990784,
      "eval_runtime": 770.4082,
      "eval_samples_per_second": 25.958,
      "eval_steps_per_second": 3.245,
      "eval_wer": 0.1164461700885209,
      "step": 11200
    },
    {
      "epoch": 3.990069161198794,
      "grad_norm": 1.6735970973968506,
      "learning_rate": 6.680067793937961e-05,
      "loss": 0.5963,
      "step": 11250
    },
    {
      "epoch": 4.007802801915234,
      "grad_norm": 1.364991307258606,
      "learning_rate": 6.660754404635214e-05,
      "loss": 0.6485,
      "step": 11300
    },
    {
      "epoch": 4.007802801915234,
      "eval_loss": 0.3711021840572357,
      "eval_runtime": 753.3156,
      "eval_samples_per_second": 26.547,
      "eval_steps_per_second": 3.319,
      "eval_wer": 0.11556830882153893,
      "step": 11300
    },
    {
      "epoch": 4.025536442631672,
      "grad_norm": 1.197075605392456,
      "learning_rate": 6.641046864530369e-05,
      "loss": 0.5784,
      "step": 11350
    },
    {
      "epoch": 4.043270083348111,
      "grad_norm": 1.0990551710128784,
      "learning_rate": 6.621339324425524e-05,
      "loss": 0.6236,
      "step": 11400
    },
    {
      "epoch": 4.043270083348111,
      "eval_loss": 0.33450716733932495,
      "eval_runtime": 754.3848,
      "eval_samples_per_second": 26.509,
      "eval_steps_per_second": 3.314,
      "eval_wer": 0.11497275536288155,
      "step": 11400
    },
    {
      "epoch": 4.06100372406455,
      "grad_norm": 1.0218569040298462,
      "learning_rate": 6.60163178432068e-05,
      "loss": 0.5906,
      "step": 11450
    },
    {
      "epoch": 4.07873736478099,
      "grad_norm": 1.5361216068267822,
      "learning_rate": 6.581924244215836e-05,
      "loss": 0.5974,
      "step": 11500
    },
    {
      "epoch": 4.07873736478099,
      "eval_loss": 0.3631030023097992,
      "eval_runtime": 758.0673,
      "eval_samples_per_second": 26.38,
      "eval_steps_per_second": 3.298,
      "eval_wer": 0.1145048205025079,
      "step": 11500
    },
    {
      "epoch": 4.0964710054974285,
      "grad_norm": 1.2547478675842285,
      "learning_rate": 6.562216704110992e-05,
      "loss": 0.5711,
      "step": 11550
    },
    {
      "epoch": 4.114204646213867,
      "grad_norm": 1.2206798791885376,
      "learning_rate": 6.542509164006148e-05,
      "loss": 0.5766,
      "step": 11600
    },
    {
      "epoch": 4.114204646213867,
      "eval_loss": 0.36153459548950195,
      "eval_runtime": 773.4539,
      "eval_samples_per_second": 25.855,
      "eval_steps_per_second": 3.232,
      "eval_wer": 0.11417223870092001,
      "step": 11600
    },
    {
      "epoch": 4.131938286930307,
      "grad_norm": 1.2216163873672485,
      "learning_rate": 6.522801623901304e-05,
      "loss": 0.5826,
      "step": 11650
    },
    {
      "epoch": 4.149671927646746,
      "grad_norm": 1.0232698917388916,
      "learning_rate": 6.50309408379646e-05,
      "loss": 0.6016,
      "step": 11700
    },
    {
      "epoch": 4.149671927646746,
      "eval_loss": 0.36308571696281433,
      "eval_runtime": 769.6318,
      "eval_samples_per_second": 25.984,
      "eval_steps_per_second": 3.248,
      "eval_wer": 0.11473685431756922,
      "step": 11700
    },
    {
      "epoch": 4.1674055683631845,
      "grad_norm": 3.8667306900024414,
      "learning_rate": 6.483386543691616e-05,
      "loss": 0.5991,
      "step": 11750
    },
    {
      "epoch": 4.185139209079624,
      "grad_norm": 1.0088047981262207,
      "learning_rate": 6.463679003586772e-05,
      "loss": 0.591,
      "step": 11800
    },
    {
      "epoch": 4.185139209079624,
      "eval_loss": 0.3465220034122467,
      "eval_runtime": 761.0513,
      "eval_samples_per_second": 26.277,
      "eval_steps_per_second": 3.285,
      "eval_wer": 0.1151042411914163,
      "step": 11800
    },
    {
      "epoch": 4.202872849796063,
      "grad_norm": 1.09553062915802,
      "learning_rate": 6.443971463481928e-05,
      "loss": 0.574,
      "step": 11850
    },
    {
      "epoch": 4.220606490512502,
      "grad_norm": 0.9912450909614563,
      "learning_rate": 6.424263923377084e-05,
      "loss": 0.5841,
      "step": 11900
    },
    {
      "epoch": 4.220606490512502,
      "eval_loss": 0.3573213815689087,
      "eval_runtime": 774.0475,
      "eval_samples_per_second": 25.836,
      "eval_steps_per_second": 3.23,
      "eval_wer": 0.11596276630714317,
      "step": 11900
    },
    {
      "epoch": 4.2383401312289415,
      "grad_norm": 1.8685892820358276,
      "learning_rate": 6.40455638327224e-05,
      "loss": 0.5812,
      "step": 11950
    },
    {
      "epoch": 4.25607377194538,
      "grad_norm": 1.112633228302002,
      "learning_rate": 6.384848843167396e-05,
      "loss": 0.5765,
      "step": 12000
    },
    {
      "epoch": 4.25607377194538,
      "eval_loss": 0.3448832333087921,
      "eval_runtime": 773.4782,
      "eval_samples_per_second": 25.855,
      "eval_steps_per_second": 3.232,
      "eval_wer": 0.11409102686564855,
      "step": 12000
    },
    {
      "epoch": 4.273807412661819,
      "grad_norm": 0.9443071484565735,
      "learning_rate": 6.365141303062552e-05,
      "loss": 0.5985,
      "step": 12050
    },
    {
      "epoch": 4.291541053378259,
      "grad_norm": 1.3105647563934326,
      "learning_rate": 6.345433762957708e-05,
      "loss": 0.5788,
      "step": 12100
    },
    {
      "epoch": 4.291541053378259,
      "eval_loss": 0.3477090299129486,
      "eval_runtime": 771.6755,
      "eval_samples_per_second": 25.915,
      "eval_steps_per_second": 3.24,
      "eval_wer": 0.11396727549761586,
      "step": 12100
    },
    {
      "epoch": 4.3092746940946975,
      "grad_norm": 1.1881986856460571,
      "learning_rate": 6.325726222852864e-05,
      "loss": 0.5909,
      "step": 12150
    },
    {
      "epoch": 4.327008334811136,
      "grad_norm": 1.0502586364746094,
      "learning_rate": 6.30601868274802e-05,
      "loss": 0.5849,
      "step": 12200
    },
    {
      "epoch": 4.327008334811136,
      "eval_loss": 0.32173559069633484,
      "eval_runtime": 764.5186,
      "eval_samples_per_second": 26.158,
      "eval_steps_per_second": 3.27,
      "eval_wer": 0.11362695923552592,
      "step": 12200
    },
    {
      "epoch": 4.344741975527576,
      "grad_norm": 1.1404516696929932,
      "learning_rate": 6.286311142643176e-05,
      "loss": 0.5868,
      "step": 12250
    },
    {
      "epoch": 4.362475616244015,
      "grad_norm": 1.1181423664093018,
      "learning_rate": 6.266603602538332e-05,
      "loss": 0.6014,
      "step": 12300
    },
    {
      "epoch": 4.362475616244015,
      "eval_loss": 0.3380019962787628,
      "eval_runtime": 757.5266,
      "eval_samples_per_second": 26.399,
      "eval_steps_per_second": 3.3,
      "eval_wer": 0.11423411438493636,
      "step": 12300
    },
    {
      "epoch": 4.380209256960454,
      "grad_norm": 1.144365668296814,
      "learning_rate": 6.246896062433486e-05,
      "loss": 0.6004,
      "step": 12350
    },
    {
      "epoch": 4.397942897676893,
      "grad_norm": 1.0921839475631714,
      "learning_rate": 6.227188522328642e-05,
      "loss": 0.5945,
      "step": 12400
    },
    {
      "epoch": 4.397942897676893,
      "eval_loss": 0.32527846097946167,
      "eval_runtime": 762.6187,
      "eval_samples_per_second": 26.223,
      "eval_steps_per_second": 3.278,
      "eval_wer": 0.11306621084912774,
      "step": 12400
    },
    {
      "epoch": 4.415676538393332,
      "grad_norm": 1.3026739358901978,
      "learning_rate": 6.207480982223798e-05,
      "loss": 0.5769,
      "step": 12450
    },
    {
      "epoch": 4.433410179109771,
      "grad_norm": 0.92041015625,
      "learning_rate": 6.188167592921051e-05,
      "loss": 0.5684,
      "step": 12500
    },
    {
      "epoch": 4.433410179109771,
      "eval_loss": 0.356031596660614,
      "eval_runtime": 770.2554,
      "eval_samples_per_second": 25.963,
      "eval_steps_per_second": 3.246,
      "eval_wer": 0.1133407841969503,
      "step": 12500
    },
    {
      "epoch": 4.4511438198262105,
      "grad_norm": 1.0151125192642212,
      "learning_rate": 6.168460052816207e-05,
      "loss": 0.6123,
      "step": 12550
    },
    {
      "epoch": 4.468877460542649,
      "grad_norm": 1.397149682044983,
      "learning_rate": 6.148752512711363e-05,
      "loss": 0.5936,
      "step": 12600
    },
    {
      "epoch": 4.468877460542649,
      "eval_loss": 0.33888956904411316,
      "eval_runtime": 753.9793,
      "eval_samples_per_second": 26.523,
      "eval_steps_per_second": 3.316,
      "eval_wer": 0.11363469369602797,
      "step": 12600
    },
    {
      "epoch": 4.486611101259088,
      "grad_norm": 3.4438021183013916,
      "learning_rate": 6.129044972606519e-05,
      "loss": 0.581,
      "step": 12650
    },
    {
      "epoch": 4.504344741975528,
      "grad_norm": 1.016675591468811,
      "learning_rate": 6.109337432501675e-05,
      "loss": 0.574,
      "step": 12700
    },
    {
      "epoch": 4.504344741975528,
      "eval_loss": 0.363617867231369,
      "eval_runtime": 766.9047,
      "eval_samples_per_second": 26.076,
      "eval_steps_per_second": 3.26,
      "eval_wer": 0.1133407841969503,
      "step": 12700
    },
    {
      "epoch": 4.522078382691967,
      "grad_norm": 1.0349383354187012,
      "learning_rate": 6.089629892396831e-05,
      "loss": 0.5778,
      "step": 12750
    },
    {
      "epoch": 4.539812023408405,
      "grad_norm": 1.5911245346069336,
      "learning_rate": 6.069922352291987e-05,
      "loss": 0.5793,
      "step": 12800
    },
    {
      "epoch": 4.539812023408405,
      "eval_loss": 0.337098091840744,
      "eval_runtime": 769.6912,
      "eval_samples_per_second": 25.982,
      "eval_steps_per_second": 3.248,
      "eval_wer": 0.11099724266483102,
      "step": 12800
    },
    {
      "epoch": 4.557545664124845,
      "grad_norm": 1.0763293504714966,
      "learning_rate": 6.050214812187143e-05,
      "loss": 0.5659,
      "step": 12850
    },
    {
      "epoch": 4.575279304841284,
      "grad_norm": 1.0174633264541626,
      "learning_rate": 6.030507272082299e-05,
      "loss": 0.5839,
      "step": 12900
    },
    {
      "epoch": 4.575279304841284,
      "eval_loss": 0.3414202332496643,
      "eval_runtime": 772.5023,
      "eval_samples_per_second": 25.887,
      "eval_steps_per_second": 3.236,
      "eval_wer": 0.11133369169666993,
      "step": 12900
    },
    {
      "epoch": 4.593012945557723,
      "grad_norm": 1.0420581102371216,
      "learning_rate": 6.010799731977455e-05,
      "loss": 0.597,
      "step": 12950
    },
    {
      "epoch": 4.610746586274162,
      "grad_norm": 0.9075919985771179,
      "learning_rate": 5.99109219187261e-05,
      "loss": 0.5998,
      "step": 13000
    },
    {
      "epoch": 4.610746586274162,
      "eval_loss": 0.32466959953308105,
      "eval_runtime": 767.8471,
      "eval_samples_per_second": 26.044,
      "eval_steps_per_second": 3.256,
      "eval_wer": 0.11036301690366343,
      "step": 13000
    },
    {
      "epoch": 4.628480226990601,
      "grad_norm": 1.0853214263916016,
      "learning_rate": 5.971384651767766e-05,
      "loss": 0.5567,
      "step": 13050
    },
    {
      "epoch": 4.64621386770704,
      "grad_norm": 1.1093487739562988,
      "learning_rate": 5.951677111662922e-05,
      "loss": 0.5818,
      "step": 13100
    },
    {
      "epoch": 4.64621386770704,
      "eval_loss": 0.3176406919956207,
      "eval_runtime": 771.9205,
      "eval_samples_per_second": 25.907,
      "eval_steps_per_second": 3.239,
      "eval_wer": 0.10981773743826934,
      "step": 13100
    },
    {
      "epoch": 4.66394750842348,
      "grad_norm": 1.1206387281417847,
      "learning_rate": 5.931969571558078e-05,
      "loss": 0.5752,
      "step": 13150
    },
    {
      "epoch": 4.681681149139918,
      "grad_norm": 0.8461987972259521,
      "learning_rate": 5.912262031453234e-05,
      "loss": 0.5955,
      "step": 13200
    },
    {
      "epoch": 4.681681149139918,
      "eval_loss": 0.3341124951839447,
      "eval_runtime": 752.886,
      "eval_samples_per_second": 26.562,
      "eval_steps_per_second": 3.321,
      "eval_wer": 0.11034368075240832,
      "step": 13200
    },
    {
      "epoch": 4.699414789856357,
      "grad_norm": 0.9300819039344788,
      "learning_rate": 5.89255449134839e-05,
      "loss": 0.5602,
      "step": 13250
    },
    {
      "epoch": 4.717148430572797,
      "grad_norm": 1.6319671869277954,
      "learning_rate": 5.872846951243546e-05,
      "loss": 0.5629,
      "step": 13300
    },
    {
      "epoch": 4.717148430572797,
      "eval_loss": 0.3509959876537323,
      "eval_runtime": 770.3389,
      "eval_samples_per_second": 25.96,
      "eval_steps_per_second": 3.245,
      "eval_wer": 0.11103204773709022,
      "step": 13300
    },
    {
      "epoch": 4.734882071289236,
      "grad_norm": 1.2219165563583374,
      "learning_rate": 5.853139411138702e-05,
      "loss": 0.5839,
      "step": 13350
    },
    {
      "epoch": 4.7526157120056745,
      "grad_norm": 1.3702143430709839,
      "learning_rate": 5.833431871033858e-05,
      "loss": 0.5622,
      "step": 13400
    },
    {
      "epoch": 4.7526157120056745,
      "eval_loss": 0.34601202607154846,
      "eval_runtime": 768.0312,
      "eval_samples_per_second": 26.038,
      "eval_steps_per_second": 3.255,
      "eval_wer": 0.11050223719270022,
      "step": 13400
    },
    {
      "epoch": 4.770349352722114,
      "grad_norm": 0.9461357593536377,
      "learning_rate": 5.813724330929014e-05,
      "loss": 0.5691,
      "step": 13450
    },
    {
      "epoch": 4.788082993438553,
      "grad_norm": 1.2160972356796265,
      "learning_rate": 5.794016790824169e-05,
      "loss": 0.5629,
      "step": 13500
    },
    {
      "epoch": 4.788082993438553,
      "eval_loss": 0.32572513818740845,
      "eval_runtime": 769.6083,
      "eval_samples_per_second": 25.985,
      "eval_steps_per_second": 3.248,
      "eval_wer": 0.10991055096429386,
      "step": 13500
    },
    {
      "epoch": 4.805816634154992,
      "grad_norm": 1.1910457611083984,
      "learning_rate": 5.774309250719325e-05,
      "loss": 0.5742,
      "step": 13550
    },
    {
      "epoch": 4.823550274871431,
      "grad_norm": 1.1620553731918335,
      "learning_rate": 5.754601710614481e-05,
      "loss": 0.5787,
      "step": 13600
    },
    {
      "epoch": 4.823550274871431,
      "eval_loss": 0.3331854045391083,
      "eval_runtime": 773.2495,
      "eval_samples_per_second": 25.862,
      "eval_steps_per_second": 3.233,
      "eval_wer": 0.11223475634515803,
      "step": 13600
    },
    {
      "epoch": 4.84128391558787,
      "grad_norm": 1.1764233112335205,
      "learning_rate": 5.734894170509637e-05,
      "loss": 0.5988,
      "step": 13650
    },
    {
      "epoch": 4.859017556304309,
      "grad_norm": 0.9258459806442261,
      "learning_rate": 5.715186630404793e-05,
      "loss": 0.5537,
      "step": 13700
    },
    {
      "epoch": 4.859017556304309,
      "eval_loss": 0.3338596522808075,
      "eval_runtime": 763.1137,
      "eval_samples_per_second": 26.206,
      "eval_steps_per_second": 3.276,
      "eval_wer": 0.11010391247684496,
      "step": 13700
    },
    {
      "epoch": 4.876751197020749,
      "grad_norm": 1.2219033241271973,
      "learning_rate": 5.695479090299949e-05,
      "loss": 0.5862,
      "step": 13750
    },
    {
      "epoch": 4.8944848377371875,
      "grad_norm": 1.2020084857940674,
      "learning_rate": 5.675771550195105e-05,
      "loss": 0.5767,
      "step": 13800
    },
    {
      "epoch": 4.8944848377371875,
      "eval_loss": 0.33260378241539,
      "eval_runtime": 766.6215,
      "eval_samples_per_second": 26.086,
      "eval_steps_per_second": 3.261,
      "eval_wer": 0.10964757930722437,
      "step": 13800
    },
    {
      "epoch": 4.912218478453626,
      "grad_norm": 1.1037397384643555,
      "learning_rate": 5.656064010090261e-05,
      "loss": 0.5895,
      "step": 13850
    },
    {
      "epoch": 4.929952119170066,
      "grad_norm": 1.1786136627197266,
      "learning_rate": 5.636356469985417e-05,
      "loss": 0.5472,
      "step": 13900
    },
    {
      "epoch": 4.929952119170066,
      "eval_loss": 0.3311998248100281,
      "eval_runtime": 775.107,
      "eval_samples_per_second": 25.8,
      "eval_steps_per_second": 3.225,
      "eval_wer": 0.10941941272241408,
      "step": 13900
    },
    {
      "epoch": 4.947685759886505,
      "grad_norm": 1.0873186588287354,
      "learning_rate": 5.616648929880573e-05,
      "loss": 0.5591,
      "step": 13950
    },
    {
      "epoch": 4.9654194006029435,
      "grad_norm": 0.9817279577255249,
      "learning_rate": 5.596941389775728e-05,
      "loss": 0.5759,
      "step": 14000
    },
    {
      "epoch": 4.9654194006029435,
      "eval_loss": 0.3572753965854645,
      "eval_runtime": 786.3108,
      "eval_samples_per_second": 25.433,
      "eval_steps_per_second": 3.179,
      "eval_wer": 0.10891280555953022,
      "step": 14000
    },
    {
      "epoch": 4.983153041319383,
      "grad_norm": 1.2906430959701538,
      "learning_rate": 5.577233849670884e-05,
      "loss": 0.5616,
      "step": 14050
    },
    {
      "epoch": 5.000886682035822,
      "grad_norm": 0.5027657151222229,
      "learning_rate": 5.55752630956604e-05,
      "loss": 0.5978,
      "step": 14100
    },
    {
      "epoch": 5.000886682035822,
      "eval_loss": 0.3422541320323944,
      "eval_runtime": 767.2084,
      "eval_samples_per_second": 26.066,
      "eval_steps_per_second": 3.259,
      "eval_wer": 0.10994535603655306,
      "step": 14100
    },
    {
      "epoch": 5.018620322752261,
      "grad_norm": 0.4167395830154419,
      "learning_rate": 5.537818769461196e-05,
      "loss": 0.5644,
      "step": 14150
    },
    {
      "epoch": 5.0363539634687005,
      "grad_norm": 0.49858036637306213,
      "learning_rate": 5.518111229356352e-05,
      "loss": 0.5798,
      "step": 14200
    },
    {
      "epoch": 5.0363539634687005,
      "eval_loss": 0.3380040228366852,
      "eval_runtime": 788.4771,
      "eval_samples_per_second": 25.363,
      "eval_steps_per_second": 3.171,
      "eval_wer": 0.11084642068504116,
      "step": 14200
    },
    {
      "epoch": 5.054087604185139,
      "grad_norm": 0.5352862477302551,
      "learning_rate": 5.498403689251508e-05,
      "loss": 0.5714,
      "step": 14250
    },
    {
      "epoch": 5.071821244901578,
      "grad_norm": 0.5599411725997925,
      "learning_rate": 5.478696149146664e-05,
      "loss": 0.5546,
      "step": 14300
    },
    {
      "epoch": 5.071821244901578,
      "eval_loss": 0.3523128032684326,
      "eval_runtime": 772.5223,
      "eval_samples_per_second": 25.887,
      "eval_steps_per_second": 3.236,
      "eval_wer": 0.1094232799526651,
      "step": 14300
    },
    {
      "epoch": 5.089554885618018,
      "grad_norm": 0.5465518236160278,
      "learning_rate": 5.45898860904182e-05,
      "loss": 0.5735,
      "step": 14350
    },
    {
      "epoch": 5.1072885263344565,
      "grad_norm": 0.5228714346885681,
      "learning_rate": 5.439281068936976e-05,
      "loss": 0.5564,
      "step": 14400
    },
    {
      "epoch": 5.1072885263344565,
      "eval_loss": 0.34048911929130554,
      "eval_runtime": 773.3135,
      "eval_samples_per_second": 25.86,
      "eval_steps_per_second": 3.233,
      "eval_wer": 0.10964371207697335,
      "step": 14400
    },
    {
      "epoch": 5.125022167050895,
      "grad_norm": 0.5018072724342346,
      "learning_rate": 5.419573528832132e-05,
      "loss": 0.5813,
      "step": 14450
    },
    {
      "epoch": 5.142755807767335,
      "grad_norm": 0.5472160577774048,
      "learning_rate": 5.399865988727287e-05,
      "loss": 0.5841,
      "step": 14500
    },
    {
      "epoch": 5.142755807767335,
      "eval_loss": 0.3293592035770416,
      "eval_runtime": 763.2786,
      "eval_samples_per_second": 26.2,
      "eval_steps_per_second": 3.275,
      "eval_wer": 0.10912163599308539,
      "step": 14500
    },
    {
      "epoch": 5.160489448483774,
      "grad_norm": 0.47907865047454834,
      "learning_rate": 5.380158448622443e-05,
      "loss": 0.5653,
      "step": 14550
    },
    {
      "epoch": 5.178223089200213,
      "grad_norm": 0.8444381952285767,
      "learning_rate": 5.360450908517599e-05,
      "loss": 0.5575,
      "step": 14600
    },
    {
      "epoch": 5.178223089200213,
      "eval_loss": 0.3652788996696472,
      "eval_runtime": 770.9705,
      "eval_samples_per_second": 25.939,
      "eval_steps_per_second": 3.243,
      "eval_wer": 0.11132595723616788,
      "step": 14600
    },
    {
      "epoch": 5.195956729916652,
      "grad_norm": 0.45229053497314453,
      "learning_rate": 5.340743368412755e-05,
      "loss": 0.5554,
      "step": 14650
    },
    {
      "epoch": 5.213690370633091,
      "grad_norm": 0.4747680723667145,
      "learning_rate": 5.321035828307911e-05,
      "loss": 0.5551,
      "step": 14700
    },
    {
      "epoch": 5.213690370633091,
      "eval_loss": 0.30686354637145996,
      "eval_runtime": 791.4128,
      "eval_samples_per_second": 25.269,
      "eval_steps_per_second": 3.159,
      "eval_wer": 0.1091757772165997,
      "step": 14700
    },
    {
      "epoch": 5.23142401134953,
      "grad_norm": 0.5635706186294556,
      "learning_rate": 5.301328288203067e-05,
      "loss": 0.5603,
      "step": 14750
    },
    {
      "epoch": 5.2491576520659695,
      "grad_norm": 0.4463827610015869,
      "learning_rate": 5.281620748098223e-05,
      "loss": 0.5536,
      "step": 14800
    },
    {
      "epoch": 5.2491576520659695,
      "eval_loss": 0.32911232113838196,
      "eval_runtime": 777.3629,
      "eval_samples_per_second": 25.725,
      "eval_steps_per_second": 3.216,
      "eval_wer": 0.10777970709598078,
      "step": 14800
    },
    {
      "epoch": 5.266891292782408,
      "grad_norm": 0.5064985156059265,
      "learning_rate": 5.261913207993379e-05,
      "loss": 0.5674,
      "step": 14850
    },
    {
      "epoch": 5.284624933498847,
      "grad_norm": 0.46493926644325256,
      "learning_rate": 5.242205667888535e-05,
      "loss": 0.567,
      "step": 14900
    },
    {
      "epoch": 5.284624933498847,
      "eval_loss": 0.3413372039794922,
      "eval_runtime": 794.0241,
      "eval_samples_per_second": 25.186,
      "eval_steps_per_second": 3.149,
      "eval_wer": 0.10977519790550809,
      "step": 14900
    },
    {
      "epoch": 5.302358574215287,
      "grad_norm": 0.5114293694496155,
      "learning_rate": 5.222498127783691e-05,
      "loss": 0.5312,
      "step": 14950
    },
    {
      "epoch": 5.320092214931726,
      "grad_norm": 0.4627464711666107,
      "learning_rate": 5.202790587678846e-05,
      "loss": 0.5291,
      "step": 15000
    },
    {
      "epoch": 5.320092214931726,
      "eval_loss": 0.3125433623790741,
      "eval_runtime": 785.4551,
      "eval_samples_per_second": 25.46,
      "eval_steps_per_second": 3.183,
      "eval_wer": 0.10877745250074444,
      "step": 15000
    },
    {
      "epoch": 5.337825855648164,
      "grad_norm": 0.5419732928276062,
      "learning_rate": 5.183083047574002e-05,
      "loss": 0.5702,
      "step": 15050
    },
    {
      "epoch": 5.355559496364604,
      "grad_norm": 0.5647068619728088,
      "learning_rate": 5.163375507469158e-05,
      "loss": 0.5504,
      "step": 15100
    },
    {
      "epoch": 5.355559496364604,
      "eval_loss": 0.3241090774536133,
      "eval_runtime": 775.1906,
      "eval_samples_per_second": 25.798,
      "eval_steps_per_second": 3.225,
      "eval_wer": 0.10846420685041167,
      "step": 15100
    },
    {
      "epoch": 5.373293137081043,
      "grad_norm": 0.41885921359062195,
      "learning_rate": 5.143667967364314e-05,
      "loss": 0.5469,
      "step": 15150
    },
    {
      "epoch": 5.391026777797482,
      "grad_norm": 0.4863746166229248,
      "learning_rate": 5.12396042725947e-05,
      "loss": 0.5487,
      "step": 15200
    },
    {
      "epoch": 5.391026777797482,
      "eval_loss": 0.3309360146522522,
      "eval_runtime": 776.9861,
      "eval_samples_per_second": 25.738,
      "eval_steps_per_second": 3.218,
      "eval_wer": 0.10983707358952445,
      "step": 15200
    },
    {
      "epoch": 5.408760418513921,
      "grad_norm": 0.46567901968955994,
      "learning_rate": 5.104252887154626e-05,
      "loss": 0.5674,
      "step": 15250
    },
    {
      "epoch": 5.42649405923036,
      "grad_norm": 0.47125187516212463,
      "learning_rate": 5.084545347049782e-05,
      "loss": 0.5384,
      "step": 15300
    },
    {
      "epoch": 5.42649405923036,
      "eval_loss": 0.3077698349952698,
      "eval_runtime": 775.6257,
      "eval_samples_per_second": 25.783,
      "eval_steps_per_second": 3.223,
      "eval_wer": 0.10793439630602167,
      "step": 15300
    },
    {
      "epoch": 5.444227699946799,
      "grad_norm": 0.5137518644332886,
      "learning_rate": 5.064837806944938e-05,
      "loss": 0.5493,
      "step": 15350
    },
    {
      "epoch": 5.461961340663239,
      "grad_norm": 0.6118910908699036,
      "learning_rate": 5.045130266840094e-05,
      "loss": 0.56,
      "step": 15400
    },
    {
      "epoch": 5.461961340663239,
      "eval_loss": 0.29588037729263306,
      "eval_runtime": 775.4671,
      "eval_samples_per_second": 25.788,
      "eval_steps_per_second": 3.224,
      "eval_wer": 0.10823604026560138,
      "step": 15400
    },
    {
      "epoch": 5.479694981379677,
      "grad_norm": 0.47233837842941284,
      "learning_rate": 5.02542272673525e-05,
      "loss": 0.5464,
      "step": 15450
    },
    {
      "epoch": 5.497428622096116,
      "grad_norm": 0.5792891383171082,
      "learning_rate": 5.005715186630405e-05,
      "loss": 0.5414,
      "step": 15500
    },
    {
      "epoch": 5.497428622096116,
      "eval_loss": 0.33451876044273376,
      "eval_runtime": 785.1179,
      "eval_samples_per_second": 25.471,
      "eval_steps_per_second": 3.184,
      "eval_wer": 0.10750900097840925,
      "step": 15500
    },
    {
      "epoch": 5.515162262812556,
      "grad_norm": 0.5160620212554932,
      "learning_rate": 4.986007646525561e-05,
      "loss": 0.5564,
      "step": 15550
    },
    {
      "epoch": 5.532895903528995,
      "grad_norm": 0.5860280394554138,
      "learning_rate": 4.966300106420717e-05,
      "loss": 0.5466,
      "step": 15600
    },
    {
      "epoch": 5.532895903528995,
      "eval_loss": 0.32057639956474304,
      "eval_runtime": 778.3259,
      "eval_samples_per_second": 25.694,
      "eval_steps_per_second": 3.212,
      "eval_wer": 0.1093536698081467,
      "step": 15600
    },
    {
      "epoch": 5.550629544245433,
      "grad_norm": 0.5079092979431152,
      "learning_rate": 4.946592566315872e-05,
      "loss": 0.551,
      "step": 15650
    },
    {
      "epoch": 5.568363184961873,
      "grad_norm": 0.518149733543396,
      "learning_rate": 4.926885026211028e-05,
      "loss": 0.5378,
      "step": 15700
    },
    {
      "epoch": 5.568363184961873,
      "eval_loss": 0.339162677526474,
      "eval_runtime": 777.3712,
      "eval_samples_per_second": 25.725,
      "eval_steps_per_second": 3.216,
      "eval_wer": 0.10675489107945998,
      "step": 15700
    },
    {
      "epoch": 5.586096825678312,
      "grad_norm": 0.5283700823783875,
      "learning_rate": 4.907177486106184e-05,
      "loss": 0.5382,
      "step": 15750
    },
    {
      "epoch": 5.603830466394751,
      "grad_norm": 0.3787843883037567,
      "learning_rate": 4.88746994600134e-05,
      "loss": 0.5543,
      "step": 15800
    },
    {
      "epoch": 5.603830466394751,
      "eval_loss": 0.33194154500961304,
      "eval_runtime": 776.5698,
      "eval_samples_per_second": 25.752,
      "eval_steps_per_second": 3.219,
      "eval_wer": 0.10831725210087284,
      "step": 15800
    },
    {
      "epoch": 5.62156410711119,
      "grad_norm": 0.4988471567630768,
      "learning_rate": 4.867762405896496e-05,
      "loss": 0.552,
      "step": 15850
    },
    {
      "epoch": 5.639297747827629,
      "grad_norm": 0.5286915302276611,
      "learning_rate": 4.848054865791652e-05,
      "loss": 0.5416,
      "step": 15900
    },
    {
      "epoch": 5.639297747827629,
      "eval_loss": 0.33167511224746704,
      "eval_runtime": 763.5709,
      "eval_samples_per_second": 26.19,
      "eval_steps_per_second": 3.274,
      "eval_wer": 0.1077294331027175,
      "step": 15900
    },
    {
      "epoch": 5.657031388544068,
      "grad_norm": 0.5378760695457458,
      "learning_rate": 4.828347325686808e-05,
      "loss": 0.5231,
      "step": 15950
    },
    {
      "epoch": 5.674765029260508,
      "grad_norm": 0.4666192829608917,
      "learning_rate": 4.808639785581964e-05,
      "loss": 0.5521,
      "step": 16000
    },
    {
      "epoch": 5.674765029260508,
      "eval_loss": 0.31287309527397156,
      "eval_runtime": 760.8556,
      "eval_samples_per_second": 26.284,
      "eval_steps_per_second": 3.286,
      "eval_wer": 0.10627535452833327,
      "step": 16000
    },
    {
      "epoch": 5.692498669976946,
      "grad_norm": 0.4496113657951355,
      "learning_rate": 4.78893224547712e-05,
      "loss": 0.5594,
      "step": 16050
    },
    {
      "epoch": 5.710232310693385,
      "grad_norm": 0.5252534747123718,
      "learning_rate": 4.769224705372275e-05,
      "loss": 0.5455,
      "step": 16100
    },
    {
      "epoch": 5.710232310693385,
      "eval_loss": 0.33696094155311584,
      "eval_runtime": 774.1399,
      "eval_samples_per_second": 25.833,
      "eval_steps_per_second": 3.229,
      "eval_wer": 0.10717255194657034,
      "step": 16100
    },
    {
      "epoch": 5.727965951409825,
      "grad_norm": 0.5219541788101196,
      "learning_rate": 4.749517165267431e-05,
      "loss": 0.5583,
      "step": 16150
    },
    {
      "epoch": 5.745699592126264,
      "grad_norm": 0.47290799021720886,
      "learning_rate": 4.729809625162587e-05,
      "loss": 0.5191,
      "step": 16200
    },
    {
      "epoch": 5.745699592126264,
      "eval_loss": 0.3281501531600952,
      "eval_runtime": 777.4521,
      "eval_samples_per_second": 25.722,
      "eval_steps_per_second": 3.216,
      "eval_wer": 0.10653445895515173,
      "step": 16200
    },
    {
      "epoch": 5.7634332328427025,
      "grad_norm": 0.4632754623889923,
      "learning_rate": 4.710102085057743e-05,
      "loss": 0.5458,
      "step": 16250
    },
    {
      "epoch": 5.781166873559142,
      "grad_norm": 0.4366455674171448,
      "learning_rate": 4.690394544952899e-05,
      "loss": 0.5671,
      "step": 16300
    },
    {
      "epoch": 5.781166873559142,
      "eval_loss": 0.30532076954841614,
      "eval_runtime": 764.3376,
      "eval_samples_per_second": 26.164,
      "eval_steps_per_second": 3.271,
      "eval_wer": 0.10748579759690312,
      "step": 16300
    },
    {
      "epoch": 5.798900514275581,
      "grad_norm": 0.5558756589889526,
      "learning_rate": 4.670687004848055e-05,
      "loss": 0.5734,
      "step": 16350
    },
    {
      "epoch": 5.81663415499202,
      "grad_norm": 0.518875002861023,
      "learning_rate": 4.650979464743211e-05,
      "loss": 0.5543,
      "step": 16400
    },
    {
      "epoch": 5.81663415499202,
      "eval_loss": 0.324423223733902,
      "eval_runtime": 783.4364,
      "eval_samples_per_second": 25.526,
      "eval_steps_per_second": 3.191,
      "eval_wer": 0.10643777819887618,
      "step": 16400
    },
    {
      "epoch": 5.834367795708459,
      "grad_norm": 0.4534156918525696,
      "learning_rate": 4.631271924638367e-05,
      "loss": 0.5426,
      "step": 16450
    },
    {
      "epoch": 5.852101436424898,
      "grad_norm": 0.640758216381073,
      "learning_rate": 4.611564384533523e-05,
      "loss": 0.5256,
      "step": 16500
    },
    {
      "epoch": 5.852101436424898,
      "eval_loss": 0.323888897895813,
      "eval_runtime": 772.5712,
      "eval_samples_per_second": 25.885,
      "eval_steps_per_second": 3.236,
      "eval_wer": 0.10801947537154415,
      "step": 16500
    },
    {
      "epoch": 5.869835077141337,
      "grad_norm": 0.557942271232605,
      "learning_rate": 4.591856844428679e-05,
      "loss": 0.5451,
      "step": 16550
    },
    {
      "epoch": 5.887568717857777,
      "grad_norm": 0.48763394355773926,
      "learning_rate": 4.572149304323834e-05,
      "loss": 0.554,
      "step": 16600
    },
    {
      "epoch": 5.887568717857777,
      "eval_loss": 0.30369263887405396,
      "eval_runtime": 774.7565,
      "eval_samples_per_second": 25.812,
      "eval_steps_per_second": 3.227,
      "eval_wer": 0.10749353205740517,
      "step": 16600
    },
    {
      "epoch": 5.9053023585742155,
      "grad_norm": 0.5504609942436218,
      "learning_rate": 4.55244176421899e-05,
      "loss": 0.549,
      "step": 16650
    },
    {
      "epoch": 5.923035999290654,
      "grad_norm": 0.5510936379432678,
      "learning_rate": 4.532734224114146e-05,
      "loss": 0.5305,
      "step": 16700
    },
    {
      "epoch": 5.923035999290654,
      "eval_loss": 0.33099064230918884,
      "eval_runtime": 774.2446,
      "eval_samples_per_second": 25.829,
      "eval_steps_per_second": 3.229,
      "eval_wer": 0.10733497561711326,
      "step": 16700
    },
    {
      "epoch": 5.940769640007094,
      "grad_norm": 0.6559057235717773,
      "learning_rate": 4.513026684009302e-05,
      "loss": 0.5395,
      "step": 16750
    },
    {
      "epoch": 5.958503280723533,
      "grad_norm": 0.5104494690895081,
      "learning_rate": 4.493319143904458e-05,
      "loss": 0.5524,
      "step": 16800
    },
    {
      "epoch": 5.958503280723533,
      "eval_loss": 0.309040904045105,
      "eval_runtime": 772.9876,
      "eval_samples_per_second": 25.871,
      "eval_steps_per_second": 3.234,
      "eval_wer": 0.10747806313640108,
      "step": 16800
    },
    {
      "epoch": 5.9762369214399715,
      "grad_norm": 0.6451519131660461,
      "learning_rate": 4.473611603799614e-05,
      "loss": 0.5469,
      "step": 16850
    },
    {
      "epoch": 5.99397056215641,
      "grad_norm": 2.277188777923584,
      "learning_rate": 4.45390406369477e-05,
      "loss": 0.5459,
      "step": 16900
    },
    {
      "epoch": 5.99397056215641,
      "eval_loss": 0.30763307213783264,
      "eval_runtime": 788.9525,
      "eval_samples_per_second": 25.348,
      "eval_steps_per_second": 3.169,
      "eval_wer": 0.10618254100230874,
      "step": 16900
    },
    {
      "epoch": 6.01170420287285,
      "grad_norm": 1.6997604370117188,
      "learning_rate": 4.4345906743920226e-05,
      "loss": 0.5282,
      "step": 16950
    },
    {
      "epoch": 6.029437843589289,
      "grad_norm": 1.8339415788650513,
      "learning_rate": 4.414883134287178e-05,
      "loss": 0.5173,
      "step": 17000
    },
    {
      "epoch": 6.029437843589289,
      "eval_loss": 0.3104231059551239,
      "eval_runtime": 762.0985,
      "eval_samples_per_second": 26.241,
      "eval_steps_per_second": 3.28,
      "eval_wer": 0.10540136049160231,
      "step": 17000
    },
    {
      "epoch": 6.047171484305728,
      "grad_norm": 2.429075002670288,
      "learning_rate": 4.395175594182334e-05,
      "loss": 0.5188,
      "step": 17050
    },
    {
      "epoch": 6.064905125022167,
      "grad_norm": 2.4556660652160645,
      "learning_rate": 4.37546805407749e-05,
      "loss": 0.5422,
      "step": 17100
    },
    {
      "epoch": 6.064905125022167,
      "eval_loss": 0.3143540918827057,
      "eval_runtime": 780.4471,
      "eval_samples_per_second": 25.624,
      "eval_steps_per_second": 3.203,
      "eval_wer": 0.10489088609846742,
      "step": 17100
    },
    {
      "epoch": 6.082638765738606,
      "grad_norm": 4.733241558074951,
      "learning_rate": 4.355760513972646e-05,
      "loss": 0.5345,
      "step": 17150
    },
    {
      "epoch": 6.100372406455045,
      "grad_norm": 1.884941577911377,
      "learning_rate": 4.336052973867802e-05,
      "loss": 0.5324,
      "step": 17200
    },
    {
      "epoch": 6.100372406455045,
      "eval_loss": 0.32236722111701965,
      "eval_runtime": 782.1054,
      "eval_samples_per_second": 25.569,
      "eval_steps_per_second": 3.197,
      "eval_wer": 0.10477873642118778,
      "step": 17200
    },
    {
      "epoch": 6.1181060471714845,
      "grad_norm": 2.217897891998291,
      "learning_rate": 4.316345433762958e-05,
      "loss": 0.544,
      "step": 17250
    },
    {
      "epoch": 6.135839687887923,
      "grad_norm": 11.54241943359375,
      "learning_rate": 4.296637893658114e-05,
      "loss": 0.5414,
      "step": 17300
    },
    {
      "epoch": 6.135839687887923,
      "eval_loss": 0.31017324328422546,
      "eval_runtime": 770.9916,
      "eval_samples_per_second": 25.938,
      "eval_steps_per_second": 3.243,
      "eval_wer": 0.1046240472111469,
      "step": 17300
    },
    {
      "epoch": 6.153573328604362,
      "grad_norm": 1.6684668064117432,
      "learning_rate": 4.27693035355327e-05,
      "loss": 0.5228,
      "step": 17350
    },
    {
      "epoch": 6.171306969320802,
      "grad_norm": 1.427603006362915,
      "learning_rate": 4.2572228134484257e-05,
      "loss": 0.5326,
      "step": 17400
    },
    {
      "epoch": 6.171306969320802,
      "eval_loss": 0.31361421942710876,
      "eval_runtime": 788.1906,
      "eval_samples_per_second": 25.372,
      "eval_steps_per_second": 3.172,
      "eval_wer": 0.10491795671022457,
      "step": 17400
    },
    {
      "epoch": 6.189040610037241,
      "grad_norm": 9.481281280517578,
      "learning_rate": 4.2375152733435816e-05,
      "loss": 0.5341,
      "step": 17450
    },
    {
      "epoch": 6.206774250753679,
      "grad_norm": 2.632479190826416,
      "learning_rate": 4.217807733238737e-05,
      "loss": 0.5162,
      "step": 17500
    },
    {
      "epoch": 6.206774250753679,
      "eval_loss": 0.314634770154953,
      "eval_runtime": 775.1326,
      "eval_samples_per_second": 25.799,
      "eval_steps_per_second": 3.225,
      "eval_wer": 0.10488315163796537,
      "step": 17500
    },
    {
      "epoch": 6.224507891470119,
      "grad_norm": 1.4359216690063477,
      "learning_rate": 4.198100193133893e-05,
      "loss": 0.5313,
      "step": 17550
    },
    {
      "epoch": 6.242241532186558,
      "grad_norm": 1.108155369758606,
      "learning_rate": 4.178392653029049e-05,
      "loss": 0.5535,
      "step": 17600
    },
    {
      "epoch": 6.242241532186558,
      "eval_loss": 0.29830101132392883,
      "eval_runtime": 758.6541,
      "eval_samples_per_second": 26.36,
      "eval_steps_per_second": 3.295,
      "eval_wer": 0.1051190526832777,
      "step": 17600
    },
    {
      "epoch": 6.259975172902997,
      "grad_norm": 1.5158690214157104,
      "learning_rate": 4.158685112924205e-05,
      "loss": 0.5379,
      "step": 17650
    },
    {
      "epoch": 6.277708813619436,
      "grad_norm": 1.6805895566940308,
      "learning_rate": 4.138977572819361e-05,
      "loss": 0.5293,
      "step": 17700
    },
    {
      "epoch": 6.277708813619436,
      "eval_loss": 0.32460522651672363,
      "eval_runtime": 765.9992,
      "eval_samples_per_second": 26.107,
      "eval_steps_per_second": 3.264,
      "eval_wer": 0.1045892421388877,
      "step": 17700
    },
    {
      "epoch": 6.295442454335875,
      "grad_norm": 4.462430477142334,
      "learning_rate": 4.119270032714517e-05,
      "loss": 0.558,
      "step": 17750
    },
    {
      "epoch": 6.313176095052314,
      "grad_norm": 2.521996259689331,
      "learning_rate": 4.099562492609673e-05,
      "loss": 0.5223,
      "step": 17800
    },
    {
      "epoch": 6.313176095052314,
      "eval_loss": 0.31216609477996826,
      "eval_runtime": 774.6313,
      "eval_samples_per_second": 25.816,
      "eval_steps_per_second": 3.227,
      "eval_wer": 0.10540136049160231,
      "step": 17800
    },
    {
      "epoch": 6.330909735768754,
      "grad_norm": 5.683049201965332,
      "learning_rate": 4.079854952504829e-05,
      "loss": 0.5026,
      "step": 17850
    },
    {
      "epoch": 6.348643376485192,
      "grad_norm": 2.0328476428985596,
      "learning_rate": 4.0601474123999846e-05,
      "loss": 0.5194,
      "step": 17900
    },
    {
      "epoch": 6.348643376485192,
      "eval_loss": 0.2989410161972046,
      "eval_runtime": 763.0697,
      "eval_samples_per_second": 26.207,
      "eval_steps_per_second": 3.276,
      "eval_wer": 0.10514999052528588,
      "step": 17900
    },
    {
      "epoch": 6.366377017201631,
      "grad_norm": 1.4685686826705933,
      "learning_rate": 4.0404398722951406e-05,
      "loss": 0.5208,
      "step": 17950
    },
    {
      "epoch": 6.384110657918071,
      "grad_norm": 1.8410977125167847,
      "learning_rate": 4.020732332190296e-05,
      "loss": 0.5484,
      "step": 18000
    },
    {
      "epoch": 6.384110657918071,
      "eval_loss": 0.31077077984809875,
      "eval_runtime": 762.845,
      "eval_samples_per_second": 26.215,
      "eval_steps_per_second": 3.277,
      "eval_wer": 0.10364563795763836,
      "step": 18000
    },
    {
      "epoch": 6.40184429863451,
      "grad_norm": 7.252791404724121,
      "learning_rate": 4.001024792085452e-05,
      "loss": 0.53,
      "step": 18050
    },
    {
      "epoch": 6.4195779393509484,
      "grad_norm": 2.190498113632202,
      "learning_rate": 3.981317251980608e-05,
      "loss": 0.5435,
      "step": 18100
    },
    {
      "epoch": 6.4195779393509484,
      "eval_loss": 0.314544141292572,
      "eval_runtime": 756.7762,
      "eval_samples_per_second": 26.425,
      "eval_steps_per_second": 3.303,
      "eval_wer": 0.1041290417390161,
      "step": 18100
    },
    {
      "epoch": 6.437311580067388,
      "grad_norm": 1.6891685724258423,
      "learning_rate": 3.961609711875764e-05,
      "loss": 0.5397,
      "step": 18150
    },
    {
      "epoch": 6.455045220783827,
      "grad_norm": 1.9545694589614868,
      "learning_rate": 3.94190217177092e-05,
      "loss": 0.5478,
      "step": 18200
    },
    {
      "epoch": 6.455045220783827,
      "eval_loss": 0.31186357140541077,
      "eval_runtime": 766.4209,
      "eval_samples_per_second": 26.093,
      "eval_steps_per_second": 3.262,
      "eval_wer": 0.10528147635382062,
      "step": 18200
    },
    {
      "epoch": 6.472778861500266,
      "grad_norm": 1.5606305599212646,
      "learning_rate": 3.922194631666076e-05,
      "loss": 0.5338,
      "step": 18250
    },
    {
      "epoch": 6.490512502216705,
      "grad_norm": 2.2529513835906982,
      "learning_rate": 3.902487091561232e-05,
      "loss": 0.5304,
      "step": 18300
    },
    {
      "epoch": 6.490512502216705,
      "eval_loss": 0.34230872988700867,
      "eval_runtime": 770.9394,
      "eval_samples_per_second": 25.94,
      "eval_steps_per_second": 3.243,
      "eval_wer": 0.10443068569859582,
      "step": 18300
    },
    {
      "epoch": 6.508246142933144,
      "grad_norm": 1.8992207050323486,
      "learning_rate": 3.8827795514563877e-05,
      "loss": 0.536,
      "step": 18350
    },
    {
      "epoch": 6.525979783649583,
      "grad_norm": 2.635328769683838,
      "learning_rate": 3.8630720113515436e-05,
      "loss": 0.543,
      "step": 18400
    },
    {
      "epoch": 6.525979783649583,
      "eval_loss": 0.32557085156440735,
      "eval_runtime": 776.3921,
      "eval_samples_per_second": 25.758,
      "eval_steps_per_second": 3.22,
      "eval_wer": 0.10363403626688529,
      "step": 18400
    },
    {
      "epoch": 6.543713424366023,
      "grad_norm": 1.4233932495117188,
      "learning_rate": 3.8433644712466996e-05,
      "loss": 0.5154,
      "step": 18450
    },
    {
      "epoch": 6.5614470650824614,
      "grad_norm": 3.1896352767944336,
      "learning_rate": 3.823656931141855e-05,
      "loss": 0.5237,
      "step": 18500
    },
    {
      "epoch": 6.5614470650824614,
      "eval_loss": 0.325893759727478,
      "eval_runtime": 772.9166,
      "eval_samples_per_second": 25.873,
      "eval_steps_per_second": 3.235,
      "eval_wer": 0.10395888360797113,
      "step": 18500
    },
    {
      "epoch": 6.5791807057989,
      "grad_norm": 1.7809407711029053,
      "learning_rate": 3.803949391037011e-05,
      "loss": 0.529,
      "step": 18550
    },
    {
      "epoch": 6.59691434651534,
      "grad_norm": 1.521924376487732,
      "learning_rate": 3.784241850932167e-05,
      "loss": 0.557,
      "step": 18600
    },
    {
      "epoch": 6.59691434651534,
      "eval_loss": 0.3289736807346344,
      "eval_runtime": 766.5041,
      "eval_samples_per_second": 26.09,
      "eval_steps_per_second": 3.262,
      "eval_wer": 0.10369977918115267,
      "step": 18600
    },
    {
      "epoch": 6.614647987231779,
      "grad_norm": 4.0644707679748535,
      "learning_rate": 3.764534310827323e-05,
      "loss": 0.5333,
      "step": 18650
    },
    {
      "epoch": 6.6323816279482175,
      "grad_norm": 1.3960994482040405,
      "learning_rate": 3.744826770722479e-05,
      "loss": 0.5644,
      "step": 18700
    },
    {
      "epoch": 6.6323816279482175,
      "eval_loss": 0.3231830894947052,
      "eval_runtime": 766.0427,
      "eval_samples_per_second": 26.106,
      "eval_steps_per_second": 3.264,
      "eval_wer": 0.10305781895948303,
      "step": 18700
    },
    {
      "epoch": 6.650115268664657,
      "grad_norm": 3.600665330886841,
      "learning_rate": 3.725119230617635e-05,
      "loss": 0.5339,
      "step": 18750
    },
    {
      "epoch": 6.667848909381096,
      "grad_norm": 1.977400779724121,
      "learning_rate": 3.705411690512791e-05,
      "loss": 0.5278,
      "step": 18800
    },
    {
      "epoch": 6.667848909381096,
      "eval_loss": 0.3113456964492798,
      "eval_runtime": 778.6386,
      "eval_samples_per_second": 25.683,
      "eval_steps_per_second": 3.211,
      "eval_wer": 0.10267883039488288,
      "step": 18800
    },
    {
      "epoch": 6.685582550097535,
      "grad_norm": 2.5466067790985107,
      "learning_rate": 3.6857041504079466e-05,
      "loss": 0.5191,
      "step": 18850
    },
    {
      "epoch": 6.7033161908139745,
      "grad_norm": 2.3586997985839844,
      "learning_rate": 3.6659966103031026e-05,
      "loss": 0.5486,
      "step": 18900
    },
    {
      "epoch": 6.7033161908139745,
      "eval_loss": 0.29422247409820557,
      "eval_runtime": 788.8454,
      "eval_samples_per_second": 25.351,
      "eval_steps_per_second": 3.169,
      "eval_wer": 0.1047632675001837,
      "step": 18900
    }
  ],
  "logging_steps": 50,
  "max_steps": 28190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6930526176205695e+20,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
