{
    "train":   [
        {"steps": 50,"loss": 35.3631, "grad_norm": 50.78611373901367, "learning_rate": 3.1066620642043493e-07, "epoch": 0.02},
        {"steps": 100,"loss": 37.8916, "grad_norm": 52.73244857788086, "learning_rate": 6.489471867449085e-07, "epoch": 0.03},
        {"steps": 150,"loss": 37.5256, "grad_norm": 59.13275909423828, "learning_rate": 9.941318605453917e-07, "epoch": 0.05},
        {"steps": 200,"loss": 35.988, "grad_norm": 67.70394134521484, "learning_rate": 1.339316534345875e-06, "epoch": 0.07},
        {"steps": 250,"loss": 35.2662, "grad_norm": 55.54794692993164, "learning_rate": 1.6845012081463583e-06, "epoch": 0.09},
        {"steps": 300, "loss": 33.6852, "grad_norm": 66.96751403808594, "learning_rate": 2.0296858819468415e-06, "epoch": 0.1},
        {"steps": 350,"loss": 35.8623, "grad_norm": 83.4151840209961, "learning_rate": 2.374870555747325e-06, "epoch": 0.12},
        {"steps": 400,"loss": 37.1507, "grad_norm": 81.82300567626953, "learning_rate": 2.7200552295478085e-06, "epoch": 0.14},
        {"steps": 450,"loss": 35.2303, "grad_norm": 52.729854583740234, "learning_rate": 3.065239903348292e-06, "epoch": 0.16},
        {"steps": 500,"loss": 31.1974, "grad_norm": 57.00068664550781, "learning_rate": 3.4104245771487747e-06, "epoch": 0.17},
        {"steps": 550,"loss": 26.6198, "grad_norm": 69.40511322021484, "learning_rate": 3.755609250949258e-06, "epoch": 0.19},
        {"steps": 600,"loss": 24.7157, "grad_norm": 74.96147155761719, "learning_rate": 4.100793924749741e-06, "epoch": 0.21},
        {"steps": 650,"loss": 21.4301, "grad_norm": 80.8115234375, "learning_rate": 4.445978598550225e-06, "epoch": 0.22},
        {"steps": 700,"loss": 20.0542, "grad_norm": 92.70976257324219, "learning_rate": 4.791163272350708e-06, "epoch": 0.24},
        {"steps": 750,"loss": 16.7274, "grad_norm": 96.99342346191406, "learning_rate": 5.1363479461511915e-06, "epoch": 0.26},
        {"steps": 800,"loss": 15.3303, "grad_norm": 114.44609069824219, "learning_rate": 5.481532619951674e-06, "epoch": 0.28},
        {"steps": 850,"loss": 14.8966, "grad_norm": 97.6893081665039, "learning_rate": 5.826717293752157e-06, "epoch": 0.29},
        {"steps": 900,"loss": 14.14, "grad_norm": 94.09905242919922, "learning_rate": 6.171901967552641e-06, "epoch": 0.31},
        {"steps": 950,"loss": 12.5105, "grad_norm": 85.82572937011719, "learning_rate": 6.517086641353125e-06, "epoch": 0.33},
        {"steps": 1000, "loss": 11.7516, "grad_norm": 91.4456558227539, "learning_rate": 6.862271315153608e-06, "epoch": 0.35},
        {"steps":1050,"loss": 11.2057, "grad_norm": 90.55353546142578, "learning_rate": 7.207455988954091e-06, "epoch": 0.36},
        {"steps":1100,"loss": 9.9869, "grad_norm": 71.05589294433594, "learning_rate": 7.552640662754575e-06, "epoch": 0.38},
        {"steps":1150,"loss": 9.2973, "grad_norm": 73.52696990966797, "learning_rate": 7.897825336555058e-06, "epoch": 0.4},
        {"steps":1200,"loss": 8.4557, "grad_norm": 60.117496490478516, "learning_rate": 8.243010010355541e-06, "epoch": 0.41},
        {"steps":1250,"loss": 7.9249, "grad_norm": 72.49068450927734, "learning_rate": 8.588194684156023e-06, "epoch": 0.43},
        {"steps":1300,"loss": 7.4402, "grad_norm": 66.552734375, "learning_rate": 8.933379357956507e-06, "epoch": 0.45},

        {"steps":1350,"loss": 6.7469, "grad_norm": 58.207763671875, "learning_rate": 9.278564031756991e-06, "epoch": 0.47},
        {"steps":1400,"loss": 6.8114, "grad_norm": 61.82878494262695, "learning_rate": 9.623748705557475e-06, "epoch": 0.48},

        {"steps":1450,"loss": 5.992, "grad_norm": 48.08763885498047, "learning_rate": 9.968933379357957e-06, "epoch": 0.5},
        {"steps":1500,"loss": 5.8476, "grad_norm": 39.31853485107422, "learning_rate": 1.031411805315844e-05, "epoch": 0.52},

        {"steps":1550,"loss": 5.3173, "grad_norm": 37.96500778198242, "learning_rate": 1.0659302726958924e-05, "epoch": 0.54},
        {"steps":1600,"loss": 5.3784, "grad_norm": 35.98183822631836, "learning_rate": 1.1004487400759408e-05, "epoch": 0.55},

        {"steps":1650,"loss": 5.1603, "grad_norm": 30.533004760742188, "learning_rate": 1.134967207455989e-05, "epoch": 0.57},
        {"steps":1700,"loss": 4.7892, "grad_norm": 31.853649139404297, "learning_rate": 1.1694856748360373e-05, "epoch": 0.59},

        {"steps":1750,"loss": 4.7381, "grad_norm": 28.00809669494629, "learning_rate": 1.2040041422160857e-05, "epoch": 0.6},
        {"steps":1800,"loss": 4.5199, "grad_norm": 19.26862907409668, "learning_rate": 1.238522609596134e-05, "epoch": 0.62},
        {"steps":1850,"loss": 4.4116, "grad_norm": 21.82164192199707, "learning_rate": 1.2730410769761821e-05, "epoch": 0.64},
        {"steps":1900,"loss": 4.1689, "grad_norm": 17.261730194091797, "learning_rate": 1.3075595443562305e-05, "epoch": 0.66},
        {"steps":1950,"loss": 4.0001, "grad_norm": 14.0667085647583, "learning_rate": 1.3420780117362789e-05, "epoch": 0.67},
        {"steps":2000,"loss": 3.8183, "grad_norm": 15.688777923583984, "learning_rate": 1.3765964791163272e-05, "epoch": 0.69},
        {"steps":2050,"loss": 3.7092, "grad_norm": 11.197284698486328, "learning_rate": 1.4111149464963758e-05, "epoch": 0.71},
        {"steps":2100,"loss": 3.6123, "grad_norm": 6.864049434661865, "learning_rate": 1.4456334138764241e-05, "epoch": 0.72},

        {"steps":2150,"loss": 3.519, "grad_norm": 9.054518699645996, "learning_rate": 1.4801518812564723e-05, "epoch": 0.74},
        {"steps":2200,"loss": 3.5194, "grad_norm": 7.2437262535095215, "learning_rate": 1.5146703486365207e-05, "epoch": 0.76}
],

    "eval": [
        {"steps": 100 ,"eval_loss": 37.11933135986328, "eval_wer": 1.0016972061375888, "eval_runtime": 1023.9524, "eval_samples_per_second": 20.119, "eval_steps_per_second": 2.516, "epoch": 0.03},
        {"steps": 200 ,"eval_loss": 36.76264953613281, "eval_wer": 1.0029720306572258, "eval_runtime": 985.7472, "eval_samples_per_second": 20.899, "eval_steps_per_second": 2.613, "epoch": 0.07},
        {"steps": 300,"eval_loss": 36.260440826416016, "eval_wer": 1.007652786950712, "eval_runtime": 984.735, "eval_samples_per_second": 20.92, "eval_steps_per_second": 2.616, "epoch": 0.1},
        {"steps": 400,"eval_loss": 35.57019805908203, "eval_wer": 1.290348964013086, "eval_runtime": 985.9441, "eval_samples_per_second": 20.895, "eval_steps_per_second": 2.613, "epoch": 0.14},
        {"steps": 500,"eval_loss": 29.80358123779297, "eval_wer": 1.1124456663645998, "eval_runtime": 984.7885, "eval_samples_per_second": 20.919, "eval_steps_per_second": 2.616, "epoch": 0.17},
        {"steps": 600,"eval_loss": 22.050580978393555, "eval_wer": 1.0054218440413474, "eval_runtime": 986.8443, "eval_samples_per_second": 20.876, "eval_steps_per_second": 2.61, "epoch": 0.21},
        {"steps": 700,"eval_loss": 17.28763198852539, "eval_wer": 1.000422381617952, "eval_runtime": 968.8377, "eval_samples_per_second": 21.264, "eval_steps_per_second": 2.659, "epoch": 0.24},
        {"steps": 800,"eval_loss": 13.952067375183105, "eval_wer": 1.0, "eval_runtime": 988.9089, "eval_samples_per_second": 20.832, "eval_steps_per_second": 2.605, "epoch": 0.28},
        {"steps": 900,"eval_loss": 11.609041213989258, "eval_wer": 1.0, "eval_runtime": 986.0393, "eval_samples_per_second": 20.893, "eval_steps_per_second": 2.612, "epoch": 0.31},
        {"steps": 1000,"eval_loss": 9.924674987792969, "eval_wer": 1.0, "eval_runtime": 984.2089, "eval_samples_per_second": 20.932, "eval_steps_per_second": 2.617, "epoch": 0.35},
        {"steps": 1100,"eval_loss": 8.61476993560791, "eval_wer": 1.0, "eval_runtime": 981.5773, "eval_samples_per_second": 20.988, "eval_steps_per_second": 2.624, "epoch": 0.38},
        {"steps": 1200,"eval_loss": 7.535671234130859, "eval_wer": 1.0, "eval_runtime": 976.1655, "eval_samples_per_second": 21.104, "eval_steps_per_second": 2.639, "epoch": 0.41},
        {"steps": 1300,"eval_loss": 6.613423824310303, "eval_wer": 1.0, "eval_runtime": 983.2522, "eval_samples_per_second": 20.952, "eval_steps_per_second": 2.62, "epoch": 0.45},
        {"steps": 1400,"eval_loss": 5.843001842498779, "eval_wer": 1.0, "eval_runtime": 980.2244, "eval_samples_per_second": 21.017, "eval_steps_per_second": 2.628, "epoch": 0.48},
        {"steps": 1500,"eval_loss": 5.233859539031982, "eval_wer": 1.0, "eval_runtime": 980.8444, "eval_samples_per_second": 21.003, "eval_steps_per_second": 2.626, "epoch": 0.52},
        {"steps": 1600,"eval_loss": 4.818850040435791, "eval_wer": 1.0, "eval_runtime": 985.4447, "eval_samples_per_second": 20.905, "eval_steps_per_second": 2.614, "epoch": 0.55},
        {"steps": 1700,"eval_loss": 4.521322727203369, "eval_wer": 1.0, "eval_runtime": 987.014, "eval_samples_per_second": 20.872, "eval_steps_per_second": 2.61, "epoch": 0.59},
        {"steps": 1800,"eval_loss": 4.195621013641357, "eval_wer": 1.0, "eval_runtime": 989.8206, "eval_samples_per_second": 20.813, "eval_steps_per_second": 2.602, "epoch": 0.62},
        {"steps": 1900,"eval_loss": 3.9157276153564453, "eval_wer": 1.0, "eval_runtime": 990.4901, "eval_samples_per_second": 20.799, "eval_steps_per_second": 2.601, "epoch": 0.66},
        {"steps": 2000,"eval_loss": 3.6995773315429688, "eval_wer": 1.0, "eval_runtime": 971.461, "eval_samples_per_second": 21.206, "eval_steps_per_second": 2.652, "epoch": 0.69},
        {"steps": 2100,"eval_loss": 3.5737812519073486, "eval_wer": 1.0, "eval_runtime": 986.4147, "eval_samples_per_second": 20.885, "eval_steps_per_second": 2.611, "epoch": 0.72}
    ]
}