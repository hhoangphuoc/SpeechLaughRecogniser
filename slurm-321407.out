	Adding nVidia Cuda Toolkit 11.7
	Adding nVidia cuDNN 8.6 (.0.163)
	Adding nVidia TensorRT 8.6 (.0.12)
	Adding nvtop
Date              = Tue Oct 22 09:22:33 PM CEST 2024
Hostname          = ctit088
Working Directory = /home/s2587130/SpeechLaughRecogniser
Name of nodes used          : ctit088
Gpu devices                 : 3
Starting worker: 
2024-10-22 21:23:40.649107: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-10-22 21:23:40.967524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-10-22 21:23:41.767620: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-10-22 21:23:42.117611: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-10-22 21:23:43.632657: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-22 21:24:05.336001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Evaluate Whisper Model - openai/whisper-small 

Loaded Switchboard Dataset: 
Dataset({
    features: ['audio', 'sampling_rate', 'transcript'],
    num_rows: 256191
})
Test dataset: 
Dataset({
    features: ['audio', 'sampling_rate', 'transcript'],
    num_rows: 25620
})
